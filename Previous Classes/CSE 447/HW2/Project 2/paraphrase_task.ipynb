{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:42.345488Z",
     "start_time": "2024-11-16T21:37:42.341460Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from glove import GloveEmbeddings\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "# Empty cache\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rohan\n",
      "[nltk_data]     Mukherjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:42.431321Z",
     "start_time": "2024-11-16T21:37:42.414544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "msr_train = pd.read_csv(\n",
    "    'data/msr/msr_paraphrase_train.txt', sep='\\t', encoding='utf-8', quoting=3\n",
    ")\n",
    "msr_test = pd.read_csv(\n",
    "    'data/msr/msr_paraphrase_test.txt', sep='\\t', encoding='utf-8', quoting=3\n",
    ")"
   ],
   "id": "8ad9ff978aea7f6f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:42.457357Z",
     "start_time": "2024-11-16T21:37:42.447609Z"
    }
   },
   "cell_type": "code",
   "source": "msr_train.head(10)",
   "id": "b6ca4b86d7c90126",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Quality    #1 ID    #2 ID  \\\n",
       "0        1   702876   702977   \n",
       "1        0  2108705  2108831   \n",
       "2        1  1330381  1330521   \n",
       "3        0  3344667  3344648   \n",
       "4        1  1236820  1236712   \n",
       "5        1   738533   737951   \n",
       "6        0   264589   264502   \n",
       "7        1   579975   579810   \n",
       "8        0  3114205  3114194   \n",
       "9        1  1355540  1355592   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called \"th...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "5  Revenue in the first quarter of the year dropp...   \n",
       "6  The Nasdaq had a weekly gain of 17.27, or 1.2 ...   \n",
       "7  The DVD-CCA then appealed to the state Supreme...   \n",
       "8  That compared with $35.18 million, or 24 cents...   \n",
       "9  He said the foodservice pie business doesn't f...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only \"the witness\", Amrozi...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  \n",
       "5  With the scandal hanging over Stewart's compan...  \n",
       "6  The tech-laced Nasdaq Composite .IXIC rallied ...  \n",
       "7  The DVD CCA appealed that decision to the U.S....  \n",
       "8  Earnings were affected by a non-recurring $8 m...  \n",
       "9  \"The foodservice pie business does not fit our...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>738533</td>\n",
       "      <td>737951</td>\n",
       "      <td>Revenue in the first quarter of the year dropp...</td>\n",
       "      <td>With the scandal hanging over Stewart's compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>264589</td>\n",
       "      <td>264502</td>\n",
       "      <td>The Nasdaq had a weekly gain of 17.27, or 1.2 ...</td>\n",
       "      <td>The tech-laced Nasdaq Composite .IXIC rallied ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>579975</td>\n",
       "      <td>579810</td>\n",
       "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
       "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3114205</td>\n",
       "      <td>3114194</td>\n",
       "      <td>That compared with $35.18 million, or 24 cents...</td>\n",
       "      <td>Earnings were affected by a non-recurring $8 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1355540</td>\n",
       "      <td>1355592</td>\n",
       "      <td>He said the foodservice pie business doesn't f...</td>\n",
       "      <td>\"The foodservice pie business does not fit our...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:47.612139Z",
     "start_time": "2024-11-16T21:37:42.492999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "data_dir = os.path.join(parent_dir, \"data\")\n",
    "\n",
    "glove_embeddings = GloveEmbeddings(\n",
    "    path=f\"{data_dir}/embeddings/glove.6B/glove.6B.50d.txt\"\n",
    ")"
   ],
   "id": "d500dcb8a96220c2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:47.632921Z",
     "start_time": "2024-11-16T21:37:47.629094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sentence_embedding(\n",
    "        sentence: str,\n",
    "        word_embeddings: GloveEmbeddings,\n",
    "        use_POS: bool = False,\n",
    "        pos_weights: Dict[str, float] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the sentence embedding using the word embeddings.\n",
    "\n",
    "    Inputs:\n",
    "    - sentence: The input sentence\n",
    "    - word_embeddings: GloveEmbeddings object\n",
    "    - use_POS: Whether to use POS tagging\n",
    "    - pos_weights: Dictionary containing POS weights\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The sentence embedding\n",
    "    \"\"\"\n",
    "    sentence_embedding = torch.sum(\n",
    "        torch.stack([\n",
    "            (pos_weights[tag] if use_POS else 1) * word_embeddings[word]\n",
    "            for word, tag in nltk.pos_tag(word_tokenize(sentence.lower()))\n",
    "            if word in word_embeddings.embeddings and (pos_weights is None or tag in pos_weights)\n",
    "        ]), dim=0\n",
    "    )\n",
    "    return sentence_embedding"
   ],
   "id": "e5f14a093af5ca88",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:50.041148Z",
     "start_time": "2024-11-16T21:37:47.651862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_st_embeddings(\n",
    "        sentences: List[str],\n",
    "        st_model: SentenceTransformer,\n",
    "        batch_size: int = 32,\n",
    "        device: str = \"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the sentence embedding using the Sentence Transformer model.\n",
    "    \n",
    "    Inputs:\n",
    "    - sentence: The input sentence\n",
    "    - st_model: SentenceTransformer model\n",
    "    - batch_size: Encode in batches to avoid memory issues in case multiple sentences are passed\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The sentence embedding of shape [d,] (when only 1 sentence) or [n, d] where n is the number of sentences and d is the embedding dimension\n",
    "    \"\"\"\n",
    "\n",
    "    st_model.to(device)\n",
    "    sentence_embeddings = None\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i: i + batch_size]\n",
    "        batch_embeddings = st_model.encode(batch_sentences, convert_to_tensor=True)\n",
    "        if sentence_embeddings is None:\n",
    "            sentence_embeddings = batch_embeddings\n",
    "        else:\n",
    "            sentence_embeddings = torch.cat(\n",
    "                [sentence_embeddings, batch_embeddings], dim=0\n",
    "            )\n",
    "    return sentence_embeddings.to(\"cpu\")"
   ],
   "id": "d21038aa960d3d0e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:50.050536Z",
     "start_time": "2024-11-16T21:37:50.047050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_msr_data(data_dir: str, split: str):\n",
    "    msr_data = pd.read_csv(\n",
    "        f\"{data_dir}/msr_paraphrase_{split}.txt\", sep=\"\\t\", encoding=\"utf-8\", quoting=3\n",
    "    )\n",
    "    data = [\n",
    "        {\n",
    "            \"#1 String\": msr_data[\"#1 String\"].values[i],\n",
    "            \"#2 String\": msr_data[\"#2 String\"].values[i],\n",
    "        }\n",
    "        for i in range(len(msr_data))\n",
    "    ]\n",
    "    labels = msr_data[\"Quality\"].values\n",
    "    return data, labels"
   ],
   "id": "618302b7976ee1de",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:50.094806Z",
     "start_time": "2024-11-16T21:37:50.057105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "msr_path = f'{data_dir}/msr'\n",
    "train_data, train_labels = load_msr_data(msr_path, \"train\")\n",
    "test_data, test_labels = load_msr_data(msr_path, \"test\")\n",
    "\n",
    "print(f\"Number of Training Examples: {len(train_data)}\")\n",
    "print(f\"Number of Test Examples: {len(test_data)}\")"
   ],
   "id": "742fc1a127ee8f50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples: 4076\n",
      "Number of Test Examples: 1725\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:50.302672Z",
     "start_time": "2024-11-16T21:37:50.104307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sns.countplot(x=train_labels)\n",
    "sns.countplot(x=test_labels)"
   ],
   "id": "3a077fafc65d0464",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:50.316474Z",
     "start_time": "2024-11-16T21:37:50.313113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# View a sample of the dataset\n",
    "print(\"Example from dataset\")\n",
    "pprint(train_data[69], sort_dicts=False, indent=4)\n",
    "print(f\"Label: {train_labels[69]}\")"
   ],
   "id": "ba7c341c36a7545e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example from dataset\n",
      "{   '#1 String': 'The processors were announced in San Jose at the Intel '\n",
      "                 'Developer Forum.',\n",
      "    '#2 String': 'The new processor was unveiled at the Intel Developer Forum '\n",
      "                 '2003 in San Jose, Calif.'}\n",
      "Label: 1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:37:50.350719Z",
     "start_time": "2024-11-16T21:37:50.347077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def st_embed_msr(msr_data: List[Dict[str, str]], st_model: SentenceTransformer, device: str = \"cpu\"):\n",
    "    str1_embedded = get_st_embeddings([example[\"#1 String\"] for example in msr_data], st_model, device=device)\n",
    "    str2_embedded = get_st_embeddings([example[\"#2 String\"] for example in msr_data], st_model, device=device)\n",
    "   \n",
    "    data_embedded = [\n",
    "        {\n",
    "            \"string1\": str1_embedded[i],\n",
    "            \"string2\": str2_embedded[i],\n",
    "        }\n",
    "        for i in range(len(msr_data))\n",
    "    ]\n",
    "    return data_embedded"
   ],
   "id": "8e42a1306f1c14f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:38:32.254383Z",
     "start_time": "2024-11-16T23:38:22.435706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_glove = [\n",
    "    {\n",
    "        \"string1\": get_sentence_embedding(msr_train[\"#1 String\"].values[i], glove_embeddings, use_POS=False),\n",
    "        \"string2\": get_sentence_embedding(msr_train[\"#2 String\"].values[i], glove_embeddings, use_POS=False),\n",
    "    }\n",
    "    for i in range(len(msr_train))\n",
    "]\n",
    "X_test_glove = [\n",
    "    {\n",
    "        \"string1\": get_sentence_embedding(msr_test[\"#1 String\"].values[i], glove_embeddings, use_POS=False),\n",
    "        \"string2\": get_sentence_embedding(msr_test[\"#2 String\"].values[i], glove_embeddings, use_POS=False),\n",
    "    }\n",
    "    for i in range(len(msr_test))\n",
    "]\n",
    "\n",
    "y_train = msr_train[\"Quality\"].values.astype(np.float32)\n",
    "y_test = msr_test[\"Quality\"].values.astype(np.float32)\n",
    "\n",
    "st_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "if os.path.exists(f\"{data_dir}/msr/train_data_embedded.pt\") and os.path.exists(f\"{data_dir}/msr/test_data_embedded.pt\"):\n",
    "    X_train_st = torch.load(f\"{data_dir}/msr/train_data_embedded.pt\")\n",
    "    X_test_st = torch.load(f\"{data_dir}/msr/test_data_embedded.pt\")\n",
    "else:\n",
    "    X_train_st = st_embed_msr(msr_train, st_model, device=DEVICE)\n",
    "    X_test_st = st_embed_msr(msr_test, st_model, device=DEVICE)\n",
    "    torch.save(X_train_st, f\"{data_dir}/msr/train_data_embedded.pt\")\n",
    "    torch.save(X_test_st, f\"{data_dir}/msr/test_data_embedded.pt\")"
   ],
   "id": "b1e6c273411a222",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_788624\\3062651526.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_train_st = torch.load(f\"{data_dir}/msr/train_data_embedded.pt\")\n",
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_788624\\3062651526.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_test_st = torch.load(f\"{data_dir}/msr/test_data_embedded.pt\")\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:38:00.785016Z",
     "start_time": "2024-11-16T21:38:00.779914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSREmbeddedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: List[Dict[str, torch.Tensor]], labels: List[float]):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"string1\": self.data[idx][\"string1\"],\n",
    "            \"string2\": self.data[idx][\"string2\"],\n",
    "            \"label\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "def get_msr_dataloader(\n",
    "    embeddings: List[Dict[str, torch.Tensor]],\n",
    "    labels: List[float],\n",
    "    batch_size: int = 32,\n",
    "    shuffle: bool = True,\n",
    "    use_weighted_sampling: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the MSR dataset, with optional weighted sampling for imbalanced datasets.\n",
    "\n",
    "    Args:\n",
    "        embeddings (List[Dict[str, torch.Tensor]]): List of embedded data dictionaries.\n",
    "        labels (List[float]): List of labels (binary classification: 0 or 1).\n",
    "        batch_size (int): Size of each batch.\n",
    "        shuffle (bool): Whether to shuffle the dataset (ignored if weighted sampling is enabled).\n",
    "        use_weighted_sampling (bool): Whether to use weighted sampling to balance the classes.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: A PyTorch DataLoader for the dataset.\n",
    "    \"\"\"\n",
    "    # Create the dataset\n",
    "    dataset = MSREmbeddedDataset(embeddings, labels)\n",
    "\n",
    "    if use_weighted_sampling:\n",
    "        # Compute class counts\n",
    "        class_counts = [sum(1 for label in labels if label == 0), sum(1 for label in labels if label == 1)]\n",
    "        class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "\n",
    "        # Assign weights to each sample based on its label\n",
    "        sample_weights = [class_weights[int(label)] for label in labels]\n",
    "\n",
    "        # Create a WeightedRandomSampler\n",
    "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "        # Return DataLoader with sampler\n",
    "        return DataLoader(dataset, batch_size=batch_size, sampler=sampler, shuffle=shuffle)\n",
    "    else:\n",
    "        # Regular DataLoader\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_loader_glove = get_msr_dataloader(X_train_glove, y_train)\n",
    "test_loader_glove = get_msr_dataloader(X_test_glove, y_test)\n",
    "train_loader_st = get_msr_dataloader(X_train_st, y_train)\n",
    "test_loader_st = get_msr_dataloader(X_test_st, y_test)"
   ],
   "id": "ecc7a535f3fe81bc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:38:00.801557Z",
     "start_time": "2024-11-16T21:38:00.792678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader_glove:\n",
    "    # Get the embeddings for str1, str2\n",
    "    str1_batch = batch[\"string1\"]\n",
    "    str2_batch = batch[\"string2\"]\n",
    "    labels = batch[\"label\"]\n",
    "\n",
    "    print(str1_batch.shape, str2_batch.shape, labels.shape)\n",
    "    break"
   ],
   "id": "1650454163070d87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50]) torch.Size([32, 50]) torch.Size([32])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T22:18:25.477467Z",
     "start_time": "2024-11-16T22:18:25.473063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using a Siamese NN architecture\n",
    "class PNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, hidden_layers: int = 1):\n",
    "        super(PNN, self).__init__()\n",
    "        # Shared layers for both strings\n",
    "        layers = []\n",
    "        for i in range(hidden_layers):\n",
    "            in_features = input_dim if i == 0 else hidden_dim\n",
    "            layers.append(torch.nn.Linear(in_features, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        self.shared_fc = torch.nn.Sequential(*layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = torch.nn.Linear(hidden_dim * 3, output_dim)\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor):\n",
    "        proj1 = self.shared_fc(x1)\n",
    "        proj2 = self.shared_fc(x2)\n",
    "        # Concatenate the two projected embeddings\n",
    "        x = torch.cat([proj1, proj2, torch.abs(proj1 - proj2)], dim=-1)\n",
    "        \n",
    "        return self.fc_out(x)"
   ],
   "id": "7d858a9d6ab67842",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T21:38:00.880809Z",
     "start_time": "2024-11-16T21:38:00.877277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the model.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Predictions from the model.\n",
    "        y_true (torch.Tensor): True labels.\n",
    "    \n",
    "    Returns:\n",
    "        float: The accuracy of the model.\n",
    "    \"\"\"\n",
    "    correct = (y_pred == y_true).sum().item()\n",
    "    total = y_true.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def precision(y_pred, y_true, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the precision of the model.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Predictions from the model.\n",
    "        y_true (torch.Tensor): True labels.\n",
    "        epsilon (float): Small value to prevent division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        float: The precision of the model.\n",
    "    \"\"\"\n",
    "    true_positives = (y_pred * y_true).sum().item()\n",
    "    predicted_positives = y_pred.sum().item()\n",
    "    return true_positives / (predicted_positives + epsilon)\n",
    "\n",
    "def recall(y_pred, y_true, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the recall of the model.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Predictions from the model.\n",
    "        y_true (torch.Tensor): True labels.\n",
    "        epsilon (float): Small value to prevent division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        float: The recall of the model.\n",
    "    \"\"\"\n",
    "    true_positives = (y_pred * y_true).sum().item()\n",
    "    actual_positives = y_true.sum().item()\n",
    "    return true_positives / (actual_positives + epsilon)\n",
    "\n",
    "def f1_score(y_pred, y_true, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the F1 score of the model.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Predictions from the model.\n",
    "        y_true (torch.Tensor): True labels.\n",
    "        epsilon (float): Small value to prevent division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        float: The F1 score of the model.\n",
    "    \"\"\"\n",
    "    prec = precision(y_pred, y_true, epsilon)\n",
    "    rec = recall(y_pred, y_true, epsilon)\n",
    "    return 2 * (prec * rec) / (prec + rec + epsilon)"
   ],
   "id": "75bfb12765b649fa",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T22:47:22.076130Z",
     "start_time": "2024-11-16T22:47:22.068282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_msr(\n",
    "    model: PNN,\n",
    "    dev_data_embedded: List[Dict[str, torch.Tensor]],\n",
    "    dev_labels: List[float],\n",
    "    eval_batch_size: int = 128,\n",
    "    device: str = \"cpu\",\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on the SocialIQA dataset.\n",
    "\n",
    "    Inputs:\n",
    "    - model: The ParaphraseNN model\n",
    "    - dev_data_embedded: List of dictionaries containing the embedded context, question and answers for the validation data\n",
    "    - dev_labels: List of labels for the validation data\n",
    "    - eval_batch_size: Batch size for evaluation\n",
    "    - device: Device to run the evaluation on\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        \"loss\": 0,\n",
    "        \"accuracy\": 0,\n",
    "        \"precision\": 0,\n",
    "        \"recall\": 0,\n",
    "        \"f1\": 0\n",
    "    }\n",
    "    \n",
    "    # true_weight = 1 / (sum(dev_labels) / len(dev_labels))\n",
    "    # loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([true_weight]).to(device))\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    msr_dl = get_msr_dataloader(dev_data_embedded, dev_labels, eval_batch_size, shuffle=False)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        for batch in msr_dl:\n",
    "            str1 = batch[\"string1\"].to(device)\n",
    "            str2 = batch[\"string2\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            \n",
    "            forward = model.forward(str1, str2)\n",
    "            pred = torch.sigmoid(forward) >= 0.5\n",
    "            pred = pred.squeeze()\n",
    "            \n",
    "            metrics[\"loss\"] += loss_fn(forward.squeeze(), labels).item()\n",
    "            metrics[\"accuracy\"] += accuracy(pred, labels)\n",
    "            metrics[\"precision\"] += precision(pred, labels)\n",
    "            metrics[\"recall\"] += recall(pred, labels)\n",
    "            metrics[\"f1\"] += f1_score(pred, labels)\n",
    "    \n",
    "    metrics[\"loss\"] /= len(msr_dl)\n",
    "    metrics[\"accuracy\"] /= len(msr_dl)\n",
    "    metrics[\"precision\"] /= len(msr_dl)\n",
    "    metrics[\"recall\"] /= len(msr_dl)\n",
    "    metrics[\"f1\"] /= len(msr_dl)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_msr(\n",
    "    model: PNN,\n",
    "    train_data_embedded: List[Dict[str, torch.Tensor]],\n",
    "    train_labels: List[float],\n",
    "    dev_data_embedded: List[Dict[str, torch.Tensor]],\n",
    "    dev_labels: List[float],\n",
    "    lr: float = 1e-3,\n",
    "    batch_size: int = 32,\n",
    "    eval_batch_size: int = 128,\n",
    "    n_epochs: int = 10,\n",
    "    device: str = \"cpu\",\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs the training loop for `n_epochs` epochs on the SocialIQA dataset.\n",
    "\n",
    "    Inputs:\n",
    "    - model: The ParaphaseNN model to be trained\n",
    "    - train_data_embedded: List of dictionaries containing the embedded context, question and answers for the training data\n",
    "    - train_labels: List of labels for the training data\n",
    "    - dev_data_embedded: List of dictionaries containing the embedded context, question and answers for the validation data\n",
    "    - dev_labels: List of labels for the validation data\n",
    "    - lr: Learning rate for the optimizer\n",
    "    - n_epochs: Number of epochs to train the model\n",
    "\n",
    "    Returns:\n",
    "    - train_losses: List of training losses for each epoch\n",
    "    - dev_metrics: List[Dict[str, float]] of validation metrics (loss, accuracy) for each epoch\n",
    "    \"\"\"\n",
    "    # We remove all the training wheels and let you implement the training loop for the SocialIQA dataset\n",
    "    # YOUR CODE HERE\n",
    "    train_dl = get_msr_dataloader(train_data_embedded, train_labels, batch_size, shuffle=True)\n",
    "    \n",
    "    # transfer model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # define CrossEntropy loss function\n",
    "    # true_weight = 1 / (sum(train_labels) / len(train_labels))\n",
    "    # loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([true_weight]).to(device))\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Define adam optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    train_losses = []\n",
    "    dev_metrics = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0.0\n",
    "        for batch in train_dl:      \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            str1 = batch[\"string1\"].to(device)\n",
    "            str2 = batch[\"string2\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            \n",
    "            forward = model.forward(str1, str2)\n",
    "            batch_loss = loss_fn(forward.squeeze(), labels)\n",
    "            \n",
    "            # backward pass and update weights\n",
    "            batch_loss.backward()\n",
    "            \n",
    "            # step of optimization\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_epoch_loss += batch_loss.item()\n",
    "        \n",
    "        train_epoch_loss /= len(train_dl)\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        \n",
    "        eval_metrics = evaluate_msr(model, dev_data_embedded, dev_labels, eval_batch_size, device)\n",
    "        dev_metrics.append(eval_metrics)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Epoch: %.d, Train Loss: %.4f, Dev Loss: %.4f, Dev Accuracy: %.4f, Dev Precision: %.4f, Dev Recall: %.4f, Dev F1: %.4f\" % (epoch + 1, train_epoch_loss, eval_metrics[\"loss\"], eval_metrics[\"accuracy\"], eval_metrics[\"precision\"], eval_metrics[\"recall\"], eval_metrics[\"f1\"]))\n",
    "\n",
    "    return train_losses, dev_metrics"
   ],
   "id": "151078b4aec80f45",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T22:18:48.238808Z",
     "start_time": "2024-11-16T22:18:28.360207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# testing train_msr\n",
    "model = PNN(input_dim=50, hidden_dim=128, output_dim=1)\n",
    "train_msr(\n",
    "    model, X_train_glove, y_train, X_test_glove, y_test,\n",
    "    lr=1e-3, n_epochs=100, batch_size=32, device='cuda', verbose=True\n",
    ")"
   ],
   "id": "dc747b65dad5d343",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.5989, Dev Loss: 0.5822, Dev Accuracy: 0.6903, Dev Precision: 0.6951, Dev Recall: 0.9512, Dev F1: 0.8024\n",
      "Epoch: 2, Train Loss: 0.5502, Dev Loss: 0.5641, Dev Accuracy: 0.7228, Dev Precision: 0.7426, Dev Recall: 0.8923, Dev F1: 0.8097\n",
      "Epoch: 3, Train Loss: 0.5236, Dev Loss: 0.5483, Dev Accuracy: 0.7261, Dev Precision: 0.7466, Dev Recall: 0.8904, Dev F1: 0.8113\n",
      "Epoch: 4, Train Loss: 0.5002, Dev Loss: 0.5389, Dev Accuracy: 0.7363, Dev Precision: 0.7630, Dev Recall: 0.8742, Dev F1: 0.8140\n",
      "Epoch: 5, Train Loss: 0.4792, Dev Loss: 0.5401, Dev Accuracy: 0.7351, Dev Precision: 0.7918, Dev Recall: 0.8160, Dev F1: 0.8026\n",
      "Epoch: 6, Train Loss: 0.4543, Dev Loss: 0.5407, Dev Accuracy: 0.7322, Dev Precision: 0.7510, Dev Recall: 0.8942, Dev F1: 0.8155\n",
      "Epoch: 7, Train Loss: 0.4411, Dev Loss: 0.5388, Dev Accuracy: 0.7351, Dev Precision: 0.7521, Dev Recall: 0.8970, Dev F1: 0.8173\n",
      "Epoch: 8, Train Loss: 0.4189, Dev Loss: 0.5338, Dev Accuracy: 0.7300, Dev Precision: 0.7652, Dev Recall: 0.8574, Dev F1: 0.8077\n",
      "Epoch: 9, Train Loss: 0.4065, Dev Loss: 0.5401, Dev Accuracy: 0.7355, Dev Precision: 0.7643, Dev Recall: 0.8695, Dev F1: 0.8129\n",
      "Epoch: 10, Train Loss: 0.3893, Dev Loss: 0.5404, Dev Accuracy: 0.7264, Dev Precision: 0.7657, Dev Recall: 0.8485, Dev F1: 0.8041\n",
      "Epoch: 11, Train Loss: 0.3767, Dev Loss: 0.5504, Dev Accuracy: 0.7256, Dev Precision: 0.7596, Dev Recall: 0.8588, Dev F1: 0.8052\n",
      "Epoch: 12, Train Loss: 0.3625, Dev Loss: 0.5428, Dev Accuracy: 0.7265, Dev Precision: 0.7640, Dev Recall: 0.8511, Dev F1: 0.8043\n",
      "Epoch: 13, Train Loss: 0.3456, Dev Loss: 0.5555, Dev Accuracy: 0.7204, Dev Precision: 0.7634, Dev Recall: 0.8398, Dev F1: 0.7987\n",
      "Epoch: 14, Train Loss: 0.3469, Dev Loss: 0.5509, Dev Accuracy: 0.7242, Dev Precision: 0.7635, Dev Recall: 0.8471, Dev F1: 0.8023\n",
      "Epoch: 15, Train Loss: 0.3297, Dev Loss: 0.5671, Dev Accuracy: 0.7221, Dev Precision: 0.7605, Dev Recall: 0.8486, Dev F1: 0.8012\n",
      "Epoch: 16, Train Loss: 0.3210, Dev Loss: 0.5611, Dev Accuracy: 0.7245, Dev Precision: 0.7671, Dev Recall: 0.8391, Dev F1: 0.8008\n",
      "Epoch: 17, Train Loss: 0.3117, Dev Loss: 0.5665, Dev Accuracy: 0.7279, Dev Precision: 0.7732, Dev Recall: 0.8336, Dev F1: 0.8015\n",
      "Epoch: 18, Train Loss: 0.2904, Dev Loss: 0.5703, Dev Accuracy: 0.7238, Dev Precision: 0.7796, Dev Recall: 0.8136, Dev F1: 0.7954\n",
      "Epoch: 19, Train Loss: 0.2884, Dev Loss: 0.5771, Dev Accuracy: 0.7278, Dev Precision: 0.7697, Dev Recall: 0.8407, Dev F1: 0.8028\n",
      "Epoch: 20, Train Loss: 0.2833, Dev Loss: 0.5884, Dev Accuracy: 0.7255, Dev Precision: 0.7693, Dev Recall: 0.8368, Dev F1: 0.8010\n",
      "Epoch: 21, Train Loss: 0.2735, Dev Loss: 0.5867, Dev Accuracy: 0.7216, Dev Precision: 0.7639, Dev Recall: 0.8397, Dev F1: 0.7992\n",
      "Epoch: 22, Train Loss: 0.2661, Dev Loss: 0.5986, Dev Accuracy: 0.7233, Dev Precision: 0.7658, Dev Recall: 0.8394, Dev F1: 0.8001\n",
      "Epoch: 23, Train Loss: 0.2571, Dev Loss: 0.6070, Dev Accuracy: 0.7255, Dev Precision: 0.7704, Dev Recall: 0.8336, Dev F1: 0.8002\n",
      "Epoch: 24, Train Loss: 0.2429, Dev Loss: 0.6073, Dev Accuracy: 0.7307, Dev Precision: 0.7778, Dev Recall: 0.8329, Dev F1: 0.8034\n",
      "Epoch: 25, Train Loss: 0.2404, Dev Loss: 0.6170, Dev Accuracy: 0.7223, Dev Precision: 0.7731, Dev Recall: 0.8209, Dev F1: 0.7956\n",
      "Epoch: 26, Train Loss: 0.2377, Dev Loss: 0.6286, Dev Accuracy: 0.7200, Dev Precision: 0.7671, Dev Recall: 0.8307, Dev F1: 0.7967\n",
      "Epoch: 27, Train Loss: 0.2241, Dev Loss: 0.6172, Dev Accuracy: 0.7245, Dev Precision: 0.7738, Dev Recall: 0.8268, Dev F1: 0.7983\n",
      "Epoch: 28, Train Loss: 0.2254, Dev Loss: 0.6203, Dev Accuracy: 0.7301, Dev Precision: 0.7750, Dev Recall: 0.8363, Dev F1: 0.8035\n",
      "Epoch: 29, Train Loss: 0.2157, Dev Loss: 0.6459, Dev Accuracy: 0.7246, Dev Precision: 0.7652, Dev Recall: 0.8425, Dev F1: 0.8013\n",
      "Epoch: 30, Train Loss: 0.2095, Dev Loss: 0.6566, Dev Accuracy: 0.7250, Dev Precision: 0.7706, Dev Recall: 0.8325, Dev F1: 0.7994\n",
      "Epoch: 31, Train Loss: 0.2067, Dev Loss: 0.6515, Dev Accuracy: 0.7306, Dev Precision: 0.7748, Dev Recall: 0.8377, Dev F1: 0.8040\n",
      "Epoch: 32, Train Loss: 0.2039, Dev Loss: 0.6425, Dev Accuracy: 0.7295, Dev Precision: 0.7815, Dev Recall: 0.8216, Dev F1: 0.8001\n",
      "Epoch: 33, Train Loss: 0.1928, Dev Loss: 0.6465, Dev Accuracy: 0.7345, Dev Precision: 0.7813, Dev Recall: 0.8329, Dev F1: 0.8054\n",
      "Epoch: 34, Train Loss: 0.1841, Dev Loss: 0.6717, Dev Accuracy: 0.7239, Dev Precision: 0.7693, Dev Recall: 0.8351, Dev F1: 0.7999\n",
      "Epoch: 35, Train Loss: 0.1832, Dev Loss: 0.6701, Dev Accuracy: 0.7227, Dev Precision: 0.7870, Dev Recall: 0.8005, Dev F1: 0.7921\n",
      "Epoch: 36, Train Loss: 0.1760, Dev Loss: 0.6796, Dev Accuracy: 0.7244, Dev Precision: 0.7685, Dev Recall: 0.8386, Dev F1: 0.8009\n",
      "Epoch: 37, Train Loss: 0.1727, Dev Loss: 0.6815, Dev Accuracy: 0.7184, Dev Precision: 0.7674, Dev Recall: 0.8271, Dev F1: 0.7950\n",
      "Epoch: 38, Train Loss: 0.1700, Dev Loss: 0.6855, Dev Accuracy: 0.7272, Dev Precision: 0.7689, Dev Recall: 0.8431, Dev F1: 0.8031\n",
      "Epoch: 39, Train Loss: 0.1743, Dev Loss: 0.7026, Dev Accuracy: 0.7300, Dev Precision: 0.7697, Dev Recall: 0.8460, Dev F1: 0.8052\n",
      "Epoch: 40, Train Loss: 0.1715, Dev Loss: 0.7021, Dev Accuracy: 0.7178, Dev Precision: 0.7668, Dev Recall: 0.8247, Dev F1: 0.7938\n",
      "Epoch: 41, Train Loss: 0.1618, Dev Loss: 0.7192, Dev Accuracy: 0.7189, Dev Precision: 0.7728, Dev Recall: 0.8169, Dev F1: 0.7932\n",
      "Epoch: 42, Train Loss: 0.1520, Dev Loss: 0.7282, Dev Accuracy: 0.7217, Dev Precision: 0.7708, Dev Recall: 0.8278, Dev F1: 0.7971\n",
      "Epoch: 43, Train Loss: 0.1541, Dev Loss: 0.7230, Dev Accuracy: 0.7182, Dev Precision: 0.7726, Dev Recall: 0.8154, Dev F1: 0.7925\n",
      "Epoch: 44, Train Loss: 0.1521, Dev Loss: 0.7362, Dev Accuracy: 0.7266, Dev Precision: 0.7844, Dev Recall: 0.8114, Dev F1: 0.7965\n",
      "Epoch: 45, Train Loss: 0.1443, Dev Loss: 0.7345, Dev Accuracy: 0.7212, Dev Precision: 0.7737, Dev Recall: 0.8200, Dev F1: 0.7949\n",
      "Epoch: 46, Train Loss: 0.1327, Dev Loss: 0.7627, Dev Accuracy: 0.7161, Dev Precision: 0.7684, Dev Recall: 0.8191, Dev F1: 0.7917\n",
      "Epoch: 47, Train Loss: 0.1444, Dev Loss: 0.7665, Dev Accuracy: 0.7183, Dev Precision: 0.7669, Dev Recall: 0.8265, Dev F1: 0.7945\n",
      "Epoch: 48, Train Loss: 0.1362, Dev Loss: 0.7526, Dev Accuracy: 0.7261, Dev Precision: 0.7769, Dev Recall: 0.8241, Dev F1: 0.7989\n",
      "Epoch: 49, Train Loss: 0.1398, Dev Loss: 0.7549, Dev Accuracy: 0.7240, Dev Precision: 0.7824, Dev Recall: 0.8094, Dev F1: 0.7942\n",
      "Epoch: 50, Train Loss: 0.1339, Dev Loss: 0.7694, Dev Accuracy: 0.7183, Dev Precision: 0.7769, Dev Recall: 0.8084, Dev F1: 0.7912\n",
      "Epoch: 51, Train Loss: 0.1307, Dev Loss: 0.7802, Dev Accuracy: 0.7273, Dev Precision: 0.7702, Dev Recall: 0.8415, Dev F1: 0.8030\n",
      "Epoch: 52, Train Loss: 0.1299, Dev Loss: 0.8067, Dev Accuracy: 0.7183, Dev Precision: 0.7597, Dev Recall: 0.8430, Dev F1: 0.7982\n",
      "Epoch: 53, Train Loss: 0.1264, Dev Loss: 0.7878, Dev Accuracy: 0.7175, Dev Precision: 0.7888, Dev Recall: 0.7846, Dev F1: 0.7858\n",
      "Epoch: 54, Train Loss: 0.1248, Dev Loss: 0.8073, Dev Accuracy: 0.7228, Dev Precision: 0.7776, Dev Recall: 0.8179, Dev F1: 0.7958\n",
      "Epoch: 55, Train Loss: 0.1191, Dev Loss: 0.8088, Dev Accuracy: 0.7121, Dev Precision: 0.7743, Dev Recall: 0.8007, Dev F1: 0.7861\n",
      "Epoch: 56, Train Loss: 0.1179, Dev Loss: 0.8358, Dev Accuracy: 0.7307, Dev Precision: 0.7714, Dev Recall: 0.8452, Dev F1: 0.8054\n",
      "Epoch: 57, Train Loss: 0.1199, Dev Loss: 0.8329, Dev Accuracy: 0.7272, Dev Precision: 0.7728, Dev Recall: 0.8349, Dev F1: 0.8016\n",
      "Epoch: 58, Train Loss: 0.1142, Dev Loss: 0.8410, Dev Accuracy: 0.7200, Dev Precision: 0.7636, Dev Recall: 0.8370, Dev F1: 0.7977\n",
      "Epoch: 59, Train Loss: 0.1166, Dev Loss: 0.8274, Dev Accuracy: 0.7155, Dev Precision: 0.7754, Dev Recall: 0.8033, Dev F1: 0.7880\n",
      "Epoch: 60, Train Loss: 0.1185, Dev Loss: 0.8464, Dev Accuracy: 0.7218, Dev Precision: 0.7698, Dev Recall: 0.8271, Dev F1: 0.7964\n",
      "Epoch: 61, Train Loss: 0.1089, Dev Loss: 0.8338, Dev Accuracy: 0.7217, Dev Precision: 0.7803, Dev Recall: 0.8081, Dev F1: 0.7929\n",
      "Epoch: 62, Train Loss: 0.1060, Dev Loss: 0.8343, Dev Accuracy: 0.7211, Dev Precision: 0.7751, Dev Recall: 0.8170, Dev F1: 0.7945\n",
      "Epoch: 63, Train Loss: 0.1112, Dev Loss: 0.8606, Dev Accuracy: 0.7189, Dev Precision: 0.7729, Dev Recall: 0.8165, Dev F1: 0.7929\n",
      "Epoch: 64, Train Loss: 0.0998, Dev Loss: 0.8617, Dev Accuracy: 0.7234, Dev Precision: 0.7736, Dev Recall: 0.8251, Dev F1: 0.7974\n",
      "Epoch: 65, Train Loss: 0.1035, Dev Loss: 0.8571, Dev Accuracy: 0.7261, Dev Precision: 0.7759, Dev Recall: 0.8278, Dev F1: 0.7997\n",
      "Epoch: 66, Train Loss: 0.1054, Dev Loss: 0.8654, Dev Accuracy: 0.7237, Dev Precision: 0.7947, Dev Recall: 0.7872, Dev F1: 0.7900\n",
      "Epoch: 67, Train Loss: 0.1019, Dev Loss: 0.8640, Dev Accuracy: 0.7261, Dev Precision: 0.7776, Dev Recall: 0.8244, Dev F1: 0.7988\n",
      "Epoch: 68, Train Loss: 0.0988, Dev Loss: 0.8828, Dev Accuracy: 0.7289, Dev Precision: 0.7728, Dev Recall: 0.8383, Dev F1: 0.8028\n",
      "Epoch: 69, Train Loss: 0.1046, Dev Loss: 0.8817, Dev Accuracy: 0.7094, Dev Precision: 0.7714, Dev Recall: 0.7985, Dev F1: 0.7833\n",
      "Epoch: 70, Train Loss: 0.1002, Dev Loss: 0.8805, Dev Accuracy: 0.7201, Dev Precision: 0.7842, Dev Recall: 0.7992, Dev F1: 0.7901\n",
      "Epoch: 71, Train Loss: 0.0971, Dev Loss: 0.8886, Dev Accuracy: 0.7245, Dev Precision: 0.7770, Dev Recall: 0.8207, Dev F1: 0.7971\n",
      "Epoch: 72, Train Loss: 0.0971, Dev Loss: 0.9009, Dev Accuracy: 0.7058, Dev Precision: 0.7740, Dev Recall: 0.7880, Dev F1: 0.7796\n",
      "Epoch: 73, Train Loss: 0.0906, Dev Loss: 0.9350, Dev Accuracy: 0.7189, Dev Precision: 0.7587, Dev Recall: 0.8450, Dev F1: 0.7986\n",
      "Epoch: 74, Train Loss: 0.0995, Dev Loss: 0.8974, Dev Accuracy: 0.7137, Dev Precision: 0.7718, Dev Recall: 0.8077, Dev F1: 0.7881\n",
      "Epoch: 75, Train Loss: 0.0958, Dev Loss: 0.9454, Dev Accuracy: 0.7245, Dev Precision: 0.7658, Dev Recall: 0.8428, Dev F1: 0.8012\n",
      "Epoch: 76, Train Loss: 0.0872, Dev Loss: 0.9204, Dev Accuracy: 0.7160, Dev Precision: 0.7652, Dev Recall: 0.8257, Dev F1: 0.7932\n",
      "Epoch: 77, Train Loss: 0.0948, Dev Loss: 0.9117, Dev Accuracy: 0.7170, Dev Precision: 0.7703, Dev Recall: 0.8190, Dev F1: 0.7926\n",
      "Epoch: 78, Train Loss: 0.0977, Dev Loss: 0.9208, Dev Accuracy: 0.7150, Dev Precision: 0.7697, Dev Recall: 0.8160, Dev F1: 0.7907\n",
      "Epoch: 79, Train Loss: 0.0875, Dev Loss: 0.9307, Dev Accuracy: 0.7284, Dev Precision: 0.7684, Dev Recall: 0.8462, Dev F1: 0.8043\n",
      "Epoch: 80, Train Loss: 0.0829, Dev Loss: 0.9233, Dev Accuracy: 0.7217, Dev Precision: 0.7811, Dev Recall: 0.8083, Dev F1: 0.7928\n",
      "Epoch: 81, Train Loss: 0.0925, Dev Loss: 0.9483, Dev Accuracy: 0.7144, Dev Precision: 0.7685, Dev Recall: 0.8146, Dev F1: 0.7898\n",
      "Epoch: 82, Train Loss: 0.0859, Dev Loss: 0.9529, Dev Accuracy: 0.7109, Dev Precision: 0.7647, Dev Recall: 0.8151, Dev F1: 0.7883\n",
      "Epoch: 83, Train Loss: 0.0818, Dev Loss: 0.9599, Dev Accuracy: 0.7170, Dev Precision: 0.7647, Dev Recall: 0.8286, Dev F1: 0.7943\n",
      "Epoch: 84, Train Loss: 0.0846, Dev Loss: 0.9749, Dev Accuracy: 0.7204, Dev Precision: 0.7694, Dev Recall: 0.8269, Dev F1: 0.7959\n",
      "Epoch: 85, Train Loss: 0.0854, Dev Loss: 0.9899, Dev Accuracy: 0.7194, Dev Precision: 0.7637, Dev Recall: 0.8368, Dev F1: 0.7972\n",
      "Epoch: 86, Train Loss: 0.0871, Dev Loss: 0.9700, Dev Accuracy: 0.7199, Dev Precision: 0.7678, Dev Recall: 0.8279, Dev F1: 0.7959\n",
      "Epoch: 87, Train Loss: 0.0814, Dev Loss: 0.9800, Dev Accuracy: 0.7228, Dev Precision: 0.7715, Dev Recall: 0.8261, Dev F1: 0.7970\n",
      "Epoch: 88, Train Loss: 0.0788, Dev Loss: 0.9718, Dev Accuracy: 0.7103, Dev Precision: 0.7774, Dev Recall: 0.7899, Dev F1: 0.7824\n",
      "Epoch: 89, Train Loss: 0.0812, Dev Loss: 0.9980, Dev Accuracy: 0.7182, Dev Precision: 0.7691, Dev Recall: 0.8219, Dev F1: 0.7936\n",
      "Epoch: 90, Train Loss: 0.0819, Dev Loss: 1.0067, Dev Accuracy: 0.7116, Dev Precision: 0.7657, Dev Recall: 0.8147, Dev F1: 0.7880\n",
      "Epoch: 91, Train Loss: 0.0820, Dev Loss: 0.9905, Dev Accuracy: 0.7104, Dev Precision: 0.7671, Dev Recall: 0.8087, Dev F1: 0.7863\n",
      "Epoch: 92, Train Loss: 0.0802, Dev Loss: 0.9903, Dev Accuracy: 0.7076, Dev Precision: 0.7727, Dev Recall: 0.7935, Dev F1: 0.7815\n",
      "Epoch: 93, Train Loss: 0.0813, Dev Loss: 1.0314, Dev Accuracy: 0.7161, Dev Precision: 0.7615, Dev Recall: 0.8337, Dev F1: 0.7947\n",
      "Epoch: 94, Train Loss: 0.0786, Dev Loss: 1.0127, Dev Accuracy: 0.7075, Dev Precision: 0.7674, Dev Recall: 0.8049, Dev F1: 0.7842\n",
      "Epoch: 95, Train Loss: 0.0720, Dev Loss: 1.0418, Dev Accuracy: 0.7183, Dev Precision: 0.7719, Dev Recall: 0.8160, Dev F1: 0.7925\n",
      "Epoch: 96, Train Loss: 0.0779, Dev Loss: 1.0392, Dev Accuracy: 0.7070, Dev Precision: 0.7670, Dev Recall: 0.8041, Dev F1: 0.7838\n",
      "Epoch: 97, Train Loss: 0.0709, Dev Loss: 1.0249, Dev Accuracy: 0.7162, Dev Precision: 0.7680, Dev Recall: 0.8210, Dev F1: 0.7924\n",
      "Epoch: 98, Train Loss: 0.0775, Dev Loss: 1.0270, Dev Accuracy: 0.7162, Dev Precision: 0.7704, Dev Recall: 0.8159, Dev F1: 0.7914\n",
      "Epoch: 99, Train Loss: 0.0855, Dev Loss: 1.0163, Dev Accuracy: 0.7150, Dev Precision: 0.7709, Dev Recall: 0.8124, Dev F1: 0.7900\n",
      "Epoch: 100, Train Loss: 0.0823, Dev Loss: 1.0168, Dev Accuracy: 0.7131, Dev Precision: 0.7736, Dev Recall: 0.8027, Dev F1: 0.7870\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:00:16.969187Z",
     "start_time": "2024-11-16T23:00:16.964661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_msr_kfold(\n",
    "    train_data: List[Dict[str, torch.Tensor]],\n",
    "    train_labels: List[int],\n",
    "    hidden_dim: int = 128,\n",
    "    num_layers: int = 1,\n",
    "    lr: float = 1e-3,\n",
    "    n_epochs: int = 10,\n",
    "    batch_size: int = 32,\n",
    "    device: str = \"cpu\",\n",
    "    verbose: bool = True,\n",
    "    k: int = 10  # Number of folds\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the model using K-fold cross-validation.\n",
    "\n",
    "    Inputs:\n",
    "    - train_data: List of dictionaries containing the embedded data for training.\n",
    "    - train_labels: List of labels for the training data.\n",
    "    - hidden_dim: Hidden dimension for the model.\n",
    "    - lr: Learning rate for the optimizer.\n",
    "    - n_epochs: Number of epochs to train the model.\n",
    "    - batch_size: Batch size for training.\n",
    "    - device: Device to run the training on.\n",
    "    - verbose: Whether to print the training progress.\n",
    "    - k: Number of folds for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    - train_losses: List of training losses for each fold.\n",
    "    - dev_metrics: List of validation metrics (loss, accuracy) for each fold.\n",
    "    \"\"\"\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    train_losses = []\n",
    "    dev_f1s = []\n",
    "\n",
    "    # K-Fold Cross Validation\n",
    "    folds = np.array_split(np.arange(len(train_data), dtype=np.int32), k)\n",
    "\n",
    "    for fold in range(k):\n",
    "        # Create validation set\n",
    "        val_idx = folds[fold]\n",
    "        dev = train_data[val_idx]\n",
    "        dev_labels_fold = train_labels[val_idx]\n",
    "    \n",
    "        # Create training set by excluding validation indices\n",
    "        train_idx = np.concatenate([folds[i] for i in range(k) if i != fold])\n",
    "        train = train_data[train_idx]\n",
    "        train_labels_fold = train_labels[train_idx]\n",
    "\n",
    "        # Initialize model\n",
    "        input_dim = train[0][\"string1\"].shape[0]\n",
    "        model = PNN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=1, hidden_layers=num_layers)\n",
    "\n",
    "        # Train model\n",
    "        train_loss, dev_metric = train_msr(\n",
    "            model, train, train_labels_fold, dev, dev_labels_fold,\n",
    "            lr=lr, n_epochs=n_epochs, batch_size=batch_size, device=device, verbose=False\n",
    "        )\n",
    "\n",
    "        # Collect metrics\n",
    "        train_losses.append(train_loss)\n",
    "        dev_f1s.append(dev_metric[-1]['f1'])\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold + 1}/{k}: Train Loss = {train_loss[-1]:.4f}, Dev Loss = {dev_metric[-1]['loss']}, Dev F1 = {dev_metric[-1]['f1']}\")\n",
    "\n",
    "    return np.mean(dev_f1s)"
   ],
   "id": "48a7e8bc7bac832d",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:18:00.888604Z",
     "start_time": "2024-11-16T23:15:52.587067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# effect of depth on the model\n",
    "\n",
    "def get_effect_of_depth_on_model():\n",
    "    hidden_dim = 1024\n",
    "    num_layers = np.arange(1, 20, 2)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for layers in tqdm(num_layers):\n",
    "        model = PNN(input_dim=768, hidden_dim=hidden_dim, output_dim=1, hidden_layers=layers)\n",
    "        train_losses, dev_metrics = train_msr(model, X_train_st, y_train, X_test_st, y_test, n_epochs=15, device=DEVICE, verbose=False)\n",
    "        f1_scores.append(dev_metrics[-1][\"f1\"])\n",
    "        \n",
    "    # plot the results\n",
    "    plt.figure()\n",
    "    plt.plot(num_layers, f1_scores, marker='o')\n",
    "    plt.xlabel(\"Number of Layers\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"Effect of Depth on Model Performance\")\n",
    "    plt.show()\n",
    "\n",
    "# get_effect_of_depth_on_model()"
   ],
   "id": "5abe1f4b5e686eef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [02:08<00:00, 12.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:36:09.935358Z",
     "start_time": "2024-11-16T23:27:49.907116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tune_hyperparams(input_type: str = \"st\"):\n",
    "    hidden_dims = [128, 256, 512, 1024, 2048]\n",
    "    num_layers = [1, 2, 3, 4]\n",
    "    lrs = np.logspace(-5, -1, 5)\n",
    "    n_epochs = np.arange(5, 20, 5)\n",
    "    batch_sizes = [32, 64, 128]\n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    \n",
    "    if input_type == \"st\":\n",
    "        train_data = X_train_st\n",
    "    else:\n",
    "        train_data = X_train_glove\n",
    "    \n",
    "    # random search for hyperparameter tuning\n",
    "    for _ in tqdm(range(30)):\n",
    "        hidden_dim = np.random.choice(hidden_dims)\n",
    "        layers = int(np.random.choice(num_layers))\n",
    "        lr = np.random.choice(lrs)\n",
    "        n_epoch = int(np.random.choice(n_epochs))\n",
    "        batch_size = int(np.random.choice(batch_sizes))\n",
    "    \n",
    "        f1 = train_msr_kfold(\n",
    "            train_data=train_data,\n",
    "            train_labels=y_train,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=layers,\n",
    "            lr=lr,\n",
    "            n_epochs=n_epoch,\n",
    "            batch_size=batch_size,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = {\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"num_layers\": layers,\n",
    "                \"lr\": lr,\n",
    "                \"n_epochs\": n_epoch,\n",
    "                \"batch_size\": batch_size\n",
    "            }\n",
    "            \n",
    "            print(f\"Best F1: {best_f1}\")\n",
    "            print(f\"Best Hyperparameters: {best_params}\")\n",
    "    \n",
    "    print(f\"Final Best F1: {best_f1}\")\n",
    "    print(f\"Final Best Hyperparameters: {best_params}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# tune_hyperparams(\"glove\")"
   ],
   "id": "ea5f37feb0732f03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:14<07:01, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.8018251283753838\n",
      "Best Hyperparameters: {'hidden_dim': 1024, 'num_layers': 3, 'lr': 0.01, 'n_epochs': 5, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:28<06:37, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.8067737284345797\n",
      "Best Hyperparameters: {'hidden_dim': 128, 'num_layers': 3, 'lr': 0.001, 'n_epochs': 5, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:51<05:07, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.8166205171607516\n",
      "Best Hyperparameters: {'hidden_dim': 512, 'num_layers': 2, 'lr': 0.0001, 'n_epochs': 10, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [08:20<00:00, 16.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Best F1: 0.8166205171607516\n",
      "Final Best Hyperparameters: {'hidden_dim': 512, 'num_layers': 2, 'lr': 0.0001, 'n_epochs': 10, 'batch_size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 512,\n",
       " 'num_layers': 2,\n",
       " 'lr': 0.0001,\n",
       " 'n_epochs': 10,\n",
       " 'batch_size': 128}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:09:49.877979Z",
     "start_time": "2024-11-21T22:09:49.498479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_with_st = PNN(input_dim=768, hidden_dim=2048, output_dim=1, hidden_layers=1)\n",
    "model_with_glove = PNN(input_dim=50, hidden_dim=512, output_dim=1, hidden_layers=2)\n",
    "_ = train_msr(\n",
    "    model_with_st, X_train_st, y_train, X_test_st, y_test,\n",
    "    lr=0.001, n_epochs=10, batch_size=128, device='cuda', verbose=True\n",
    ")\n",
    "_ = train_msr(\n",
    "    model_with_glove, X_train_glove, y_train, X_test_glove, y_test,\n",
    "    lr=0.0001, n_epochs=10, batch_size=128, device='cuda', verbose=True\n",
    ")"
   ],
   "id": "914070f3366077d9",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model_with_st \u001B[38;5;241m=\u001B[39m PNN(input_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m768\u001B[39m, hidden_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2048\u001B[39m, output_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, hidden_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      2\u001B[0m model_with_glove \u001B[38;5;241m=\u001B[39m PNN(input_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, hidden_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, output_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, hidden_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      3\u001B[0m _ \u001B[38;5;241m=\u001B[39m train_msr(\n\u001B[0;32m      4\u001B[0m     model_with_st, X_train_st, y_train, X_test_st, y_test,\n\u001B[0;32m      5\u001B[0m     lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, n_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      6\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'PNN' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:37:40.477096Z",
     "start_time": "2024-11-16T23:37:40.474090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# predict\n",
    "def predict(\n",
    "    model: PNN,\n",
    "    data: List[Dict[str, str]],\n",
    "    st_model: SentenceTransformer,\n",
    "    device: str = \"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Predicts the labels for the data.\n",
    "\n",
    "    Inputs:\n",
    "    - model: The ParaphaseNN model\n",
    "    - data_embedded: List of dictionaries containing the embedded context, question and answers for the data\n",
    "\n",
    "    Returns:\n",
    "    - List of predicted labels\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    data_embedded = st_embed_msr(data, st_model, device=device)\n",
    "    \n",
    "    for i in range(len(data_embedded)):\n",
    "        str1 = data_embedded[i][\"string1\"].to(device)\n",
    "        str2 = data_embedded[i][\"string2\"].to(device)\n",
    "        if str1.dim() == 1:\n",
    "            str1 = str1.unsqueeze(0)\n",
    "            str2 = str2.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            forward = model.forward(str1, str2)\n",
    "            pred = torch.sigmoid(forward) >= 0.5\n",
    "            preds.append(pred.item())\n",
    "    return preds"
   ],
   "id": "b75bbca6883848da",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:39:12.669174Z",
     "start_time": "2024-11-16T23:39:12.508816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "str1 = \"I saw meow at the store yesterday\"\n",
    "str2 = \"Then I'll meet Meow who will venture to the market tomorrow\"\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "\n",
    "print(predict(model_with_st, [{\"#1 String\": str1, \"#2 String\": str2}], st_model, device='cpu'))"
   ],
   "id": "1b30ccc5ad089cea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:39:35.744602Z",
     "start_time": "2024-11-16T23:39:35.734578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save model in the msr folder\n",
    "torch.save(model_with_st.state_dict(), f\"{data_dir}/msr/model_st.pth\")\n",
    "torch.save(model_with_glove.state_dict(), f\"{data_dir}/msr/model_glove.pth\")"
   ],
   "id": "c1741a986f7f4fa6",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:39:45.663897Z",
     "start_time": "2024-11-16T23:39:45.629889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the model (ST)\n",
    "model = PNN(input_dim=768, hidden_dim=2048, output_dim=1, hidden_layers=1)\n",
    "model.load_state_dict(torch.load(f\"{data_dir}/msr/model.pth\"))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_metrics = evaluate_msr(model, X_test_st, y_test, device=DEVICE)\n",
    "\n",
    "# Display test metrics\n",
    "pprint(test_metrics)"
   ],
   "id": "d6abd0157f74433b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7496798155737705,\n",
      " 'f1': 0.8201168703527429,\n",
      " 'loss': 0.7070094432149615,\n",
      " 'precision': 0.7817812044318408,\n",
      " 'recall': 0.8639975912680173}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_788624\\3395966179.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{data_dir}/msr/model.pth\"))\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:40:16.580060Z",
     "start_time": "2024-11-16T23:40:16.545413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the model (Glove)\n",
    "model = PNN(input_dim=50, hidden_dim=512, output_dim=1, hidden_layers=2)\n",
    "model.load_state_dict(torch.load(f\"{data_dir}/msr/model_glove.pth\"))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_metrics = evaluate_msr(model, X_test_glove, y_test, device=DEVICE)\n",
    "\n",
    "# Display test metrics\n",
    "pprint(test_metrics)"
   ],
   "id": "8a3b22e3908c02c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7153103044496488,\n",
      " 'f1': 0.8073136174754441,\n",
      " 'loss': 0.5555667792047773,\n",
      " 'precision': 0.7316298711272615,\n",
      " 'recall': 0.9029550515510593}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_788624\\2573642455.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{data_dir}/msr/model_glove.pth\"))\n"
     ]
    }
   ],
   "execution_count": 131
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
