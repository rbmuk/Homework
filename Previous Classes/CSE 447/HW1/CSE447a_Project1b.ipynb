{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJf9RfjKejip"
   },
   "source": [
    "# Project 1b: N-Gram Language Models\n",
    "\n",
    "Author: Kabir Ahuja\n",
    "\n",
    "Thanks to Melissa Mitchell and Khushi Khandelwal for feedback and Kavel Rao for designing the autograder.\n",
    "\n",
    "In this project, you will implement and experiment with N-gram language models. N-gram language models are simplest versions of a language model, which make a simplifying assumption that the probability of predicting a word in a sentence only depends on the past $N$ words in the sentence. In this project you will learn:\n",
    "\n",
    "- How to train word-level unigram and N-gram LMs on text data\n",
    "- Evaluating quality of an LM by computing perplexity\n",
    "- Sampling text from an N-gram LM\n",
    "- Implement Laplace Smoothing\n",
    "- Implement Interpolation for N-Gram Language Models\n",
    "\n",
    "We will be working with Shakespear Plays data from Andrej Karpathy's [blog post on Recurrent neural networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/). We also recommend going through chapter 3 of [Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/3.pdf) on N-Gram models, especially if you are not familiar with them yet."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LjZeldhSejiq",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:06.933150Z",
     "start_time": "2024-10-31T05:14:03.698562Z"
    }
   },
   "source": [
    "# Load necessary packages\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup nltk\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rohan\n",
      "[nltk_data]     Mukherjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Rohan\n",
      "[nltk_data]     Mukherjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# !wget https://homes.cs.washington.edu/~kahuja/cse447/project1/data.zip -O data.zip\n",
    "# !unzip -o data.zip\n",
    "\n",
    "# Set data directory. Important: DO NOT CHANGE THIS. AUTOGRADER WILL FAIL ON YOUR SUBMISSION OTHERWISE\n",
    "parent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "data_dir = os.path.join(parent_dir, \"data\")"
   ],
   "metadata": {
    "id": "mKmoJnGnenm4",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:06.964449Z",
     "start_time": "2024-10-31T05:14:06.961867Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Gy2szV-ejir",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.054114Z",
     "start_time": "2024-10-31T05:14:07.051001Z"
    }
   },
   "source": [
    "# Helper functions for sample test cases\n",
    "\n",
    "def evaluate_test_case(input, output, expected_output, output_str = \"Output\", atol=1e-4) -> Dict:\n",
    "    if input is not None:\n",
    "        print(\"Input:\\n\", input)\n",
    "    print(f\"{output_str}:\\n\", output)\n",
    "    print(f\"Expected {output_str}:\\n\", expected_output)\n",
    "\n",
    "    match = (\n",
    "        output == expected_output\n",
    "        if type(output) == str\n",
    "        else np.allclose(output, expected_output, atol=atol)\n",
    "    )\n",
    "\n",
    "    if match:\n",
    "        print(\"Test case passed! :)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Test case failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "def evaluate_list_test_case(input: List, output: List, expected_output: List) -> Dict:\n",
    "\n",
    "    print(\"Input:\\n\", input)\n",
    "    print(\"Output:\\n\", output)\n",
    "    print(\"Expected output:\\n\", expected_output)\n",
    "    if output == expected_output:\n",
    "        print(\"Test case passed! :)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Test case failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Aann01eejir"
   },
   "source": [
    "## Part 1: Word-level unigram language models (11 points)\n",
    "\n",
    "We will start by considering word-level language models i.e. language models where the smallest unit (or a unigram) that can be predicted by the model is a word. In part 1, we will implement unigram language models, which constitutes the simplest variant of N-gram models -- simply learn the distribution of each unigram (here a word) in the corpus. Recall from the lectures, that for a text sequence with unigrams $w_1, w_2, \\cdots, w_n$, unigram language models, the probability of the sequence is given as:\n",
    "\n",
    "$$P(w_1, w_2, \\cdots, w_n) =P(w_1)P(w_2)\\cdots P(w_n)$$\n",
    "\n",
    "where $P(w_i)$ is simply the frequency of the word $w_i$ in the training corpus.\n",
    "\n",
    "For this part we will work with the Shakespear dataset. Let's start by loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hbfkB-f3ejis",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.063691Z",
     "start_time": "2024-10-31T05:14:07.058644Z"
    }
   },
   "source": [
    "with open(f\"{data_dir}/shakespear_train.txt\") as f:\n",
    "    train_data = f.read().split(\"\\n\")\n",
    "\n",
    "with open(f\"{data_dir}/shakespear_dev.txt\") as f:\n",
    "    dev_data = f.read().split(\"\\n\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-LtACiiejis"
   },
   "source": [
    "Below we print first 10 sentences from the training data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3IVqmDauejis",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.078946Z",
     "start_time": "2024-10-31T05:14:07.076821Z"
    }
   },
   "source": "print(\"\\n\".join(train_data[:10]))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen : Before we proceed any further , hear me speak .\n",
      "All : Speak , speak .\n",
      "First Citizen : You are all resolved rather to die than to famish ?\n",
      "All : Resolved .\n",
      "resolved .\n",
      "First Citizen : First , you know Caius Marcius is chief enemy to the people .\n",
      "All : We know't , we know't .\n",
      "First Citizen : Let us kill him , and we 'll have corn at our own price .\n",
      "Is't a verdict ?\n",
      "All : No more talking o n't ; let it be done : away , away !\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT2nlEC-ejis"
   },
   "source": [
    "### Exercise 1.0 Text Processing\n",
    "\n",
    "Before start training our models, let's perform some basic preprocessing. For this exercise, we only want to put an \\<eos\\> tag at the end of each sentence in the training and dev sets. Implement `add_eos` function below that does that."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "567c963b4937319d6cb1aa91140c8315",
     "grade": false,
     "grade_id": "cell-83e8a74c3faf2ec2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "ERy9v-Tcejis",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.160892Z",
     "start_time": "2024-10-31T05:14:07.158106Z"
    }
   },
   "source": [
    "def add_eos(data: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Adds an <eos> token to the end of each line in the data.\n",
    "\n",
    "    Inputs:\n",
    "    - data: a list of strings where each string is a line of text\n",
    "\n",
    "    Returns:\n",
    "    - a list of strings where each string is a line of text with <eos> token appended\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return [line + \" <eos>\" for line in data]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0AyzsPaXejis",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.211745Z",
     "start_time": "2024-10-31T05:14:07.208737Z"
    }
   },
   "source": [
    "def test_add_eos():\n",
    "    print(\"Running Sample Test Case 1\")\n",
    "    data = [\"hello!\", \"world!\"]\n",
    "\n",
    "    evaluate_list_test_case(data, add_eos(data), [\"hello! <eos>\", \"world! <eos>\"])\n",
    "\n",
    "    print(\"Running Sample Test Case 2\")\n",
    "    data = [\n",
    "        \"Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .\",\n",
    "        \"At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .\",\n",
    "        \"The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .\" ]\n",
    "\n",
    "    expected_output = [\n",
    "        \"Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice . <eos>\",\n",
    "        \"At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs . <eos>\",\n",
    "        \"The world was so recent that many things lacked names, and in order to indicate them it was necessary to point . <eos>\"]\n",
    "    evaluate_list_test_case(data, add_eos(data), expected_output)\n",
    "\n",
    "test_add_eos()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sample Test Case 1\n",
      "Input:\n",
      " ['hello!', 'world!']\n",
      "Output:\n",
      " ['hello! <eos>', 'world! <eos>']\n",
      "Expected output:\n",
      " ['hello! <eos>', 'world! <eos>']\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 2\n",
      "Input:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Output:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice . <eos>', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs . <eos>', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point . <eos>']\n",
      "Expected output:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice . <eos>', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs . <eos>', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point . <eos>']\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4azJ73t3ejit",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.245888Z",
     "start_time": "2024-10-31T05:14:07.242781Z"
    }
   },
   "source": [
    "train_data_processed = add_eos(train_data)\n",
    "dev_data_processed = add_eos(dev_data)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp6eGbpnejit"
   },
   "source": [
    "### Exercise 1.1: Training (word-level) Unigram Language Model (2 Points)\n",
    "\n",
    "Training a unigram model simply corresponds to calculating frequencies of each word in the corpus, i.e.\n",
    "\n",
    "$$p(w_i) = \\frac{C(w_i)}{n}$$\n",
    "\n",
    "where $C(w_i)$ is the count of word $w_i$ in the training data and $n$ is the total number of words in the training dataset.\n",
    "\n",
    "Implement the `train_word_unigram` function below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77dcf20f8be686508635ed1f65dcd0e7",
     "grade": false,
     "grade_id": "cell-8ae19fe766eed890",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "jn8D65OMejit",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.276718Z",
     "start_time": "2024-10-31T05:14:07.273203Z"
    }
   },
   "source": [
    "def train_word_unigram(train_data: List[str]) -> Dict[str, float]:\n",
    "\n",
    "    \"\"\"\n",
    "    Trains a word-level unigram language model.\n",
    "\n",
    "    Inputs:\n",
    "        - train_data: List[str], list of sentences in training data\n",
    "\n",
    "    Outputs:\n",
    "        - Dict[str, float], a dictionary mapping words to their unigram probabilities\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    unigram_probs = nltk.FreqDist([word for line in train_data for word in line.split()])\n",
    "    total_words = sum(unigram_probs.values())\n",
    "    for word in unigram_probs:\n",
    "        unigram_probs[word] /= total_words\n",
    "\n",
    "    return unigram_probs"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vzx0rzOKejit",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.347146Z",
     "start_time": "2024-10-31T05:14:07.280919Z"
    }
   },
   "source": [
    "unigram_probs = train_word_unigram(train_data_processed)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbe516c204fe52ea1a235010e9d2d316",
     "grade": true,
     "grade_id": "cell-f3e22e1c9dfc5a64",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "id": "5n3qbA7xejiu",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.364301Z",
     "start_time": "2024-10-31T05:14:07.360754Z"
    }
   },
   "source": [
    "# Sample test cases\n",
    "def test_train_word_unigram(unigram_probs):\n",
    "\n",
    "    print(\"Running Sample Test Case 1: Check if the number of unique words is correct\")\n",
    "    evaluate_test_case(None, len(unigram_probs), 12610, output_str=\"Number of unique words\")\n",
    "\n",
    "    print(\"Running Sample Test Case 2: Check if the probability of word \\\"thou\\\" is correct\")\n",
    "    evaluate_test_case(\"thou\", unigram_probs[\"thou\"], 0.004559649641510829)\n",
    "\n",
    "    print(\"Running Sample Test Case 3: Check if the probability of word \\\"love\\\" is correct\")\n",
    "    evaluate_test_case(\"love\", unigram_probs[\"love\"], 0.0015984182127282134)\n",
    "\n",
    "    print(\"Running Sample Test Case 4: Check if the probability of word \\\"Richard\\\" is correct\")\n",
    "    evaluate_test_case(\"Richard\", unigram_probs[\"Richard\"], 0.0005035479340675586)\n",
    "\n",
    "    print(\"Running Sample Test Case 5: Check if the probability of word \\\"pytorch\\\" is correct\")\n",
    "    evaluate_test_case(\"pytorch\", unigram_probs.get(\"pytorch\", 0), 0)\n",
    "\n",
    "    print(\"Running Sample Test Case 6: Check if the probability of word \\\"richard\\\" is correct\")\n",
    "    evaluate_test_case(\"richard\", unigram_probs.get(\"richard\", 0), 0)\n",
    "\n",
    "\n",
    "test_train_word_unigram(unigram_probs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sample Test Case 1: Check if the number of unique words is correct\n",
      "Number of unique words:\n",
      " 12610\n",
      "Expected Number of unique words:\n",
      " 12610\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 2: Check if the probability of word \"thou\" is correct\n",
      "Input:\n",
      " thou\n",
      "Output:\n",
      " 0.004559649641510829\n",
      "Expected Output:\n",
      " 0.004559649641510829\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 3: Check if the probability of word \"love\" is correct\n",
      "Input:\n",
      " love\n",
      "Output:\n",
      " 0.0015984182127282134\n",
      "Expected Output:\n",
      " 0.0015984182127282134\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 4: Check if the probability of word \"Richard\" is correct\n",
      "Input:\n",
      " Richard\n",
      "Output:\n",
      " 0.0005035479340675586\n",
      "Expected Output:\n",
      " 0.0005035479340675586\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 5: Check if the probability of word \"pytorch\" is correct\n",
      "Input:\n",
      " pytorch\n",
      "Output:\n",
      " 0\n",
      "Expected Output:\n",
      " 0\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 6: Check if the probability of word \"richard\" is correct\n",
      "Input:\n",
      " richard\n",
      "Output:\n",
      " 0\n",
      "Expected Output:\n",
      " 0\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4WePCJhejiu"
   },
   "source": [
    "### Exercise 1.2: Evaluating (word-level) Unigram Language Models using Perplexity (2 Points)\n",
    "\n",
    "Now that we have trained our first (albeit very basic) language model, our next job is to evaluate how good of a job it does in modeling the training text as well as generalizing on the unseen text. The most commonly used metric for evaluating the quality of a language model is Perplexity. Recall from the lecture, perplexity of a language model on a test dataset measures the (inverse) probability assigned by the language model to the test dataset normalized by the number of words (or tokens). Lower the perplexity the higher probability the model assigns to the text in the test dataset and hence better quality.\n",
    "\n",
    "$$\\text{perplexity}(W) = P(w_1w_2\\cdots w_n)^{\\frac{-1}{n}} = \\sqrt[n]{\\frac{1}{P(w_1w_2\\cdots w_n)}}$$\n",
    "\n",
    "where $W$ is a test set with $n$ words $w_1w_2\\cdots w_n$\n",
    "\n",
    "It is useful to do perplexity calculation in log space to avoid numerical issues\n",
    "\n",
    "$$\\text{perplexity}(W) = \\exp\\bigl(-\\frac{\\log{P(w_1w_2\\cdots w_n)}}{n}\\bigr)$$\n",
    "\n",
    "When we have multiple sentences in the corpus and we assume sentences to be independent, we can write:\n",
    "\n",
    "$$\\text{perplexity}(W) = \\exp\\bigl(-\\frac{ \\sum_{S \\in W}  \\log{P(s_1s_2\\cdots s_{n_s})}}{n}\\bigr)$$\n",
    "\n",
    "where $S$ is a sentence in the corpus $W$ with words $s_1 s_2 \\cdots s_{n_s}$ and $n_s$ is the number of words in $S$.\n",
    "\n",
    "Note that assuming sentences to be independent is something that is not actually true in practice. However, since N-gram language models are already limited in their context, it is not the greatest loss to remove dependencies between sentences. In the future homeworks we will be dropping this assumption as we build more powerful models.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fb1e8b5c673c0ef7f7ec715b8d284a6",
     "grade": false,
     "grade_id": "cell-669e5cc008545af9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "xBq6Spkyejiu",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.413115Z",
     "start_time": "2024-10-31T05:14:07.410295Z"
    }
   },
   "source": [
    "def eval_ppl_word_unigram(eval_data: List[str], unigram_probs: Dict[str, float]) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluates the perplexity of a word-level unigram language model on the dev set.\n",
    "\n",
    "    Inputs:\n",
    "        - dev_data: List[str], list of sentences in the evaluation data\n",
    "        - unigram_probs: Dict[str, float], a dictionary mapping words to their unigram probabilities\n",
    "\n",
    "    Outputs:\n",
    "        - float, the perplexity of the unigram language model on the evaluation set\n",
    "\n",
    "    Note 1: It is useful to do the calculations in log space and convert the final answer to original space to\n",
    "    avoid numerical issues .\n",
    "    Note 2: Assign 0 probability to words that are not in the unigram_probs dictionary, since those words were not seen during training.\n",
    "    \"\"\"\n",
    "\n",
    "    perplexity = 0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for line in eval_data:\n",
    "        for word in line.split():\n",
    "            perplexity += np.log(unigram_probs.get(word, 0))\n",
    "    \n",
    "    return np.exp(-perplexity / sum(len(line.split()) for line in eval_data))"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuzxPRaXejiu"
   },
   "source": [
    "First let's compute the perplexity of training data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FEeLsluGejiu",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.585361Z",
     "start_time": "2024-10-31T05:14:07.446054Z"
    }
   },
   "source": [
    "train_ppl = eval_ppl_word_unigram(train_data_processed, unigram_probs)\n",
    "print(train_ppl)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575.1110328373742\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZwKVP-ejiu"
   },
   "source": [
    "You should expect a perplexity around 575 on the training data. Now let's evaluate on dev data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TrceEF7Zejiu",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.629258Z",
     "start_time": "2024-10-31T05:14:07.607834Z"
    }
   },
   "source": [
    "dev_ppl = eval_ppl_word_unigram(dev_data_processed, unigram_probs)\n",
    "print(dev_ppl)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_485528\\1573223851.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "  perplexity += np.log(unigram_probs.get(word, 0))\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqfR-3Kkejiu"
   },
   "source": [
    "You should see a RuntimeWarning: divide by zero and a perplexity of infinity in this case. Why did this happen? Because we have some words in the dev dataset, which were never seen during training. The unigram model assigns a zero probability to those, which result in an infinite perplexity (inverse probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZmPFCGVejiu"
   },
   "source": [
    "### Exercise 1.3: Handling Unknown Words (2 Points)\n",
    "\n",
    "How do we deal with such situations? An easy solution is to introduce an unknown word token, e.g. \\<unk\\>. Before training, we replace the words which occur less than a threshold number of times with an \\<unk\\> token. E.g., if a word occurs less than 3 times in the dataset, we replace it with the \\<unk\\> token. At test time, when evaluating the perplexity if we see a word, which was unseen during training i.e. has a unigram frequency of 0, we assign that word the probability of \\<unk\\> token.\n",
    "\n",
    "Implement the `replace_rare_words_wth_unks` function below which replaces words which occur less than `unk_thresh` number of times by \\<unk\\> token. Also reimplement `eval_ppl_word_unigram` to handle unseen words. You might find the [`Counter` class from the `collections` module useful](https://docs.python.org/3/library/collections.html#counter-objects)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fab38469df7969a85c849c6aecb21cf",
     "grade": false,
     "grade_id": "cell-7335b83debed50b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "jfozoQBaejiu",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:07.682733Z",
     "start_time": "2024-10-31T05:14:07.678815Z"
    }
   },
   "source": [
    "def replace_rare_words_wth_unks(train_data: List[str], unk_thresh: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Replaces words that occur less than unk_thresh times in the training data with \"<unk>\" token.\n",
    "\n",
    "    Inputs:\n",
    "        - train_data: List[str], list of sentences in the training data\n",
    "        - unk_thresh: int, the threshold on the number of occurrences of a word to be considered known (less than considered <unk>)\n",
    "\n",
    "    Outputs:\n",
    "        - List[str], the training text with rare words replaced by \"<unk>\" token\n",
    "    \"\"\"\n",
    "\n",
    "    word_freq = nltk.FreqDist([word for line in train_data for word in line.split()])\n",
    "    \n",
    "    train_data_unked = [\" \".join(\"<unk>\" if word_freq[word] < unk_thresh else word for word in line.split()) for line in train_data]\n",
    "\n",
    "    return train_data_unked"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mRRc44Prejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.048535Z",
     "start_time": "2024-10-31T05:14:07.721921Z"
    }
   },
   "source": [
    "# Sample test cases\n",
    "def test_train_word_unigram_wth_unks():\n",
    "\n",
    "    print(\"# Testing for Threshold 3\\n\\n\")\n",
    "    train_data_wth_unks = replace_rare_words_wth_unks(train_data_processed, 3)\n",
    "    unigram_probs_wth_unks = train_word_unigram(train_data_wth_unks)\n",
    "    print(\"Sample Test Case 1: Check if the number of unique words is correct\")\n",
    "    evaluate_test_case(None, len(unigram_probs_wth_unks), 4620, output_str=\"Number of unique words\")\n",
    "\n",
    "    print(\"Sample Test Case 2: Check if the probability of word \\\"<unk>\\\" is correct\")\n",
    "    evaluate_test_case(\"<unk>\", unigram_probs_wth_unks[\"<unk>\"], 0.045185342597383396)\n",
    "\n",
    "    print(\"# Testing for threshold 5\\n\\n\")\n",
    "    train_data_wth_unks = replace_rare_words_wth_unks(train_data_processed, 5)\n",
    "    unigram_probs_wth_unks = train_word_unigram(train_data_wth_unks)\n",
    "    print(\"Sample Test Case 3: Check if the number of unique words is correct\")\n",
    "    evaluate_test_case(None, len(unigram_probs_wth_unks), 3088, output_str=\"Number of unique words\")\n",
    "\n",
    "    print(\"Sample Test Case 4: Check if the probability of word \\\"<unk>\\\" is correct\")\n",
    "    evaluate_test_case(\"<unk>\", unigram_probs_wth_unks[\"<unk>\"], 0.06910155961268387)\n",
    "\n",
    "test_train_word_unigram_wth_unks()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Testing for Threshold 3\n",
      "\n",
      "\n",
      "Sample Test Case 1: Check if the number of unique words is correct\n",
      "Number of unique words:\n",
      " 4620\n",
      "Expected Number of unique words:\n",
      " 4620\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sample Test Case 2: Check if the probability of word \"<unk>\" is correct\n",
      "Input:\n",
      " <unk>\n",
      "Output:\n",
      " 0.045185342597383396\n",
      "Expected Output:\n",
      " 0.045185342597383396\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "# Testing for threshold 5\n",
      "\n",
      "\n",
      "Sample Test Case 3: Check if the number of unique words is correct\n",
      "Number of unique words:\n",
      " 3088\n",
      "Expected Number of unique words:\n",
      " 3088\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sample Test Case 4: Check if the probability of word \"<unk>\" is correct\n",
      "Input:\n",
      " <unk>\n",
      "Output:\n",
      " 0.06910155961268387\n",
      "Expected Output:\n",
      " 0.06910155961268387\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Ullwfehejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.209990Z",
     "start_time": "2024-10-31T05:14:08.055983Z"
    }
   },
   "source": [
    "# We will remove words that occur less than 3 times\n",
    "train_data_wth_unks = replace_rare_words_wth_unks(train_data_processed, 10)\n",
    "unigram_probs_wth_unks = train_word_unigram(train_data_wth_unks)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFcq_WbWejiv"
   },
   "source": [
    "We recommend you to check the unigram probabilities before and after replacing rare words with \\<unk\\> token to verify your implementation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d77bde66108370572d9eea31ee499752",
     "grade": false,
     "grade_id": "cell-7c1a766eb312e9ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "SmgnSOXdejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.218804Z",
     "start_time": "2024-10-31T05:14:08.215672Z"
    }
   },
   "source": [
    "def eval_ppl_word_unigram_wth_unks(eval_data: List[str], unigram_probs_wth_unks: Dict[str, float]) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluates the perplexity of a word-level unigram language model on the dev set. For unseen words, uses the <unk> token probability.\n",
    "\n",
    "    Inputs:\n",
    "        - eval_data: string, List of sentences in eval data\n",
    "        - unigram_probs_wth_unks: Dict[str, float], a dictionary mapping words to their unigram probabilities, including <unk> token\n",
    "\n",
    "    Outputs:\n",
    "        - float, the perplexity of the unigram language model on the evaluation set\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    perplexity = 0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for line in eval_data:\n",
    "        for word in line.split():\n",
    "            perplexity += np.log(unigram_probs_wth_unks.get(word, unigram_probs_wth_unks[\"<unk>\"]))\n",
    "\n",
    "    return np.exp(-perplexity / sum(len(line.split()) for line in eval_data))"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcLm7vWbejiv"
   },
   "source": [
    "Let's compute the train and dev perplexity now"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mwsbrEKNejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.399783Z",
     "start_time": "2024-10-31T05:14:08.228702Z"
    }
   },
   "source": [
    "train_ppl = eval_ppl_word_unigram_wth_unks(train_data_wth_unks, unigram_probs_wth_unks)\n",
    "print(f\"Train Perplexity: {train_ppl}\")\n",
    "dev_ppl = eval_ppl_word_unigram_wth_unks(dev_data_processed, unigram_probs_wth_unks)\n",
    "print(f\"Dev Perplexity: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity: 216.08200416605456\n",
      "Dev Perplexity: 167.3194142699338\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mibA-NRsejiv"
   },
   "source": [
    "You should observe a train perplexity around 384 and dev perplexity around 282."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "766OWdu4ejiv"
   },
   "source": [
    "### Exercise 1.4: Sampling from Unigram Language Model (2 Points)\n",
    "\n",
    "Now that we have trained and evaluated our unigram LM, we are ready to generate some text from it. To sample text from an N-gram language model given prefix words $w_1, w_2, \\cdots, w_n$, we sequentially sample next tokens from the N-gram probability distribution given the previous words, i.e.,\n",
    "\n",
    "$$w_{n+1} \\sim P(w_{n+1} | w_{1}, \\cdots, w_{n} )$$\n",
    "\n",
    "For a unigram language model, since $P(w_1, \\dots, w_n) = P(w_1)\\cdots P(w_n)$ i.e. all words all distributed independently and the next token is sampled independent of previous tokens, the above equation simplifies to:\n",
    "\n",
    "$$w_{n+1} \\sim P(w_{n+1})$$\n",
    "\n",
    "You will now implement the function `sample_from_word_unigram` below. You might find the [Numpy's random module (np.random)](https://numpy.org/doc/stable/reference/random/index.html) useful."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3df1ccda6ea9c610f2b4ea609f7222e9",
     "grade": false,
     "grade_id": "cell-08f4a7dd328533c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "aYecrpWfejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.430948Z",
     "start_time": "2024-10-31T05:14:08.427584Z"
    }
   },
   "source": [
    "def sample_from_word_unigram(unigram_probs: Dict[str, float], max_words: int, prefix: str = \"\") -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Samples sequence of words from a unigram language model.\n",
    "    Terminate sampling when either max_words is reached or when <eos> token is sampled.\n",
    "\n",
    "    Inputs:\n",
    "        - unigram_probs: Dict[str, float], a dictionary mapping words to their unigram probabilities\n",
    "        - n_words: int, the number of words to sample\n",
    "        - prefix: str, a prefix to start the sampling from. Can have multiple words separated by spaces.\n",
    "\n",
    "    Outputs:\n",
    "        - str: sampled text i.e. string of sampled words separated by spaces along with the prefix\n",
    "\n",
    "    # Note: Please use np.random.choice to sample from the unigram_probs dictionary.\n",
    "    \"\"\"\n",
    "    sampled_string = \"\"\n",
    "    # YOUR CODE HERE\n",
    "    for _ in range(max_words):\n",
    "        sample = np.random.choice(list(unigram_probs.keys()), p=list(unigram_probs.values()), replace=False)\n",
    "        sampled_string += sample + \" \"\n",
    "        if sample == '<eos>':\n",
    "            break\n",
    "\n",
    "    return prefix + \" \" + sampled_string"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6vce5Flaejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.697414Z",
     "start_time": "2024-10-31T05:14:08.454878Z"
    }
   },
   "source": [
    "# Sample test cases\n",
    "def test_sample_from_word_unigram():\n",
    "\n",
    "    np.random.seed(0)\n",
    "    sampled_string = sample_from_word_unigram(unigram_probs_wth_unks, 10, \"The king\")\n",
    "    print(\"Running Test Case 1: Check if the sampled string starts with the prefix\")\n",
    "    evaluate_test_case(None, sampled_string.startswith(\"The king\"), True, output_str=\"Sampled string starts with the prefix\")\n",
    "\n",
    "    print(\"Running Test Case 2: Check if the sampled string has either 10 generated words or ends with <eos> token\")\n",
    "    print(f\"Generated string: {sampled_string}\")\n",
    "    print(f\"Number of generated words: {len(sampled_string.split()) - 2}\")\n",
    "    print(f\"Does the generated string end with <eos> token: {'<eos>' in sampled_string}\")\n",
    "    if len(sampled_string.split()) - 2 == 10 or (\n",
    "        len(sampled_string.split()) - 2 < 10 and \"<eos>\" in sampled_string\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Running Test Case 3: Check if the probability of generating <unk> token is correct\")\n",
    "\n",
    "    sampled_strings = [\n",
    "        sample_from_word_unigram(unigram_probs_wth_unks, 1, \"\")\n",
    "        for _ in range(1000)\n",
    "    ]\n",
    "    sampled_string = \" \".join(sampled_strings)\n",
    "    num_unks = sampled_string.count(\"<unk>\")\n",
    "    unk_gen_prob = num_unks / len(sampled_string.split())\n",
    "    evaluate_test_case(None, unk_gen_prob, unigram_probs_wth_unks[\"<unk>\"], output_str=\"Probability of generating <unk> token\", atol=1e-2)\n",
    "\n",
    "test_sample_from_word_unigram()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test Case 1: Check if the sampled string starts with the prefix\n",
      "Sampled string starts with the prefix:\n",
      " True\n",
      "Expected Sampled string starts with the prefix:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Test Case 2: Check if the sampled string has either 10 generated words or ends with <eos> token\n",
      "Generated string: The king I That was I a go ; brother deposed us \n",
      "Number of generated words: 10\n",
      "Does the generated string end with <eos> token: False\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Test Case 3: Check if the probability of generating <unk> token is correct\n",
      "Probability of generating <unk> token:\n",
      " 0.121\n",
      "Expected Probability of generating <unk> token:\n",
      " 0.10872477640623845\n",
      "Test case failed! :(\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDH2cPmxejiv"
   },
   "source": [
    "Note that due to the randomness in sampling, it is difficult to automatically test this function. However, you can use the technique we use in sample test case 3 by repeatedly sampling from the unigram model and checking the frequency of different words in the generated text and checking if they are close to the unigram probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQzlYLLTejiv"
   },
   "source": [
    "Let's sample some text from the unigram model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-k1p_c8Oejiv",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.738637Z",
     "start_time": "2024-10-31T05:14:08.715724Z"
    }
   },
   "source": [
    "for _ in range(5):\n",
    "    sampled_string = sample_from_word_unigram(unigram_probs_wth_unks, 20)\n",
    "    print(sampled_string)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what , <unk> ! : at that <unk> his once <unk> stay my Clarence makes child that <eos> \n",
      " Hermione . on , slain dream see you <unk> <unk> . with . to one answer : ; do part \n",
      " if KING <unk> : might <unk> meet <unk> <unk> greater That in off a : : an , , CATESBY \n",
      " farewell . First queen <unk> <eos> \n",
      " there , <unk> PRINCE my this and thee . KING Within ' , To precious with is me out note \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43Lxt3h9ejiw"
   },
   "source": [
    "You should see that the generated that doesn't make a whole lot of sense, which is natural since we are using a unigram model that doesn't account for the context at all, and essentially samples the most common tokens in its generations. We will now move to build language models that do not have this problem, i.e., they take into account the context (albeit to different degrees) for modeling the distribution of words (or tokens) in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1-uZfAqejiw"
   },
   "source": [
    "## Part 2: N(>1)-Gram Word-Level Language Models (12 Points)\n",
    "\n",
    "We will now implement much more sophisticated language models, which make use of the surrounding text to model the distribution of text. Recall from the lectures for an $N$-gram language model with $n > 1$, the distribution of a sequence of tokens $w_1, w_2, \\cdots, w_n$ is given as:\n",
    "\n",
    "$$P(w_1, w_2, \\cdots, w_n) = \\prod_{k=1}^{n}P(w_k \\mid w_{k-N-1}, \\cdots, w_{k-1})$$\n",
    "\n",
    "E.g., for a bigram model i.e. $N = 2$, the expression becomes:\n",
    "\n",
    "$$P(w_1, w_2, \\cdots, w_n) = \\prod_{k=1}^{n}P(w_k \\mid w_{k-1})$$\n",
    "\n",
    "i.e. the distribution of a token depends solely on the past $N-1$ tokens in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gcMLJ8x-ejiw",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.794089Z",
     "start_time": "2024-10-31T05:14:08.792103Z"
    }
   },
   "source": [
    "# Before we start, lets set training data to be the one with <unk> tokens and dev data to be the one with <eos> tokens in the end\n",
    "\n",
    "train_data = train_data_wth_unks\n",
    "dev_data = dev_data_processed"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bop8Iu1Dejiw"
   },
   "source": [
    "### Exercise 2.1: Text Processing\n",
    "\n",
    "A careful reader must have noted that the above expression: $P(w_1, w_2, \\cdots, w_n) = \\prod_{k=1}^{n}P(w_k \\mid w_{k-1})$ has a problem. On the right hand side, when $k = 1$, this will result in the term $P(w_1 | w_0)$, but there is no $w_0$ in the sequence. Similarly, for a trigram language model we will have terms, $P(w_1 | w_{-1}, w_{0})$ and $P(w_2 | w_0, w_1)$ with conditionals on words that are not part of the sequence. To handle this issue, we add $N-1$ start of sequence tokens, e.g. \\<sos\\> to the beginning of the sequence.\n",
    "\n",
    "Implement `process_text_for_Ngram` function below that adds $N-1$ \\<sos\\> tokens to beginning of each sentence in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff450790d0053d8d5f1bdc110dddece4",
     "grade": false,
     "grade_id": "cell-2228a409c358fa6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "7Z01HXa5ejiw",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.803688Z",
     "start_time": "2024-10-31T05:14:08.800801Z"
    }
   },
   "source": [
    "def process_text_for_Ngram(sents: List[str], N: int = 2) -> List[str]:\n",
    "\n",
    "    \"\"\"\n",
    "    Adds N-1 <sos> tokens to the start of every sentence in the text.\n",
    "\n",
    "    Inputs:\n",
    "        - sents: List[str], List of sentences\n",
    "        - N: int, the N in N-gram\n",
    "\n",
    "    Outputs:\n",
    "        - List[str], the processed text\n",
    "    \"\"\"\n",
    "    processed_sents = [\"<sos> \" * (N-1) + line for line in sents]\n",
    "\n",
    "    return processed_sents"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gJACPGMzejiw",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.829044Z",
     "start_time": "2024-10-31T05:14:08.825011Z"
    }
   },
   "source": [
    "# Sample test cases\n",
    "\n",
    "def test_process_text_for_Ngram():\n",
    "\n",
    "    sents = [\"Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .\",\n",
    "    \"At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .\",\n",
    "    \"The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .\" ]\n",
    "\n",
    "    print(\"Running Sample Test Case 1 with N=1\")\n",
    "    unigram_processed_text = process_text_for_Ngram(sents, 1)\n",
    "    excepted_output = [\n",
    "        \"Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .\",\n",
    "        \"At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .\",\n",
    "        \"The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .\"\n",
    "    ]\n",
    "    evaluate_list_test_case(sents, unigram_processed_text, excepted_output)\n",
    "\n",
    "    print(\"Running Sample Test Case 2 with N=2\")\n",
    "    bigram_processed_text = process_text_for_Ngram(sents, 2)\n",
    "    excepted_output = [\n",
    "        \"<sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .\",\n",
    "        \"<sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .\",\n",
    "        \"<sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .\"\n",
    "    ]\n",
    "    evaluate_list_test_case(sents, bigram_processed_text, excepted_output)\n",
    "\n",
    "    print(\"Running Sample Test Case 3 with N=3\")\n",
    "    trigram_processed_text = process_text_for_Ngram(sents, 3)\n",
    "    excepted_output = [\n",
    "        \"<sos> <sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .\",\n",
    "        \"<sos> <sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .\",\n",
    "        \"<sos> <sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .\"\n",
    "    ]\n",
    "    evaluate_list_test_case(sents, trigram_processed_text, excepted_output)\n",
    "\n",
    "    print(\"Running Sample Test Case 4 with N=4\")\n",
    "    fourgram_processed_text = process_text_for_Ngram(sents, 4)\n",
    "    excepted_output = [\n",
    "        \"<sos> <sos> <sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .\",\n",
    "        \"<sos> <sos> <sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .\",\n",
    "        \"<sos> <sos> <sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .\"\n",
    "    ]\n",
    "    evaluate_list_test_case(sents, fourgram_processed_text, excepted_output)\n",
    "\n",
    "test_process_text_for_Ngram()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sample Test Case 1 with N=1\n",
      "Input:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Output:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Expected output:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 2 with N=2\n",
      "Input:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Output:\n",
      " ['<sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', '<sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', '<sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Expected output:\n",
      " ['<sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', '<sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', '<sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 3 with N=3\n",
      "Input:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Output:\n",
      " ['<sos> <sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', '<sos> <sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', '<sos> <sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Expected output:\n",
      " ['<sos> <sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', '<sos> <sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', '<sos> <sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running Sample Test Case 4 with N=4\n",
      "Input:\n",
      " ['Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', 'At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', 'The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Output:\n",
      " ['<sos> <sos> <sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', '<sos> <sos> <sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', '<sos> <sos> <sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Expected output:\n",
      " ['<sos> <sos> <sos> Many years later , as he faced the firing squad , Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice .', '<sos> <sos> <sos> At that time Macondo was a village of twenty adobe houses, built on the bank of a river of clear water that ran along a bed of polished stones, which were white and enormous, like prehistoric eggs .', '<sos> <sos> <sos> The world was so recent that many things lacked names, and in order to indicate them it was necessary to point .']\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3M1Y7RDSejiw"
   },
   "source": [
    "### Exercise 2.2: Implementing N-gram language models (10 Points)\n",
    "\n",
    "The heart of implementing an N-gram language model is to estimate the conditional distributions $P(w_n \\mid w_{n-N-1}, \\cdots, w_{n-1})$. Recall from the lectures that the conditional distributions can be estimated as:\n",
    "\n",
    "$$P(w_n \\mid w_{n-N-1}, \\cdots, w_{n-1}) = \\frac{C(w_{n-N-1} \\cdots w_{n-1} w_{n})}{\\sum_{w \\in W}{C(w_{n-N-1} \\cdots w_{n-1} w)}} = \\frac{C(w_{n-N-1} \\cdots w_{n-1} w_{n})}{{C(w_{n-N-1} \\cdots w_{n-1})}}$$\n",
    "\n",
    "where $C(w_{n-N-1} \\cdots w_{n-1} w)$ is the number of times the token sequence $w_{n-N-1} \\cdots w_{n-1} w$ appears in the corpus, and $W$ is the vocabulary of the N-gram model.\n",
    "\n",
    "You will now implement an N-gram language model from scratch. Note that a full implementation involves a `fit` function, which computes the N-gram counts $C(w_{n-N-1} \\cdots w_{n-1} w)$ needed to compute the conditional distributions; `eval_perplexity` function, which evaluates the perplexity of the language model on a test set; and a `sample_text` function which generates the text from the LM. Implement the class `WordNGramLM` below with these functions.This time we leave all the implementation details for you to decide. We just provide a boiler plate code, with the expected input output for the three functions in the class. You might need to implement additional functions for your implementation of the three functions.\n",
    "\n",
    "**Note 1**: If implementing a general NGram Model from scratch seems too daunting, we recommend starting implementing just the Bigram LM and checking if you are able to pass BigramLM Test cases. From there you can work on generalizing your solution.\n",
    "\n",
    "**Note 2**: Efficiency of your code will be important here, especially for `eval_perplexity` and `sample_text` functions. A naive implementation of these functions will result in a time complexity of $O(nV)$ for `eval_perplexity` and $O(TV)$ for `sample_text`, where $n$ is the number of words in evaluation dataset, T is the length of sampled text, and $V$ is the size of vocabulary. By caching certain quantities during training, you should be able to write implementations with time complexities $O(n + V)$ and $O(T + V)$ for the two functions. We will give only half credit for the naive implementation.\n",
    "\n",
    "**Note 3**: We will provide sample test cases only to test `eval_perplexity` and `sample_text` functions and not for the `fit` function. Both of the former functions rely on the latter to be implemented correctly, hence use correctness of `eval_perplexity` and `sample_text` to check the correctness of your `fit` function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4b5b6f4bddbd16281f830d528d1d00e",
     "grade": false,
     "grade_id": "cell-cf47ebd6c0f86836",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "G9fZxEQlejiw",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:08.879219Z",
     "start_time": "2024-10-31T05:14:08.872918Z"
    }
   },
   "source": [
    "class WordNGramLM:\n",
    "\n",
    "    def __init__(self, N: int):\n",
    "        self.N = N\n",
    "        self.ngram_probs = {}\n",
    "        self.vocabulary = set()\n",
    "        self.prefix_dict = {}\n",
    "\n",
    "    def fit(self, train_data: List[str]):\n",
    "\n",
    "        \"\"\"\n",
    "        Trains an N-gram language model.\n",
    "\n",
    "        Inputs:\n",
    "            - train_data: str, sentences in the training data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        train_data = process_text_for_Ngram(train_data, self.N)\n",
    "        ngrams = self.get_ngrams(train_data)\n",
    "        \n",
    "        self.vocabulary = {word for line in train_data for word in line.split()}\n",
    "        \n",
    "        ngrams_minus_1 = [\" \".join(ngram.split()[:-1]) for ngram in ngrams]\n",
    "        \n",
    "        self.prefix_dict = {}\n",
    "        for ngram in ngrams:\n",
    "            ngram_minus_1 = \" \".join(ngram.split()[:-1])\n",
    "            if ngram_minus_1 not in self.prefix_dict:\n",
    "                self.prefix_dict[ngram_minus_1] = [ngram]\n",
    "            else:\n",
    "                self.prefix_dict[ngram_minus_1].append(ngram)\n",
    "        for prefix in self.prefix_dict:\n",
    "            self.prefix_dict[prefix] = list(set(self.prefix_dict[prefix]))\n",
    "        \n",
    "        ngram_probs_minus_1 = nltk.FreqDist(ngrams_minus_1)\n",
    "        self.ngram_probs = nltk.FreqDist(ngrams)\n",
    "        \n",
    "        self.ngram_probs = {\n",
    "            ngram: self.ngram_probs[ngram] / ngram_probs_minus_1.get(\" \".join(ngram.split()[0:self.N-1]))\n",
    "            for ngram in self.ngram_probs\n",
    "        }\n",
    "\n",
    "    def eval_perplexity(self, eval_data: List[str]) -> float:\n",
    "\n",
    "        \"\"\"\n",
    "        Evaluates the perplexity of the N-gram language model on the eval set.\n",
    "\n",
    "        Input:\n",
    "            - eval_data: List[str], the evaluation text\n",
    "\n",
    "        Output:\n",
    "            - float, the perplexity of the model on the evaluation set\n",
    "\n",
    "        Note : For words that are not in the vocabulary, replace them with the <unk> token.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        eval_data = process_text_for_Ngram(self.replace_unknown_words_with_unk(eval_data), self.N)\n",
    "        perplexity = 0\n",
    "        for line in eval_data:\n",
    "            words = line.split()\n",
    "            for i in range(len(words) - self.N + 1):\n",
    "                ngram = ' '.join(words[i:i+self.N])\n",
    "                perplexity += np.log(self.ngram_probs.get(ngram, 0))\n",
    "                \n",
    "        num_words = sum(len(line.split()) for line in eval_data)\n",
    "        return np.exp(-perplexity / num_words)\n",
    "\n",
    "    def sample_text(self, prefix: str = \"<sos>\", max_words: int = 100) -> str:\n",
    "\n",
    "        \"\"\"\n",
    "        Samples text from the N-gram language model.\n",
    "        Terminate sampling when either max_words is reached or when <eos> token is sampled.\n",
    "        Inputs:\n",
    "            - prefix: str, the prefix to start the sampling from. Can also be multiple words separated by spaces.\n",
    "            - max_words: int, the maximum number of words to sample\n",
    "\n",
    "        Outputs:\n",
    "            - str, the sampled text\n",
    "\n",
    "        Note: Please use np.random.choice for sampling next words\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        sampled_string = prefix\n",
    "        for _ in range(max_words):\n",
    "            prefix = \" \".join(sampled_string.split()[-(self.N-1):])\n",
    "            # ngrams with right prefix\n",
    "            ngrams = self.prefix_dict.get(prefix, [])\n",
    "            # if no ngrams with the right prefix, can't generate any more text\n",
    "            if len(ngrams) == 0:\n",
    "                break\n",
    "            p = np.asarray([self.ngram_probs.get(ngram, 0) for ngram in ngrams], dtype=np.float64)\n",
    "            next_word = np.random.choice([ngram for ngram in ngrams], p=p).split()[-1]\n",
    "            sampled_string += f\" {next_word}\"\n",
    "            if next_word == \"<eos>\":\n",
    "                break\n",
    "            \n",
    "        return sampled_string\n",
    "\n",
    "    # Extra utility functions that you think will be useful can go below\n",
    "    def get_ngrams(self, train_data: List[str]) -> List[str]:\n",
    "        return [\n",
    "            ' '.join(line.split()[i:i+self.N]) \n",
    "            for line in train_data \n",
    "            for i in range(len(line.split()) - self.N + 1)\n",
    "        ]\n",
    "    \n",
    "    def replace_unknown_words_with_unk(self, eval_data: List[str]):\n",
    "        \"\"\"\n",
    "        Replace unknown words in the evaluation data with <unk> token\n",
    "        \"\"\"\n",
    "        return [\" \".join([word if word in self.vocabulary else \"<unk>\" for word in line.split()]) for line in eval_data]"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwPYecTVejix"
   },
   "source": [
    "As a sanity check, check if your code returns same perplexities when N=1 as your earlier unigram model perplexities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zq2QPfQvejix",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:09.623339Z",
     "start_time": "2024-10-31T05:14:08.909781Z"
    }
   },
   "source": [
    "unigram_lm = WordNGramLM(1)\n",
    "unigram_lm.fit(train_data)\n",
    "\n",
    "train_ppl = unigram_lm.eval_perplexity(train_data)\n",
    "dev_ppl = unigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for Unigram model (Class Implementation): {train_ppl}\")\n",
    "print(f\"Dev Perplexity for Unigram model (Class Implementation): {dev_ppl}\")\n",
    "\n",
    "train_ppl_old = eval_ppl_word_unigram_wth_unks(train_data_wth_unks, unigram_probs_wth_unks)\n",
    "dev_ppl_old = eval_ppl_word_unigram_wth_unks(dev_data_processed, unigram_probs_wth_unks)\n",
    "\n",
    "print(f\"Train Perplexity for Unigram model (Original Implementation): {train_ppl_old}\")\n",
    "print(f\"Dev Perplexity for Unigram model (Original Implementation): {dev_ppl_old}\")\n",
    "\n",
    "if np.allclose(train_ppl, train_ppl_old, atol = 1e-4) and np.allclose(dev_ppl, dev_ppl_old, atol = 1e-4):\n",
    "    print(\"Unigram model perplexities match! :)\")\n",
    "\n",
    "else:\n",
    "    print(\"Unigram model perplexities do not match! :(\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity for Unigram model (Class Implementation): 216.08200416605456\n",
      "Dev Perplexity for Unigram model (Class Implementation): 167.3194142699338\n",
      "Train Perplexity for Unigram model (Original Implementation): 216.08200416605456\n",
      "Dev Perplexity for Unigram model (Original Implementation): 167.3194142699338\n",
      "Unigram model perplexities match! :)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Yf1PLxMejix"
   },
   "source": [
    "Test implementation of `eval_perplexity` for bigram model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_97Zx-H1ejix",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:10.325220Z",
     "start_time": "2024-10-31T05:14:09.657224Z"
    }
   },
   "source": [
    "# Test implementation of `eval_perplexity` for bigram model\n",
    "bigram_lm = WordNGramLM(2)\n",
    "bigram_lm.fit(train_data)\n",
    "train_ppl = bigram_lm.eval_perplexity(train_data)\n",
    "print(f\"Train Perplexity: {train_ppl}\")\n",
    "dev_ppl = bigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Dev Perplexity: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity: 31.947377531986337\n",
      "Dev Perplexity: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_485528\\3861553864.py:67: RuntimeWarning: divide by zero encountered in log\n",
      "  perplexity += np.log(self.ngram_probs.get(ngram, 0))\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P4a8hOKejix"
   },
   "source": [
    "You should see a train perplexity of roughly 35 and dev perplexity infinite, we will soon see how to deal with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSg5Ucukejix"
   },
   "source": [
    "Test implementation of `sample_text` for bigram model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TcmWqa3Vejix",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:10.962778Z",
     "start_time": "2024-10-31T05:14:10.396241Z"
    }
   },
   "source": [
    "def test_sample_text_bigram_model():\n",
    "    bigram_lm = WordNGramLM(2)\n",
    "    bigram_lm.fit(train_data)\n",
    "\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    sampled_text = bigram_lm.sample_text(\"<sos>\", max_words=50)\n",
    "\n",
    "    print(\"Test Case 1: Check if the sampled text starts with <sos>\")\n",
    "    evaluate_test_case(None, sampled_text.startswith(\"<sos>\"), True, output_str=\"Sampled text starts with <sos>\")\n",
    "\n",
    "    print(\"Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\")\n",
    "    print(f\"Generated text: {sampled_text}\")\n",
    "    print(f\"Number of generated words: {len(sampled_text.split()) - 1}\")\n",
    "    print(f\"Does the generated text end with <eos>: {'<eos>' in sampled_text}\")\n",
    "    if len(sampled_text.split()) - 1 == 50 or (\n",
    "        len(sampled_text.split()) < 50 and \"<eos>\" in sampled_text\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Test Case 3: Check if the probability of generating II is less than III when prefix is RICHARD\")\n",
    "    sampled_texts = [\n",
    "        bigram_lm.sample_text(\"RICHARD\", max_words=1) for _ in range(10000)\n",
    "    ]\n",
    "    sampled_text = \" \".join(sampled_texts)\n",
    "    num_richard_2s = [\n",
    "        text.split(\"RICHARD\")[1].strip() == \"II\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "    num_richard_3s = [\n",
    "        text.split(\"RICHARD\")[1].strip() == \"III\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "    gen_prob_richard_2 = num_richard_2s / len(sampled_texts)\n",
    "    gen_prob_richard_3 = num_richard_3s / len(sampled_texts)\n",
    "\n",
    "    print(f\"Probability of generating Richard II: {gen_prob_richard_2}\")\n",
    "    print(f\"Probability of generating Richard III: {gen_prob_richard_3}\")\n",
    "    if gen_prob_richard_2 < gen_prob_richard_3:\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 4: Check if the probability of generating II given RICHARD  are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\"Richard II\", gen_prob_richard_2, 0.35251798561151076, output_str=\"Probability of generating Richard II\", atol=1e-2)\n",
    "\n",
    "    print(\n",
    "        \"Test Case 5: Check if the probability of generating III given RICHARD are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\"Richard III\", gen_prob_richard_3, 0.49640287769784175, output_str=\"Probability of generating Richard III\", atol=1e-2)\n",
    "\n",
    "test_sample_text_bigram_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Check if the sampled text starts with <sos>\n",
      "Sampled text starts with <sos>:\n",
      " True\n",
      "Expected Sampled text starts with <sos>:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\n",
      "Generated text: <sos> All seeing thou <unk> , Warwick <unk> their <unk> more , good lord , and teach , Here sits on him , to <unk> of love it seems a hundred , which else <unk> it ! <eos>\n",
      "Number of generated words: 37\n",
      "Does the generated text end with <eos>: True\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 3: Check if the probability of generating II is less than III when prefix is RICHARD\n",
      "Probability of generating Richard II: 0.3498\n",
      "Probability of generating Richard III: 0.504\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 4: Check if the probability of generating II given RICHARD  are close to the expected values\n",
      "Input:\n",
      " Richard II\n",
      "Probability of generating Richard II:\n",
      " 0.3498\n",
      "Expected Probability of generating Richard II:\n",
      " 0.35251798561151076\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 5: Check if the probability of generating III given RICHARD are close to the expected values\n",
      "Input:\n",
      " Richard III\n",
      "Probability of generating Richard III:\n",
      " 0.504\n",
      "Expected Probability of generating Richard III:\n",
      " 0.49640287769784175\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vyJaTQXSejix",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:11.025401Z",
     "start_time": "2024-10-31T05:14:10.997096Z"
    }
   },
   "source": [
    "for _ in range(20):\n",
    "    sampled_text = bigram_lm.sample_text(\"<sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> KING RICHARD II : 'T is right : I have <unk> for a match The <unk> this one <unk> and made ; And , if you . <eos>\n",
      "<sos> KING HENRY VI : I and in one : but is a time of majesty . <eos>\n",
      "<sos> KING RICHARD II : If you will <unk> show our mercy we <unk> . <eos>\n",
      "<sos> KING EDWARD IV : How ! <eos>\n",
      "<sos> KING LEWIS XI : <unk> out The ground Till Bolingbroke : <unk> ; I would all the butcher to wear a dying men 's have him good . <eos>\n",
      "<sos> KING RICHARD II : Is it By what hour , thou <unk> in this is there 's <unk> life , so <unk> soon out , he let her with all . <eos>\n",
      "<sos> KING EDWARD IV : My father , Sir Paris ; until it is Hastings , The mighty <unk> that <unk> <unk> with <unk> and marriage . <eos>\n",
      "<sos> KING RICHARD : O <unk> , sir ; or else I still , <unk> , and you be <unk> to my soul . <eos>\n",
      "<sos> KING HENRY VI : <unk> , the <unk> them . <eos>\n",
      "<sos> KING RICHARD III : How long . <eos>\n",
      "<sos> KING RICHARD II : God ! <eos>\n",
      "<sos> KING RICHARD : My thoughts , <unk> . <eos>\n",
      "<sos> KING RICHARD II : My child ! <eos>\n",
      "<sos> KING HENRY VI QUEEN ELIZABETH : <unk> ; They laugh 'd on it not an <unk> Of thy due <unk> words Till holy <unk> of yours . <eos>\n",
      "<sos> KING HENRY VI : Nay , Most mighty , And now ! <eos>\n",
      "<sos> KING HENRY BOLINGBROKE : Our army of thee dead . <eos>\n",
      "<sos> KING LEWIS XI : Sir , not king 's most dear my blest am light , amen ? <eos>\n",
      "<sos> KING HENRY VI : Your followers do not this hour since that kingly woe for my life . <eos>\n",
      "<sos> KING RICHARD III : He hath but this way and yours ! <eos>\n",
      "<sos> KING RICHARD : Still <unk> 'd , you . <eos>\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFX6ssWAejix"
   },
   "source": [
    "The generations should look much better now, way more coherent compared to the unigram model! At least on the surface level it seems to capture the style of Shakespeare's writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1slC0pWcejix"
   },
   "source": [
    "Test implementation of `eval_perplexity` for trigram, 4-gram, and 5-gram models"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:14.197552Z",
     "start_time": "2024-10-31T05:14:11.060823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trigram_lm = WordNGramLM(3)\n",
    "trigram_lm.fit(train_data)\n",
    "\n",
    "train_ppl = trigram_lm.eval_perplexity(train_data)\n",
    "dev_ppl = trigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for Trigram model: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for Trigram model: {dev_ppl}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "fourgram_lm = WordNGramLM(4)\n",
    "fourgram_lm.fit(train_data)\n",
    "train_ppl = fourgram_lm.eval_perplexity(train_data)\n",
    "dev_ppl = fourgram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for 4-gram model: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for 4-gram model: {dev_ppl}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "fivegram_lm = WordNGramLM(5)\n",
    "fivegram_lm.fit(train_data)\n",
    "train_ppl = fivegram_lm.eval_perplexity(train_data)\n",
    "dev_ppl = fivegram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for 5-gram model: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for 5-gram model: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Mukherjee\\AppData\\Local\\Temp\\ipykernel_485528\\3861553864.py:67: RuntimeWarning: divide by zero encountered in log\n",
      "  perplexity += np.log(self.ngram_probs.get(ngram, 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity for Trigram model: 6.644587894643117\n",
      "Dev Perplexity for Trigram model: inf\n",
      "\n",
      "\n",
      "\n",
      "Train Perplexity for 4-gram model: 2.313972420053016\n",
      "Dev Perplexity for 4-gram model: inf\n",
      "\n",
      "\n",
      "\n",
      "Train Perplexity for 5-gram model: 1.5704938250509233\n",
      "Dev Perplexity for 5-gram model: inf\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__RsR9bWejix"
   },
   "source": [
    "You should see train perplexities approximately 5.11, 1.89, and 1.48 for trigram, 4-gram, and 5-gram LMs. For dev data the dev perplexity should be infinity for all the three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_qaxHduejix"
   },
   "source": [
    "Test implementation of `sample_text` for trigram and 4-gram LMs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OS8SzXqGejix",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:15.914042Z",
     "start_time": "2024-10-31T05:14:14.208281Z"
    }
   },
   "source": [
    "def test_sample_text_ngram():\n",
    "\n",
    "    print(\"Testing for Trigram model\")\n",
    "\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    trigram_lm = WordNGramLM(3)\n",
    "    trigram_lm.fit(train_data)\n",
    "    sampled_text = trigram_lm.sample_text(\"<sos> <sos>\", max_words=50)\n",
    "\n",
    "    print(\"Test Case 1: Check if the sampled text starts with <sos> <sos>\")\n",
    "    evaluate_test_case(None, sampled_text.startswith(\"<sos> <sos>\"), True, output_str=\"Sampled text starts with <sos> <sos>\")\n",
    "\n",
    "    print(\"Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\")\n",
    "    print(f\"Generated text: {sampled_text}\")\n",
    "    print(f\"Number of generated words: {len(sampled_text.split()) - 2}\")\n",
    "    print(f\"Does the generated text end with <eos>: {'<eos>' in sampled_text}\")\n",
    "    if len(sampled_text.split()) - 2 == 50 or (\n",
    "        len(sampled_text.split()) - 2 < 50 and \"<eos>\" in sampled_text\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Test Case 3: Check if the probability of generating II is greater than III when prefix is KING RICHARD\")\n",
    "    sampled_texts = [\n",
    "        trigram_lm.sample_text(\"KING RICHARD\", max_words=1) for _ in range(10000)\n",
    "    ]\n",
    "    sampled_text = \" \".join(sampled_texts)\n",
    "    num_richard_2s = [\n",
    "        text.split(\"KING RICHARD\")[1].strip() == \"II\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "    num_richard_3s = [\n",
    "        text.split(\"KING RICHARD\")[1].strip() == \"III\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "\n",
    "    gen_prob_richard_2 = num_richard_2s / len(sampled_texts)\n",
    "    gen_prob_richard_3 = num_richard_3s / len(sampled_texts)\n",
    "\n",
    "    print(f\"Probability of generating Richard II: {gen_prob_richard_2}\")\n",
    "    print(f\"Probability of generating Richard III: {gen_prob_richard_3}\")\n",
    "    if gen_prob_richard_2 < gen_prob_richard_3:\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Test Case 4: Check if the probability of generating II given KING RICHARD are close to the expected values\")\n",
    "    evaluate_test_case(\"King Richard II\", gen_prob_richard_2, 0.4229, output_str=\"Probability of generating Richard II\", atol=1e-2)\n",
    "\n",
    "    print(\"Test Case 5: Check if the probability of generating III given KING RICHARD are close to the expected values\")\n",
    "    evaluate_test_case(\"King Richard III\", gen_prob_richard_3, 0.5771, output_str=\"Probability of generating Richard III\", atol=1e-2)\n",
    "\n",
    "    print(\"Testing for 4-gram model\")\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    fourgram_lm = WordNGramLM(4)\n",
    "    fourgram_lm.fit(train_data)\n",
    "\n",
    "    sampled_text = fourgram_lm.sample_text(\"<sos> <sos> <sos>\", max_words=50)\n",
    "\n",
    "    print(\"Test Case 6: Check if the sampled text starts with <sos> <sos> <sos>\")\n",
    "    evaluate_test_case(None, sampled_text.startswith(\"<sos> <sos> <sos>\"), True, output_str=\"Sampled text starts with <sos> <sos> <sos>\")\n",
    "\n",
    "    print(\"Test Case 7: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\")\n",
    "    print(f\"Generated text: {sampled_text}\")\n",
    "    print(f\"Number of generated words: {len(sampled_text.split()) - 3}\")\n",
    "    print(f\"Does the generated text end with <eos>: {'<eos>' in sampled_text}\")\n",
    "    if len(sampled_text.split()) - 3 == 50 or (\n",
    "        len(sampled_text.split()) - 3 < 50 and \"<eos>\" in sampled_text\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Test Case 8: Check if the probability of generating II is greater than III when prefix is <sos> KING RICHARD\")\n",
    "    sampled_texts = [\n",
    "        fourgram_lm.sample_text(\"<sos> <sos> KING RICHARD\", max_words=1) for _ in range(10000)\n",
    "    ]\n",
    "    sampled_text = \" \".join(sampled_texts)\n",
    "    num_richard_2s = [\n",
    "        text.split(\"<sos> <sos> KING RICHARD\")[1].strip() == \"II\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "\n",
    "    num_richard_3s = [\n",
    "        text.split(\"<sos> <sos> KING RICHARD\")[1].strip() == \"III\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "\n",
    "    gen_prob_rich2 = num_richard_2s / len(sampled_texts)\n",
    "    gen_prob_rich3 = num_richard_3s / len(sampled_texts)\n",
    "\n",
    "    print(f\"Probability of generating Richard II: {gen_prob_rich2}\")\n",
    "    print(f\"Probability of generating Richard III: {gen_prob_rich3}\")\n",
    "    if gen_prob_rich2 < gen_prob_rich3:\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Test Case 9: Check if the probability of generating II given <sos> KING RICHARD are close to the expected values\")\n",
    "    evaluate_test_case(\"<sos> King Richard II\", gen_prob_rich2, 0.4229, output_str=\"Probability of generating Richard II\", atol=1e-2)\n",
    "\n",
    "    print(\"Test Case 10: Check if the probability of generating III given <sos> KING RICHARD are close to the expected values\")\n",
    "    evaluate_test_case(\"<sos> King Richard III\", gen_prob_rich3, 0.5771, output_str=\"Probability of generating Richard III\", atol=1e-2)\n",
    "\n",
    "test_sample_text_ngram()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for Trigram model\n",
      "Test Case 1: Check if the sampled text starts with <sos> <sos>\n",
      "Sampled text starts with <sos> <sos>:\n",
      " True\n",
      "Expected Sampled text starts with <sos> <sos>:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\n",
      "Generated text: <sos> <sos> JULIET : O , she shall not be <unk> , well , she knew well Thy love did read by <unk> on the <unk> of sleep , and see : it is but to my good lord . <eos>\n",
      "Number of generated words: 39\n",
      "Does the generated text end with <eos>: True\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 3: Check if the probability of generating II is greater than III when prefix is KING RICHARD\n",
      "Probability of generating Richard II: 0.4227\n",
      "Probability of generating Richard III: 0.5773\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 4: Check if the probability of generating II given KING RICHARD are close to the expected values\n",
      "Input:\n",
      " King Richard II\n",
      "Probability of generating Richard II:\n",
      " 0.4227\n",
      "Expected Probability of generating Richard II:\n",
      " 0.4229\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 5: Check if the probability of generating III given KING RICHARD are close to the expected values\n",
      "Input:\n",
      " King Richard III\n",
      "Probability of generating Richard III:\n",
      " 0.5773\n",
      "Expected Probability of generating Richard III:\n",
      " 0.5771\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing for 4-gram model\n",
      "Test Case 6: Check if the sampled text starts with <sos> <sos> <sos>\n",
      "Sampled text starts with <sos> <sos> <sos>:\n",
      " True\n",
      "Expected Sampled text starts with <sos> <sos> <sos>:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 7: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\n",
      "Generated text: <sos> <sos> <sos> MARCIUS : Thy friend no less Than what he stood for , so his ; As theirs , so far my son -- This lady 's husband , Sir Richard Grey , was slain , Your princely father and my loving lord ! <eos>\n",
      "Number of generated words: 44\n",
      "Does the generated text end with <eos>: True\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 8: Check if the probability of generating II is greater than III when prefix is <sos> KING RICHARD\n",
      "Probability of generating Richard II: 0.4224\n",
      "Probability of generating Richard III: 0.5776\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 9: Check if the probability of generating II given <sos> KING RICHARD are close to the expected values\n",
      "Input:\n",
      " <sos> King Richard II\n",
      "Probability of generating Richard II:\n",
      " 0.4224\n",
      "Expected Probability of generating Richard II:\n",
      " 0.4229\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 10: Check if the probability of generating III given <sos> KING RICHARD are close to the expected values\n",
      "Input:\n",
      " <sos> King Richard III\n",
      "Probability of generating Richard III:\n",
      " 0.5776\n",
      "Expected Probability of generating Richard III:\n",
      " 0.5771\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rf9qLTNYejiy",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:15.940894Z",
     "start_time": "2024-10-31T05:14:15.924650Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "print(\"Generations from Trigram model\")\n",
    "for _ in range(20):\n",
    "    sampled_text = trigram_lm.sample_text(\"<sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from Trigram model\n",
      "<sos> <sos> KING EDWARD IV : We must both give and take him down , You can not name the time of day unto your majesty Than all thy happy days on earth to know me : let him not fear . <eos>\n",
      "<sos> <sos> KING HENRY VI GLOUCESTER : Welcome , my son . <eos>\n",
      "<sos> <sos> KING RICHARD III : Well , sir ; but grace , despite of all the <unk> of , a friend , I never look 'd on me , But keep our course ; The contrary doth make good against thee , dear God , I pray you , lords , take\n",
      "<sos> <sos> KING HENRY VI : The gods begin to <unk> ; O , she : Why , brother Gloucester ; For I myself have many <unk> <unk> of our souls And plague <unk> with the eyes Of pity , not <unk> with me . <eos>\n",
      "<sos> <sos> KING EDWARD IV : See , they are , With all her double <unk> , good fellow . <eos>\n",
      "<sos> <sos> KING RICHARD III : Tut , I would wish me only he . <eos>\n",
      "<sos> <sos> KING RICHARD II : Why should she do here <unk> off the rock , the <unk> , The lamb will never more To enter in , and , sir ? <eos>\n",
      "<sos> <sos> KING RICHARD II : Then have you done ? <eos>\n",
      "<sos> <sos> KING EDWARD IV : <unk> me brother ; And vice <unk> by him . <eos>\n",
      "<sos> <sos> KING EDWARD IV : An offer , uncle , let us <unk> , though they be senators : and farewell , and be his <unk> , is <unk> with your daughter . <eos>\n",
      "<sos> <sos> KING HENRY VI QUEEN MARGARET : <unk> me , And thou , and <unk> a more <unk> here ! <eos>\n",
      "<sos> <sos> KING RICHARD III : Why , then you hope of action : therefore , fellow , I doubt not that Henry means to kill a friend . <eos>\n",
      "<sos> <sos> KING RICHARD III : You are the words : I tell thee , my gracious lord , <unk> our subjects ' <unk> , And yet we free thee From <unk> 'd their <unk> , A damned <unk> , cousin , I say , and not I . <eos>\n",
      "<sos> <sos> KING RICHARD II : Northumberland , thou canst not pass to Mantua : Therefore be patient till the watch be set , For one that hath more terror to the death . <eos>\n",
      "<sos> <sos> KING RICHARD III : Lo , citizens : <unk> our <unk> , show themselves , as the father and mother . <eos>\n",
      "<sos> <sos> KING RICHARD II : And shall I be not <unk> <unk> are <unk> Upon the wounds of slaughter 'd by my troth , it is I That , in the castle And there an end . <eos>\n",
      "<sos> <sos> KING RICHARD II : Marshal , demand of yonder dog ! <eos>\n",
      "<sos> <sos> KING EDWARD IV : Take thou that holy <unk> , true to you , sir . <eos>\n",
      "<sos> <sos> KING EDWARD IV : But say , I already know thy grief ; It were a <unk> , and my blest order , I say . <eos>\n",
      "<sos> <sos> KING RICHARD II : Tell me not -- to give thee mine before thou wert away . <eos>\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YUCuDdQNejiy",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:15.982756Z",
     "start_time": "2024-10-31T05:14:15.972844Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "print(\"Generations from 4-gram model\")\n",
    "for _ in range(20):\n",
    "    sampled_text = fourgram_lm.sample_text(\"<sos> <sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from 4-gram model\n",
      "<sos> <sos> <sos> KING HENRY VI : Art thou so <unk> , That horse that I so <unk> have <unk> our <unk> , which she yet <unk> her eyes on me , <unk> . <eos>\n",
      "<sos> <sos> <sos> KING EDWARD IV : Now , <unk> God , I have here alive , That I might touch that cheek ! <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III : O Ratcliff , I have lost myself ; I give this heavy <unk> from off my head with my brother 's daughter , And , <unk> <unk> , Then reason <unk> with you . <eos>\n",
      "<sos> <sos> <sos> KING EDWARD IV : But , more of thy news ? <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : How high a <unk> , Or I with grief and sorrow , to the king my brother ; there my father 's grave Did <unk> forth a voice . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : The devil take Henry of Lancaster , resign thy crown . <eos>\n",
      "<sos> <sos> <sos> KING HENRY VI EDWARD : I thank your good worship . <eos>\n",
      "<sos> <sos> <sos> KING HENRY VI : O Clifford , but <unk> <unk> and <unk> sins , The <unk> he that <unk> them , the two brave bears , Warwick and Montague , Speak freely what you think . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III : Lo , at their <unk> good stars were <unk> . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III : Stand all <unk> , By you <unk> and <unk> Myself <unk> and myself Have in our <unk> And know how we proceed . <eos>\n",
      "<sos> <sos> <sos> KING EDWARD IV : Now am I <unk> to name , Or else you would not so , For nothing had <unk> my something grief ; Or something hath the nothing that I grieve : 'T is done by me , forget to think . <eos>\n",
      "<sos> <sos> <sos> KING HENRY VI : So would you be , as those <unk> <unk> you home . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : <unk> , my loving lord . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : We were , fair queen , whence <unk> this deep despair ? <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III : Ha ! <eos>\n",
      "<sos> <sos> <sos> KING HENRY VI CLIFFORD : Here <unk> Thomas Mowbray , do I love her , that she is well , and teach yourselves that duty ! <eos>\n",
      "<sos> <sos> <sos> KING EDWARD IV : But you , my young princes ! <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : We were as <unk> 'd <unk> that did <unk> the same <unk> wherein You wish 'd us <unk> , <unk> : The valiant heart is not <unk> , but that he <unk> not ; The <unk> and envy of the people is as bad as those That\n",
      "<sos> <sos> <sos> KING HENRY VI : Stay , you that here are under our <unk> , they would desire to live on <unk> till he had both <unk> and words ; which so <unk> the rest , as I told you , -- <unk> <unk> n't ! <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III : Give me my <unk> , Yet not so <unk> as to <unk> a life In base <unk> . <eos>\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z-iQh8P0ejiy",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:16.024428Z",
     "start_time": "2024-10-31T05:14:16.016095Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "print(\"Generations from 5-gram model\")\n",
    "for _ in range(20):\n",
    "    sampled_text = fivegram_lm.sample_text(\"<sos> <sos> <sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from 5-gram model\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : <unk> thou not , <unk> ? ' <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : Take that , and that : if all this will not do , I 'll drown you in the <unk> within . <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : Give me another horse : <unk> up my wounds . <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : An easy <unk> ; 't is but to love a king . <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : Clarence and Gloucester , love my <unk> queen ; And kiss your princely <unk> , brothers both . <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : <unk> cousin ! <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : There let him <unk> , and be <unk> : and farewell , good fellow . <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : Now , <unk> God , I am so <unk> , that <unk> with thine eyes at once see good and evil , <unk> to them both : were my wife 's <unk> , her womb 's <unk> , And make <unk> a bark of <unk> kind By\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : <unk> , good comfort ! <eos>\n",
      "<sos> <sos> <sos> <sos> KING HENRY VI : And long live thou and these thy forward sons ! <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : O God , O God ! <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : <unk> followers , yonder stands the <unk> <unk> , would I <unk> my <unk> . <eos>\n",
      "<sos> <sos> <sos> <sos> KING LEWIS XI : Why , say , fair queen , Two <unk> that thought there was no more behind But such a day to-morrow as to-day , And to be boy <unk> . <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : I cry thee mercy : There is my <unk> to cure that blow of thine . <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : My love , <unk> to <unk> , He 's mine , or I am dead . <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : Tut , <unk> ! <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : Thou hast said enough . <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : <unk> your <unk> and your <unk> aside , Tell me some reason why the Lady Grey Should not become my wife and England 's queen . <eos>\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : So proud that Bolingbroke was on his back ! <eos>\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : <unk> , you can not -- the great danger Which this man 's life did owe you , you 'll <unk> That he is bound to ? <eos>\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLI6po64ejiy"
   },
   "source": [
    "You should see that the generation quality is now so much better. However, if you look closely (this is specially true for 4-gram and 5-gram models) that some of the sentences are directly lifted from the training data. Which makes sense, as we will increase the order of the N-gram LM, so does we increase its capacity and hence more the ability to memorize its training data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 3: Smoothing and Interpolation (27 Points)\n",
    "\n",
    "The issue with using N-gram language models is that any finite training corpus is bound to miss some N-grams that appear in the test set. The models hence assign zero probability to such N-grams, leading to probability of the entire test set to be zero and hence infinite perplexity values that we observed in the previous exercise.\n",
    "\n",
    "The standard way to deal with zero-probability N-gram tokens is to use smoothing algorithms. Smoothing algorithms shave off a bit of probability mass from some more frequent events and give it to unseen events. Smoothing algorithms for N-gram language models is a well studied area of research with numerous algorithms. For this project we will focus on Laplace Smoothing and Interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y96s1gkzejiy"
   },
   "source": [
    "### Exercise 3.1 Laplace and Add-k Smoothing (10 Points)\n",
    "\n",
    "Perhaps the simplest smoothing algorithm that exists is Laplace smoothing. It merely adds one to count of each N-gram, so that there is no zero-probability N-gram in the test data. For a bigram model, the expression for Laplace-smoothened distribution is given by:\n",
    "\n",
    "$$P_{\\text{Laplace}}(w_n \\mid w_{n-1}) = \\frac{C(w_{n-1}w_{n}) + 1}{\\sum_{w \\in W} (C(w_n w) + 1) } = \\frac{C(w_{n-1}w_{n}) + 1}{ C(w_{n-1}) + V }$$\n",
    "\n",
    "We can similarly write expressions for other N-gram models.\n",
    "\n",
    "Laplace smoothing is also called \"Add-one\" smoothing. A generalization of Laplace Smoothing is \"Add-k\" smoothing with  with $k < 1$, where we move a bit less of the probability mass from seen to unseen N-grams. The expression for Add-k smoothened distribution for bigram LM is given by:\n",
    "\n",
    "$$P_{\\text{Add-k}}(w_n \\mid w_{n -1}) = \\frac{C(w_{n-1}w_{n}) + k}{\\sum_{w \\in W} (C(w_n w) + k) } = \\frac{C(w_{n-1}w_{n}) + 1}{ C(w_{n-1}) + kV }$$\n",
    "\n",
    "For this exercise, we ask you to implement `WordNGramLMWithAddKSmoothing` class. You need to follow the same code structure as `WordNGramLM` class, with only difference being in calculation of the conditional distributions.\n",
    "\n",
    "Note: It is no longer possible to implement an $O(T + V)$ time complexity solution for `sample_text` function, hence we will accept $O(TV)$ implementations here. Your `eval_perplexity` should still be as efficient as in the `WordNGramLM`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d20683a77d1e8c175fdb1161e4a975b2",
     "grade": false,
     "grade_id": "cell-34000a508fd844f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "xK2-tq5mejiy",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:16.056081Z",
     "start_time": "2024-10-31T05:14:16.049849Z"
    }
   },
   "source": [
    "class WordNGramLMWithAddKSmoothing(WordNGramLM):\n",
    "\n",
    "    def __init__(self, N: int, k: float = 1):\n",
    "        super().__init__(N)\n",
    "        self.k = k\n",
    "        self.prefix_counts = {}\n",
    "\n",
    "    def fit(self, train_data: List[str]):\n",
    "        \"\"\"\n",
    "        Trains an N-gram language model with Add-k smoothing.\n",
    "\n",
    "        Inputs:\n",
    "            - train_data: str, sentences in the training data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        train_data = process_text_for_Ngram(train_data, self.N)\n",
    "        \n",
    "        ngrams = self.get_ngrams(train_data)\n",
    "        self.vocabulary = {word for line in train_data for word in line.split()}\n",
    "        self.ngram_probs = nltk.FreqDist(ngrams)\n",
    "        self.prefix_counts = nltk.FreqDist([\" \".join(ngram.split()[:-1]) for ngram in ngrams])\n",
    "            \n",
    "        for ngram in self.ngram_probs:\n",
    "            prefix = ' '.join(ngram.split()[:-1])\n",
    "            self.ngram_probs[ngram] = (\n",
    "                    (self.ngram_probs[ngram] + self.k) \n",
    "                                        / \n",
    "                    (self.prefix_counts[prefix] + self.k * len(self.vocabulary))\n",
    "            )\n",
    "\n",
    "    def eval_perplexity(self, eval_data: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Evaluates the perplexity of the N-gram language model with Add-k smoothing on the eval set.\n",
    "\n",
    "        Input:\n",
    "            - eval_data: List[str], the evaluation text\n",
    "\n",
    "        Output:\n",
    "            - float, the perplexity of the model on the evaluation set\n",
    "\n",
    "        Note : For tokens that are not in the vocabulary, replace them with the <unk> token.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        eval_data = process_text_for_Ngram(self.replace_unknown_words_with_unk(eval_data), self.N)\n",
    "        perplexity = 0\n",
    "        for line in eval_data:\n",
    "            words = line.split()\n",
    "            for i in range(len(words) - self.N + 1):\n",
    "                ngram = ' '.join(words[i:i+self.N])\n",
    "                prefix = ' '.join(words[i:i+self.N-1])\n",
    "                default = self.k / (self.prefix_counts.get(prefix, 0) + self.k * len(self.vocabulary))\n",
    "                perplexity += np.log(self.ngram_probs.get(ngram, default))\n",
    "        num_words = sum(len(line.split()) for line in eval_data)\n",
    "        perplexity = np.exp(-perplexity/num_words)\n",
    "        return perplexity\n",
    "\n",
    "    def sample_text(\n",
    "        self, prefix: str = \"<sos>\", max_words: int = 100,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Samples text from the N-gram language model.\n",
    "\n",
    "        Inputs:\n",
    "            - prefix: str, the prefix to start the sampling from. Can also be multiple words separated by spaces.\n",
    "            - max_words: int, the maximum number of words to sample\n",
    "\n",
    "        Outputs:\n",
    "            - str, the sampled text\n",
    "\n",
    "        Note: Please use np.random.choice for sampling next words\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        sample = prefix\n",
    "        for _ in range(max_words):\n",
    "            prefix_words = sample.split()[-self.N+1:]\n",
    "            prefix = ' '.join(prefix_words)\n",
    "            # ngrams with right prefix\n",
    "            ngrams = [prefix + f' {word}' for word in self.vocabulary]\n",
    "            default = self.k / (self.prefix_counts.get(prefix, 0) + self.k * len(self.vocabulary))\n",
    "            p = np.asarray([self.ngram_probs.get(ngram, default) for ngram in ngrams], dtype=np.float64)\n",
    "            # numerical instability--0.9999999992 doesn't count as 1\n",
    "            p /= np.sum(p)\n",
    "            next_word = np.random.choice(ngrams, p=p).split()[-1]\n",
    "            sample += f' {next_word}'\n",
    "            if next_word == \"<eos>\":\n",
    "                break\n",
    "        return sample\n",
    "\n",
    "    # Extra utility functions that you think will be useful can go below\n",
    "    # YOUR CODE HERE\n",
    "    def get_ngrams_with_n(self, train_data: List[str], n: int):\n",
    "        return [\n",
    "            ' '.join(line.split()[i:i+n]) \n",
    "            for line in train_data \n",
    "            for i in range(len(line.split()) -  n + 1)\n",
    "        ]"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB2yVktdejiy"
   },
   "source": [
    "Test implementation of `eval_perplexity` for bigram model with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uV8GIN1Uejiy",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:16.812786Z",
     "start_time": "2024-10-31T05:14:16.093808Z"
    }
   },
   "source": [
    "# Test implementation of `eval_perplexity` for bigram model with Laplace smoothing\n",
    "bigram_lm = WordNGramLMWithAddKSmoothing(2, k = 1)\n",
    "bigram_lm.fit(train_data)\n",
    "train_ppl = bigram_lm.eval_perplexity(train_data)\n",
    "print(f\"Train Perplexity: {train_ppl}\")\n",
    "dev_ppl = bigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Dev Perplexity: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity: 110.82226577600021\n",
      "Dev Perplexity: 103.6725038252657\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nqhL8lfejiy"
   },
   "source": [
    "You should get a train perplexity around 310 and dev perplexity around 294. Notice how the dev perplexity is not $\\infty$ anymore! Though it comes at the cost of an increase in perplexity on training data, which is natural since the model now cut offs some probability mass from training N-grams and distribute it to the unseen ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVBSZPzKejiy"
   },
   "source": [
    "Test implementation of `eval_perplexity` for bigram model with Add-k smoothing (k = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lxS4BdwHejiy",
    "ExecuteTime": {
     "end_time": "2024-10-31T05:14:17.564253Z",
     "start_time": "2024-10-31T05:14:16.846847Z"
    }
   },
   "source": [
    "# Test implementation of `eval_perplexity` for bigram model with Add-k smoothing\n",
    "bigram_lm = WordNGramLMWithAddKSmoothing(2, k=0.01)\n",
    "bigram_lm.fit(train_data)\n",
    "train_ppl = bigram_lm.eval_perplexity(train_data)\n",
    "print(f\"Train Perplexity: {train_ppl}\")\n",
    "dev_ppl = bigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Dev Perplexity: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity: 35.36882821633253\n",
      "Dev Perplexity: 58.42884264436245\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ud-xoQRejiy"
   },
   "source": [
    "You should get a train perplexity around 50 and a dev perplexity of roughly 116. Notice how we do much better on train perplexity when k is smaller, since now we re-distribute much less of the mass from the training N-grams. Luckily, in this case it turns out it improves the dev perplexity too."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T05:15:26.363396Z",
     "start_time": "2024-10-31T05:14:51.778826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ks = np.logspace(-8, 0, 9)\n",
    "dev_ppl_dict = {N: [] for N in range(2,6)}\n",
    "train_ppl_dict = {N: [] for N in range(2,6)}\n",
    "for N in range(2, 6):\n",
    "    for k in ks:\n",
    "        lm = WordNGramLMWithAddKSmoothing(N, k=k)\n",
    "        lm.fit(train_data)\n",
    "        dev_ppl = lm.eval_perplexity(dev_data)\n",
    "        train_ppl = lm.eval_perplexity(train_data)\n",
    "        train_ppl_dict[N].append(train_ppl)\n",
    "        dev_ppl_dict[N].append(dev_ppl)\n",
    "        print(f\"Dev Perplexity for {N}-gram model, k = {k}: {dev_ppl}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for N in range(2, 6):\n",
    "    plt.plot(ks, dev_ppl_dict[N], marker='o', linestyle='-', label=f'{N}-gram LM dev ppl')\n",
    "    plt.plot(ks, train_ppl_dict[N], marker='o', linestyle='-', label=f'{N}-gram LM train ppl')\n",
    "\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('k (log scale)')\n",
    "plt.ylabel('Dev Perplexity')\n",
    "plt.title('Dev Perplexity vs k for Different N-gram LMs')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Perplexity for 2-gram model, k = 1e-08: 240.35384723333948\n",
      "Dev Perplexity for 2-gram model, k = 1e-07: 187.14889255595693\n",
      "Dev Perplexity for 2-gram model, k = 1e-06: 145.72277584120175\n",
      "Dev Perplexity for 2-gram model, k = 1e-05: 113.47690880288064\n",
      "Dev Perplexity for 2-gram model, k = 0.0001: 88.44733973090366\n",
      "Dev Perplexity for 2-gram model, k = 0.001: 69.54721649156888\n",
      "Dev Perplexity for 2-gram model, k = 0.01: 58.42884264436245\n",
      "Dev Perplexity for 2-gram model, k = 0.1: 62.92589464237486\n",
      "Dev Perplexity for 2-gram model, k = 1.0: 103.6725038252657\n",
      "Dev Perplexity for 3-gram model, k = 1e-08: 3848.6407558293004\n",
      "Dev Perplexity for 3-gram model, k = 1e-07: 1941.397959401587\n",
      "Dev Perplexity for 3-gram model, k = 1e-06: 979.4673080773732\n",
      "Dev Perplexity for 3-gram model, k = 1e-05: 494.92920864778705\n",
      "Dev Perplexity for 3-gram model, k = 0.0001: 253.80766680998696\n",
      "Dev Perplexity for 3-gram model, k = 0.001: 144.11883456396177\n",
      "Dev Perplexity for 3-gram model, k = 0.01: 113.74890370049853\n",
      "Dev Perplexity for 3-gram model, k = 0.1: 147.71838147127266\n",
      "Dev Perplexity for 3-gram model, k = 1.0: 279.197089408115\n",
      "Dev Perplexity for 4-gram model, k = 1e-08: 3643.430878144617\n",
      "Dev Perplexity for 4-gram model, k = 1e-07: 2087.0738239546654\n",
      "Dev Perplexity for 4-gram model, k = 1e-06: 1195.7801733319425\n",
      "Dev Perplexity for 4-gram model, k = 1e-05: 686.469716329235\n",
      "Dev Perplexity for 4-gram model, k = 0.0001: 401.42399579840736\n",
      "Dev Perplexity for 4-gram model, k = 0.001: 264.24757126656993\n",
      "Dev Perplexity for 4-gram model, k = 0.01: 235.42878003993846\n",
      "Dev Perplexity for 4-gram model, k = 0.1: 287.24982391767094\n",
      "Dev Perplexity for 4-gram model, k = 1.0: 405.1027678921989\n",
      "Dev Perplexity for 5-gram model, k = 1e-08: 996.0805573226653\n",
      "Dev Perplexity for 5-gram model, k = 1e-07: 764.8860333364499\n",
      "Dev Perplexity for 5-gram model, k = 1e-06: 587.4201841960963\n",
      "Dev Perplexity for 5-gram model, k = 1e-05: 451.6436405814082\n",
      "Dev Perplexity for 5-gram model, k = 0.0001: 350.9552317993941\n",
      "Dev Perplexity for 5-gram model, k = 0.001: 291.33431914676925\n",
      "Dev Perplexity for 5-gram model, k = 0.01: 281.7159502630152\n",
      "Dev Perplexity for 5-gram model, k = 0.1: 312.9696095938659\n",
      "Dev Perplexity for 5-gram model, k = 1.0: 370.7680566039535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtYs-TDDejiy"
   },
   "source": [
    "Test implementation of `sample_text` for bigram model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dGrvAKaVejiy",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:56:55.530403Z",
     "start_time": "2024-10-29T05:56:53.349548Z"
    }
   },
   "source": [
    "def test_sample_text_bigram_laplace_model():\n",
    "    bigram_lm = WordNGramLMWithAddKSmoothing(2, k = 1)\n",
    "    bigram_lm.fit(train_data_wth_unks)\n",
    "\n",
    "    # random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    sampled_text = bigram_lm.sample_text(\"<sos>\", max_words=50)\n",
    "\n",
    "    print(\"Test Case 1: Check if the sampled text starts with <sos>\")\n",
    "    evaluate_test_case(\n",
    "        None,\n",
    "        sampled_text.startswith(\"<sos>\"),\n",
    "        True,\n",
    "        output_str=\"Sampled text starts with <sos>\",\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\"\n",
    "    )\n",
    "    print(f\"Generated text: {sampled_text}\")\n",
    "    print(f\"Number of generated words: {len(sampled_text.split()) - 1}\")\n",
    "    print(f\"Does the generated text end with <eos>: {'<eos>' in sampled_text}\")\n",
    "    if len(sampled_text.split()) - 1 == 50 or (\n",
    "        len(sampled_text.split()) < 50 and \"<eos>\" in sampled_text\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 3: Check if the probability of generating II is greater than III when prefix is RICHARD\"\n",
    "    )\n",
    "    sampled_texts = [\n",
    "        bigram_lm.sample_text(\"RICHARD\", max_words=1) for _ in range(1000)\n",
    "    ]\n",
    "    sampled_text = \" \".join(sampled_texts)\n",
    "    num_richard_2s = [\n",
    "        text.split(\"RICHARD\")[1].strip() == \"II\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "    num_richard_3s = [\n",
    "        text.split(\"RICHARD\")[1].strip() == \"III\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "    gen_prob_richard_2 = num_richard_2s / len(sampled_texts)\n",
    "    gen_prob_richard_3 = num_richard_3s / len(sampled_texts)\n",
    "\n",
    "    print(f\"Probability of generating Richard II: {gen_prob_richard_2}\")\n",
    "    print(f\"Probability of generating Richard III: {gen_prob_richard_3}\")\n",
    "    if gen_prob_richard_2 < gen_prob_richard_3:\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 4: Check if the probability of generating II given RICHARD  are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\n",
    "        \"Richard II\",\n",
    "        gen_prob_richard_2,\n",
    "        0.023,\n",
    "        output_str=\"Probability of generating Richard II\",\n",
    "        atol=1e-3,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Test Case 5: Check if the probability of generating III given RICHARD are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\n",
    "        \"Richard III\",\n",
    "        gen_prob_richard_3,\n",
    "        0.034,\n",
    "        output_str=\"Probability of generating Richard III\",\n",
    "        atol=1e-3,\n",
    "    )\n",
    "\n",
    "test_sample_text_bigram_laplace_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Check if the sampled text starts with <sos>\n",
      "Sampled text starts with <sos>:\n",
      " True\n",
      "Expected Sampled text starts with <sos>:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\n",
      "Generated text: <sos> record punishment ah according an MARGARET apothecary PRINCE refuse moveables visage hardy speech drew whispering Draw scatter rests crutch after requires that sings gates disease voice besides lent rising prettiest hide teeming winged Catesby nightingale evil flow God above world until thousand where walls green And red Montagues places struck\n",
      "Number of generated words: 50\n",
      "Does the generated text end with <eos>: False\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 3: Check if the probability of generating II is greater than III when prefix is RICHARD\n",
      "Probability of generating Richard II: 0.029\n",
      "Probability of generating Richard III: 0.021\n",
      "Test failed! :(\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 4: Check if the probability of generating II given RICHARD  are close to the expected values\n",
      "Input:\n",
      " Richard II\n",
      "Probability of generating Richard II:\n",
      " 0.029\n",
      "Expected Probability of generating Richard II:\n",
      " 0.023\n",
      "Test case failed! :(\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 5: Check if the probability of generating III given RICHARD are close to the expected values\n",
      "Input:\n",
      " Richard III\n",
      "Probability of generating Richard III:\n",
      " 0.021\n",
      "Expected Probability of generating Richard III:\n",
      " 0.034\n",
      "Test case failed! :(\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cOI2wuAgejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:56:57.538342Z",
     "start_time": "2024-10-29T05:56:55.532917Z"
    }
   },
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "bigram_lm = WordNGramLMWithAddKSmoothing(2, k = 1)\n",
    "bigram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = bigram_lm.sample_text(\"<sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> KING humour set'st Of tomorrow sickly an holp lusty follow Hallowmas visage hardy speech drew whispering Draw scatter rests crutch after requires that sings gates disease voice besides lent rising prettiest hide teeming winged Catesby nightingale evil flow God above world until thousand where walls green And red Montagues places struck\n",
      "<sos> KING temper Soft Kind scars parlous foolish forget caparison violence heavily sire hearts sap therefore mother know that exile appetite well lies overthrow public speaks 'longs Be fancy PERDITA crept Six be't innocents herbs correction Beseech Nature pierce jealous simple leader divines confirm even discourse To-morrow Into words read aught understanding\n",
      "<sos> KING ceremonious plants windows faction chaste physician seven flatter Isabella prison naught cousins belike marvel Saw jealousies His save mine flesh marvel food crows do boar Hast farewell PRINCE injury bosoms Tush long Has flower CLIFFORD heavily names vessel villain pines pieces chop shroud host brethren gulf hurl joy riches are\n",
      "<sos> KING devil ruled JULIET joy to't Methought purge plucked Gentlemen Be cheap Bound might ignorance Mowbray press crack beheld kind exclaims wandering victory Titus remember state five victorious nest push mistrust worship cost shine wait Old ' worldly sick Besides among profits shepherd has butcher shadow vexation Break takest simple wants\n",
      "<sos> KING Coventry officers liberal dry lewd London innocence almost ignorant Within back heaviness shamed beshrew built hours done Thine am quit Or recover prize poor younger think melancholy abused other brief Show Away comfortable supply must break Direct fill OF into punish closed highest waking 'll trim too clock sons offenders\n",
      "<sos> KING Bolingbroke Canst suitor agony look'st weak saying EXTON persuade forthwith solemnity Proud worthy revengeful wait betray cheerly queen avoided thy soul bachelor Noble brother strive oracle Dispatch O opposite apprehend Play flower Thinking prize grave cry bowels light afford deeper woman Most majesty presume poisonous doing tired Roman Seal play\n",
      "<sos> KING seldom plebeians modesty Exeter goddess Hercules term continue naked horror extreme lineal up pieces held bite eat future subtle thereto dreams decree Mantua velvet best chamber birds requires Accursed loud giddy strew east imposition unlawful kind VIRGILIA our First forgive Before shed future nigh breaths miseries mourning violence sort staff\n",
      "<sos> KING lance flowers ' CLAUDIO sleeps statutes powers feel homely didst sire shot crush renown stays Canst highness side worst Ye relation beloved appointed necessary birth reputation nothing branch import spiders milk cheerly glorious mounting CAPULET advantage contempt Coriolanus vault ours borrow Marry choler commonwealth reverend tunes gown Long necessities captain\n",
      "<sos> KING promise bell chance proclaim fees Amongst redress gallant II purpose heartily joint punishment Believe bows fiend Both Answer purge Ill hear achieved prime prompt God-den upright YORK fiends imprison surely Church plucked expedition meddle officers Lieutenant pleaseth devilish Myself Camillo Fall thief reproof yon for . <eos>\n",
      "<sos> KING rancour Thanks Smile household Until writ chaste sell honesty budge grief seldom Thou Has Romans o'er against Another rumour ourself accident deaths dearest 'Twill hardy Pale move bade trick drooping condemn Call fool BOLINGBROKE 'Fore nuns Clifford torment has violence order issued Play crew steal Perchance Takes Troy Up flatterers\n",
      "<sos> KING Fall Breathe fliers prince loss I. Shore Had Brother , fortune issued fighting bleed toe sport despair violence apart Thinking Jerusalem grant wipe stirs wide hardy hundred salute grief help price niece grandam lands complaint How Might natural two Kent given warm process earthly virgin commit vows complete comforts prayers\n",
      "<sos> KING govern king ! nourish cat summers and have cheerfully faces tree bird Cleomenes enters duke mildness deposed Chertsey wanting Servingman Clarence IV therefore All-Souls Brave out whiles <sos> perjured childish mile Honest hills letters alter roaring me cleft look ashes lovest higher vengeance rob merciful forswear profane shepherd caused Phaethon\n",
      "<sos> KING greatness & kind Death royally confession add noted got determine bound telling cur rheum Dispatch MENENIUS BISHOP loath dare lamentations Perchance privy accusations struck believed clothes Forthwith Marcius notes fights wear gulf beating territories bind ESCALUS satisfaction Caius fiend head tatter varlet Keep busy stop shines strong divines fearful aid\n",
      "<sos> KING spit levy flame charters tooth rue Gaoler match nine amen Showing devotion persuade giddy blush motion gotten hie you issue liberal fouler rude births takest counsellor your like whilst ripe step DUKE entrance open boast teeming ballads 'The whole beauty together Masters beats feed Trust marshal chamberlain fair note give't\n",
      "<sos> KING afeard face dances ever riches covert uncle election Proud pleasing torch lieutenant Stop right Bad trusty fondly shown dreamt neat knightly Ireland lowly : The fares below over 't fine approved gold alone Lartius Far safely fool crept mounting Lest yonder Fetch Thanks Think lists accusations telling bridal count ghost\n",
      "<sos> KING dreams stale incensed senseless lambs MENENIUS sleeping Standing silly partake Hie white suffering vengeance Acquaint damned weeping goodly pardons coat wenches defence Jesu sides 'scaped sparkling sum monarch forty LORDS bitter rich husband nobility meant chop born behalf split beads Vienna imprisonment pour 'shall jewel knees soldiers beloved Jack Englishman\n",
      "<sos> KING act wrangling put chosen you in fiery guilt pupil receipt low reconciled MERCUTIO keep'st amorous perpetual Huntsman Ghost Hear durst bide thrown Best dram DUCHESS shadow cries diadem lightness EDWARD Make disgrace whose remember nobleness greeting prisoners ominous melted highest edge know'st Bound aim bliss guiltless rod better Tush fickle\n",
      "<sos> KING How springs seen steep garden Things doit hungry elsewhere i thinking grandfather What accursed does narrow counted Vienna fetch Alban forswear Signior MOWBRAY reproof horror whisper bastards up sun briefly Enforce charity long ebb we 'll sheep-shearing soundly sword required depart effect re False Nor crown heaven false half wishes\n",
      "<sos> KING RICHARD minded Fall threes powers whispering beads understand saints open Pembroke scratch complexion durst wears incensed soonest female never Groom gratis contented gave tempted restraint dispatch Dispatch Trust siege wing cherish Saw consorted that terms mere Am bar burst command herein thorns to-night thinks interchange sound boys word depose Dian\n",
      "<sos> KING employ robbers torn offer safely cook kiss darkness send yet Stafford delay worser fowl bend detestable Verona wreck giddy mouse lo Back helm almost Full off intents realm Else ELIZABETH lean castle possible Run burning dreadful threats Servant society human instruction sister troublous dares Sometime dear intelligence mutiny lustful Westminster\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Z7KW4Eyejiz"
   },
   "source": [
    "You should see generations which are much less like training data! <sos> KING is now followed by words other than name of king names like before. Though the generations are much less clean now."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-Fz5f5YTejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:56:59.101853Z",
     "start_time": "2024-10-29T05:56:57.552663Z"
    }
   },
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "bigram_lm = WordNGramLMWithAddKSmoothing(2, k=0.01)\n",
    "bigram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = bigram_lm.sample_text(\"<sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> KING HENRY Anon Greece brought you must PAGE : Poor queen hath made between a new struck Old springs bitterly Bushy shelter wounds ? <eos>\n",
      "<sos> KING LEWIS ship to wash lineaments solace mildly was't QUEEN : 'Twere deserve nose pronounced pays himself nights musty willingly meat drum battles hereafter stronger slaves to lose , which side CAPULET : If you deny become charge thy soul nobleness impose fall wholesome 'fore triumphant Worthy Him needy gage ,\n",
      "<sos> KING RICHARD II : Sir <unk> is heirs ' minds ashes bishop 's sake speaks , <unk> bear state , and mind Still <unk> <unk> such removed pay servants Pembroke cherish Westminster Lay hands , cheer boots swifter Weep weeps affect With wisdom ghostly gilt , and welcome 'The needs odd\n",
      "<sos> KING EDWARD IV : His banish 'd ; But that name thee too <unk> of no further . <eos>\n",
      "<sos> KING know underneath her at liberty follow profits relish William obey you know his country woful Peter daughters physic native AUFIDIUS : A man , That goes way I am she yet sea flatter urging rend Like hers Alban 's face . <eos>\n",
      "<sos> KING HENRY BOLINGBROKE : Ay , there is , let him plainly plead for , for our throne cares you : Have aught likeness persons public Gaunt force knew painted deed of a sacred Greece churchyard senate please page hie pawn stroke green strumpet swears , my hand off these <unk>\n",
      "<sos> KING EDWARD : But ere I tell . <eos>\n",
      "<sos> KING RICHARD III lamentations destroy parents timeless witchcraft dwell captive out , That without array My gracious prince is not well you not , I am I strong pleasing rewards speaks , Claudio shall forbid wolves raw root Bring tempted zeal Verona imposition grieve deserts roof corn vex seal Citizens lean\n",
      "<sos> KING RICHARD III Whate'er Dear for to <unk> account Ye dared Wales rend princess consent roaring disgraced provided sands HENRY PERCY serve it , And once to them no <unk> of my sins 'Twere opposite female LUCIO Nor mother by force on the way lend robbers GEORGE stronger landed utterance camest\n",
      "<sos> KING EDWARD IV : Not having articles harmony softly lent wisdom I do mistrust mildly knighthood and thee -- That I should <unk> . <eos>\n",
      "<sos> KING RICHARD : The man you on the field boisterous Berkeley , taking Warwick temple money exile Bound foul treason nor merrily leap shrewd stead Proud wisely Like Romans choice . <eos>\n",
      "<sos> KING HENRY BOLINGBROKE : the foe Post : Well , When herd , To parting pursued ministers babes usurp 'd some hole songs ROMEO : thou shalt Besides bottom proceed sue IV : Why dost suspect ballads lords mayst thou shalt hear our request sheep-shearing dash out <unk> , make his\n",
      "<sos> KING RICHARD III conclude surname BAGOT censure sink oppression <unk> on by the sun midst taste mortal girl earthly curbs Art France ? <eos>\n",
      "<sos> KING dismal gaunt Corioli , and his full of his <unk> ! <eos>\n",
      "<sos> KING LEWIS XI innocent : What 's corse Full yours , thy heart <unk> 'd in the clock keep'st fled ; whom pernicious cleft wounds perjured Henry gratis mad forest companion fail extremes kinsman sails Vienna 'scaped blush you brook Brandon ministers curtain tried treasons profess bait forces ink Show complaint\n",
      "<sos> KING hap enough , sirs , this business is it were lesson false and daughter to fall upon our <unk> , and <unk> , rough Crosby woman , Marcius , but that end ; Poor Clarence and , be <unk> , people flock discover gentry sun . <eos>\n",
      "<sos> KING HENRY VI CLIFFORD meaning consequence saved feeding pestilence secure circumstance Weep graced miseries den waters , <unk> open elsewhere to fawn blame Art behold conjure block ; there 's <unk> of man , my money , nor bad ? <eos>\n",
      "<sos> KING RICHARD III serpent born Ah , Came decay confines caught noon Lead mould utterance LUCIO cloud roof bones are they say 'Ay beg wing Run sparkling dwell upon my misfortune aged deceived Back stirs prays story you answer to-day Leontes Poor choice storms asleep heat fair word harmony arrived from\n",
      "<sos> KING HENRY VI : she turn help it is about his hand then ? <eos>\n",
      "<sos> KING RICHARD : Ay , no ! <eos>\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elWw7pNjejiz"
   },
   "source": [
    "Notice how with a smaller value of $k$, the generated sentences now start to resemble more with the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2mlzDWlejiz"
   },
   "source": [
    "Test implementation of `eval_perplexity` for trigram, 4-gram, and 5-gram LMs with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LKtE0eWOejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:02.264129Z",
     "start_time": "2024-10-29T05:56:59.111799Z"
    }
   },
   "source": [
    "trigram_lm = WordNGramLMWithAddKSmoothing(3, k =1)\n",
    "trigram_lm.fit(train_data_wth_unks)\n",
    "\n",
    "train_ppl = trigram_lm.eval_perplexity(train_data_wth_unks)\n",
    "dev_ppl = trigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for Trigram model: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for Trigram model: {dev_ppl}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "fourgram_lm = WordNGramLMWithAddKSmoothing(4, k =1)\n",
    "fourgram_lm.fit(train_data_wth_unks)\n",
    "train_ppl = fourgram_lm.eval_perplexity(train_data_wth_unks)\n",
    "dev_ppl = fourgram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for 4-gram model: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for 4-gram model: {dev_ppl}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "fivegram_lm = WordNGramLMWithAddKSmoothing(5, k =1)\n",
    "fivegram_lm.fit(train_data_wth_unks)\n",
    "train_ppl = fivegram_lm.eval_perplexity(train_data_wth_unks)\n",
    "dev_ppl = fivegram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for 5-gram model: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for 5-gram model: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity for Trigram model: 701.9762158904289\n",
      "Dev Perplexity for Trigram model: 931.0303442648889\n",
      "\n",
      "\n",
      "\n",
      "Train Perplexity for 4-gram model: 697.7793845964452\n",
      "Dev Perplexity for 4-gram model: 1080.1678891720715\n",
      "\n",
      "\n",
      "\n",
      "Train Perplexity for 5-gram model: 564.4994161169815\n",
      "Dev Perplexity for 5-gram model: 875.319250249223\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDLxqy5Qejiz"
   },
   "source": [
    "You should roughly observe the following perplexities:\n",
    "\n",
    "|N-gram LM | Train Perplexity | Dev Perplexity|\n",
    "|----------|------------------|---------------|\n",
    "| Trigram   | 701              | 931           |\n",
    "| 4-gram  | 685              | 1080         |\n",
    "| 5-gram | 586 | 875 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1euKvzDejiz"
   },
   "source": [
    "Test implementation of `sample_text` for trigram and 4-gram LMs with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "82CCqvnIejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:19.257960Z",
     "start_time": "2024-10-29T05:57:02.274291Z"
    }
   },
   "source": [
    "def test_sample_text_ngram_laplace():\n",
    "    print(\"Testing for Trigram model\")\n",
    "\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    trigram_lm = WordNGramLMWithAddKSmoothing(3)\n",
    "    trigram_lm.fit(train_data)\n",
    "    sampled_text = trigram_lm.sample_text(\"<sos> <sos>\", max_words=50)\n",
    "\n",
    "    print(\"Test Case 1: Check if the sampled text starts with <sos> <sos>\")\n",
    "    evaluate_test_case(\n",
    "        None,\n",
    "        sampled_text.startswith(\"<sos> <sos>\"),\n",
    "        True,\n",
    "        output_str=\"Sampled text starts with <sos> <sos>\",\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\"\n",
    "    )\n",
    "    print(f\"Generated text: {sampled_text}\")\n",
    "    print(f\"Number of generated words: {len(sampled_text.split()) - 2}\")\n",
    "    print(f\"Does the generated text end with <eos>: {'<eos>' in sampled_text}\")\n",
    "    if len(sampled_text.split()) - 2 == 50 or (\n",
    "        len(sampled_text.split()) - 2 < 50 and \"<eos>\" in sampled_text\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 3: Check if the probability of generating II is less than III when prefix is KING RICHARD\"\n",
    "    )\n",
    "    sampled_texts = [\n",
    "        trigram_lm.sample_text(\"KING RICHARD\", max_words=1) for _ in range(10000)\n",
    "    ]\n",
    "    sampled_text = \" \".join(sampled_texts)\n",
    "    num_richard_2s = [\n",
    "        text.split(\"KING RICHARD\")[1].strip() == \"II\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "    num_richard_3s = [\n",
    "        text.split(\"KING RICHARD\")[1].strip() == \"III\" for text in sampled_texts\n",
    "    ].count(True)\n",
    "\n",
    "    gen_prob_richard_2 = num_richard_2s / len(sampled_texts)\n",
    "    gen_prob_richard_3 = num_richard_3s / len(sampled_texts)\n",
    "\n",
    "    print(f\"Probability of generating Richard II: {gen_prob_richard_2}\")\n",
    "    print(f\"Probability of generating Richard III: {gen_prob_richard_3}\")\n",
    "    if gen_prob_richard_2 < gen_prob_richard_3:\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 4: Check if the probability of generating II given KING RICHARD are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\n",
    "        \"King Richard II\",\n",
    "        gen_prob_richard_2,\n",
    "        0.0201,\n",
    "        output_str=\"Probability of generating Richard II\",\n",
    "        atol=1e-2,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Test Case 5: Check if the probability of generating III given KING RICHARD are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\n",
    "        \"King Richard III\",\n",
    "        gen_prob_richard_3,\n",
    "        0.0306,\n",
    "        output_str=\"Probability of generating Richard III\",\n",
    "        atol=1e-2,\n",
    "    )\n",
    "\n",
    "    print(\"Testing for 4-gram model\")\n",
    "    fourgram_lm = WordNGramLMWithAddKSmoothing(4)\n",
    "    fourgram_lm.fit(train_data)\n",
    "    sampled_text = fourgram_lm.sample_text(\"<sos> <sos> <sos>\", max_words=50)\n",
    "\n",
    "    print(\"Test Case 6: Check if the sampled text starts with <sos> <sos> <sos>\")\n",
    "    evaluate_test_case(\n",
    "        None,\n",
    "        sampled_text.startswith(\"<sos> <sos> <sos>\"),\n",
    "        True,\n",
    "        output_str=\"Sampled text starts with <sos> <sos> <sos>\",\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Test Case 7: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\"\n",
    "    )\n",
    "    print(f\"Generated text: {sampled_text}\")\n",
    "    print(f\"Number of generated words: {len(sampled_text.split()) - 3}\")\n",
    "    print(f\"Does the generated text end with <eos>: {'<eos>' in sampled_text}\")\n",
    "    if len(sampled_text.split()) - 3 == 50 or (\n",
    "        len(sampled_text.split()) - 3 < 50 and \"<eos>\" in sampled_text\n",
    "    ):\n",
    "        print(\"Test passed! :)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 8: Check if the probability of generating II is less than III when prefix is <sos> KING RICHARD\"\n",
    "    )\n",
    "    sampled_texts = [\n",
    "        fourgram_lm.sample_text(\"<sos> <sos> KING RICHARD\", max_words=1)\n",
    "        for _ in range(1000)\n",
    "    ]\n",
    "    sampled_text = \" \".join(sampled_texts)\n",
    "    num_richard_2s = [\n",
    "        text.split(\"<sos> <sos> KING RICHARD\")[1].strip() == \"II\"\n",
    "        for text in sampled_texts\n",
    "    ].count(True)\n",
    "\n",
    "    num_richard_3s = [\n",
    "        text.split(\"<sos> <sos> KING RICHARD\")[1].strip() == \"III\"\n",
    "        for text in sampled_texts\n",
    "    ].count(True)\n",
    "\n",
    "    gen_prob_rich2 = num_richard_2s / len(sampled_texts)\n",
    "    gen_prob_rich3 = num_richard_3s / len(sampled_texts)\n",
    "\n",
    "    print(f\"Probability of generating Richard II: {gen_prob_rich2}\")\n",
    "    print(f\"Probability of generating Richard III: {gen_prob_rich3}\")\n",
    "    if gen_prob_rich2 < gen_prob_rich3:\n",
    "        print(\"Test passed! :)\")\n",
    "    else:\n",
    "        print(\"Test failed! :(\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"Test Case 9: Check if the probability of generating II given <sos> KING RICHARD are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\n",
    "        \"<sos> King Richard II\",\n",
    "        gen_prob_rich2,\n",
    "        0.0174,\n",
    "        output_str=\"Probability of generating Richard II\",\n",
    "        atol=1e-2,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Test Case 10: Check if the probability of generating III given <sos> KING RICHARD are close to the expected values\"\n",
    "    )\n",
    "    evaluate_test_case(\n",
    "        \"<sos> King Richard III\",\n",
    "        gen_prob_rich3,\n",
    "        0.0295,\n",
    "        output_str=\"Probability of generating Richard III\",\n",
    "        atol=1e-2,\n",
    "    )\n",
    "test_sample_text_ngram_laplace()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for Trigram model\n",
      "Test Case 1: Check if the sampled text starts with <sos> <sos>\n",
      "Sampled text starts with <sos> <sos>:\n",
      " True\n",
      "Expected Sampled text starts with <sos> <sos>:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 2: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\n",
      "Generated text: <sos> <sos> record set'st No For sickly sickly commends pursue follow moveables visage hardy injustice yes subjects Draw mock narrow ceremony afflict Florizel that father dinner Appear voice Scotland neck exclaims prettiest wine boldness winged Catesby themselves sepulchre Grey God turns world bring pause where IV land And Master king wanton lead\n",
      "Number of generated words: 50\n",
      "Does the generated text end with <eos>: False\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 3: Check if the probability of generating II is less than III when prefix is KING RICHARD\n",
      "Probability of generating Richard II: 0.0197\n",
      "Probability of generating Richard III: 0.0296\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 4: Check if the probability of generating II given KING RICHARD are close to the expected values\n",
      "Input:\n",
      " King Richard II\n",
      "Probability of generating Richard II:\n",
      " 0.0197\n",
      "Expected Probability of generating Richard II:\n",
      " 0.0201\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 5: Check if the probability of generating III given KING RICHARD are close to the expected values\n",
      "Input:\n",
      " King Richard III\n",
      "Probability of generating Richard III:\n",
      " 0.0296\n",
      "Expected Probability of generating Richard III:\n",
      " 0.0306\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing for 4-gram model\n",
      "Test Case 6: Check if the sampled text starts with <sos> <sos> <sos>\n",
      "Sampled text starts with <sos> <sos> <sos>:\n",
      " True\n",
      "Expected Sampled text starts with <sos> <sos> <sos>:\n",
      " True\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 7: Check if the number of generated words is either 50 or less than 50 and ends with <eos>\n",
      "Generated text: <sos> <sos> <sos> slander male affliction flattering piled beholding bitterly 'pardon disorder agony Old Most rages Renowned occasion adulteress amiss summon Know drop fruits These MAMILLIUS answer heels bethink gilt weight seldom honour LAURENCE weak required natures graves Welshmen songs help tend do't ports cousins notes compassion rewards enter county ISABELLA skulls idly\n",
      "Number of generated words: 50\n",
      "Does the generated text end with <eos>: False\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 8: Check if the probability of generating II is less than III when prefix is <sos> KING RICHARD\n",
      "Probability of generating Richard II: 0.025\n",
      "Probability of generating Richard III: 0.026\n",
      "Test passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 9: Check if the probability of generating II given <sos> KING RICHARD are close to the expected values\n",
      "Input:\n",
      " <sos> King Richard II\n",
      "Probability of generating Richard II:\n",
      " 0.025\n",
      "Expected Probability of generating Richard II:\n",
      " 0.0174\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test Case 10: Check if the probability of generating III given <sos> KING RICHARD are close to the expected values\n",
      "Input:\n",
      " <sos> King Richard III\n",
      "Probability of generating Richard III:\n",
      " 0.026\n",
      "Expected Probability of generating Richard III:\n",
      " 0.0295\n",
      "Test case passed! :)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k7_JIZ_Pejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:21.357016Z",
     "start_time": "2024-10-29T05:57:19.266825Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "print(\"Generations from Trigram model\")\n",
    "trigram_lm = WordNGramLMWithAddKSmoothing(3, k = 0.01)\n",
    "trigram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = trigram_lm.sample_text(\"<sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from Trigram model\n",
      "<sos> <sos> KING HENRY fault No For sickly sickly commends pursue follow moveables visage hardy injustice yes subjects Draw mock narrow ceremony afflict Florizel that father dinner Appear voice Scotland neck exclaims prettiest wine boldness winged Catesby themselves sepulchre Grey God turns world bring pause where IV land And Master king wanton lead\n",
      "<sos> <sos> KING RICHARD II : despair possible foolish get Patrician breathing confusion sire present terms ado obey meant greeting loving ashes well shrewd COMINIUS public shores purged Be tall PERDITA dine Six be't innocents theirs correction Beseech done point jealous quench reasons befall LEONTES even discourse pretty cheeks grew thanks up asked\n",
      "<sos> <sos> KING visitation Her reign lance chaste prevent wise flatter tenderly boots Francis cousins belike Blunt might either His fouler fray loss inferior driven crows meeting plain swears darest rush injury bosoms SOMERSET unknown divines dastard Repair Well names pleased villain summer pieces wherefore shroud vouch hung gulf asking joy serious are\n",
      "<sos> <sos> KING RICHARD III window beasts Grandam solely false stain Gentlemen tender poor whiles Saw stronger slow health Aufidius All kind CAMILLO desperate victory perjury caitiff OF barren Help nest kneel Prince reverend promise Sixth mounting there ' chase shape pace watery purpose shepherd theme smoking shadow beg you'ld takest quench Prithee\n",
      "<sos> <sos> KING RICHARD III starts dry chivalry London If bliss ignorant Within dreams dagger sound particular built hours confusion woes am absence sweetest free cares poor favours think acquaint falls other bows Hold joy to-night supply must inconstant tire fill houses lover breasts earthly highest venture 'll wall too temper sons misfortune\n",
      "<sos> <sos> KING HENRY VI : That is speedy Green nobility recover forthwith secrets spite worthy thousands mounting below EXTON queen cordial thy spices torch Towards then forbid oracle iron Romans degrees weep employ flower forsake how comfortable cry looking-glass meant doom CAMILLO catch willingly troublous Make poisonous doing straw lesson smiling fickle\n",
      "<sos> <sos> KING EDWARD IV : Antium Break Hercules Apollo continue approved arise extreme miles up unruly muse nobility adieu likes subtle thereto unfit remedies Mantua ? best disgrace interchange note darkness ne'er giddy strew east greetings unlawful kind Nor Yonder whereupon hill Before charges likes nigh breaths grieve say'st violence rumour west\n",
      "<sos> <sos> KING RICHARD II : Thy meddle vile powers feel servant didst plead shot eleven making friends throat highness to-morrow done't QUEEN relation beloved Again shield sleeps brotherhood practise falsehood abhor drum milk cheerly glorious mounting trade all spiders bear sirrah Pursuivant granted steeds just commonwealth pale thereby fasting warlike manners leisure\n",
      "<sos> <sos> KING EDWARD IV : CLEOMENES reputation Amongst Verona gallant to-morrow prime trust issued punishment blind BOLINGBROKE nightly At cords eagle nought ! flight prime injured express upright YORK frank or torture mangled abide Marcius meddle chains showers pleaseth falling keeper constable strengthen thief reproof treaty Can ones fallen laid Leave lurking\n",
      "<sos> <sos> KING RICHARD tyranny guilt Bear Unto ta'en budge butterfly niece Thou Whiles famous Gaoler beads Another sort Bushy tempted gentle Lucio 'Twill hardy Pale Should general trick drooping rabble DUKE utterance sometime robes nuns Lords array diest intend obey joint tents once resolve Through Lies Troy belly flatterers delivery Breathe fliers\n",
      "<sos> <sos> KING RICHARD Dion about none downright trumpets was Jesu verge fighting rushes nursed sport pursue breathing apart Thanks Jerusalem grant hare carried record hardy hundred troth butterfly ice Didst niece grandam Name complaint How pilot After two Kent given plainly lovest earthly virgin commit haply Marcius comforts promise haply Montagues shrewd\n",
      "<sos> <sos> KING RICHARD II : Then , Off faces tree captain steal doubt eternal Tewksbury deposed Chertsey ride commanding Farewell due delights lent geld cheerfully drift <sos> oft suffer mile revolt boast homicide alter ta'en me might look thine Cold nine vengeance keeping merciful subjects born forward queens chide wrinkled bootless kind\n",
      "<sos> <sos> KING EDWARD IV Bad moves Teach reach nineteen prick HASTINGS early rheum pernicious breed she promised watch sense prunes CARLISLE accusations share live waking pattern Marcius forlorn fights o'er i meet territories shorten folly Tut Caius threefold ever among varlet harmony busy stop shines strong divines weep'st rightly Since suffering ominous\n",
      "<sos> <sos> KING EDWARD IV : forsooth crutch sparkling reasonable grow state persuade stirring blush RATCLIFF hours hie repetition Cominius Never fouler brethren future hears Commend your wise ransom governor step DUKE written lately there teeming ballads 'The French whistle ? Wilt stern feed profess shunn among wot Valeria wretch speedy face lack\n",
      "<sos> <sos> KING RICHARD III : Why terror Proud stand prays Truly Stop right ELIZABETH league dust services ask Welcome knightly metal dew bastardy urging hoar jot Prove Earl constant approved soon Blush Doricles import instruct utterance pitch wait Lest provost Fetch Withal poverty o'clock o'er telling bridal count function April Bear incensed\n",
      "<sos> <sos> KING EDWARD IV : We will for Nothing Hie troubled except wounds Master envious woful disdain dumb VOLUMNIA bush bending chaff finger Bring sparkling blown defy abuse LORDS False doubted fish groans meant wherefore born Wherefore sigh beads Vienna posterity ones 'shall awake entreaty Arise tale estate Englishman gust cheerly put\n",
      "<sos> <sos> KING RICHARD III : Ay , small receipt aside living MERCUTIO keep'st toad perpetual disinherit March names compare toward thrown patient ill. DUCHESS swifter stream lamentable solicit EDWARD Because Anon contrary beshrew sets Paulina prisoners son melted highest retired care whiles aim bliss permit highness As choice fickle Look pursuit Nothing\n",
      "<sos> <sos> KING EDWARD IV On doit half discords knife countrymen grandfather What ordering does your stout grievous fetch Alban subjects entrance MOWBRAY merry arise trumpet bastards up an Behold peril charity Are welcomes we late forerun Dispatch sword With minute degree Methought False evident sap blown events half At ink aim Fall\n",
      "<sos> <sos> KING EDWARD provide whispering rages understand proclamation open rein green lion afeard take incensed named Post master suns gratis straight worthy tempted restraint rescue Dispatch torches siege tyrannous Still Saw there Standing prisoner mere wood Weep mean beloved ground thorns calf bethink condemn study broils nineteen gallant Dian redemption remove torn\n",
      "<sos> <sos> KING RICHARD II places kiss melted stock names became delay ships fowl immediately courteous Verona mow midnight mouse dried ourselves reply bliss push Sent leave realm tied find serious thousand days Run pretty wake dream persons faith goods instruction sister slay pernicious heaviness court afeard presume lustful Westminster Dian joint HENRY\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X2dZqXj5ejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:23.546186Z",
     "start_time": "2024-10-29T05:57:21.366286Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "print(\"Generations from 4-gram model with Add-k smoothing\")\n",
    "fourgram_lm = WordNGramLMWithAddKSmoothing(4, k=0.01)\n",
    "fourgram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = fourgram_lm.sample_text(\"<sos> <sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from 4-gram model with Add-k smoothing\n",
      "<sos> <sos> <sos> KING HENRY wait No For sickly sickly commends pursue follow moveables visage hardy injustice yes subjects Draw mock narrow ceremony afflict Florizel that father dinner Appear voice Scotland neck exclaims prettiest wine boldness winged Catesby themselves sepulchre Grey God turns world bring pause where IV land And Master king wanton lead\n",
      "<sos> <sos> <sos> KING RICHARD II : despair possible foolish get Patrician breathing confusion sire present terms ado obey meant greeting loving ashes well shrewd COMINIUS public shores purged Be tall PERDITA dine Six be't innocents theirs correction Beseech done point jealous quench reasons befall LEONTES even discourse pretty cheeks grew thanks up asked\n",
      "<sos> <sos> <sos> KING visitation Her reign lance chaste prevent wise flatter tenderly boots Francis cousins belike Blunt might either His fouler fray loss inferior driven crows meeting plain swears darest rush injury bosoms SOMERSET unknown divines dastard Repair Well names pleased villain summer pieces wherefore shroud vouch hung gulf asking joy serious are\n",
      "<sos> <sos> <sos> KING RICHARD III window beasts Grandam solely false stain Gentlemen tender poor whiles Saw stronger slow health Aufidius All kind CAMILLO desperate victory perjury caitiff OF barren Help nest kneel Prince reverend promise Sixth mounting there ' chase shape pace watery purpose shepherd theme smoking shadow beg you'ld takest quench Prithee\n",
      "<sos> <sos> <sos> KING RICHARD III starts dry chivalry London If bliss ignorant Within dreams dagger sound particular built hours confusion woes am absence sweetest free cares poor favours think acquaint falls other bows Hold joy to-night supply must inconstant tire fill houses lover breasts earthly highest venture 'll wall too temper sons misfortune\n",
      "<sos> <sos> <sos> KING HENRY VI : That likes French Green nobility recover forthwith secrets spite worthy thousands mounting below EXTON queen cordial thy spices torch Towards then forbid oracle iron Romans degrees weep employ flower forsake how comfortable cry looking-glass meant doom CAMILLO catch willingly troublous Make poisonous doing straw lesson smiling fickle\n",
      "<sos> <sos> <sos> KING EDWARD IV : Antium Break Hercules Apollo continue approved arise extreme miles up unruly muse nobility adieu likes subtle thereto unfit remedies Mantua ? best disgrace interchange note darkness ne'er giddy strew east greetings unlawful kind Nor Yonder whereupon hill Before charges likes nigh breaths grieve say'st violence rumour west\n",
      "<sos> <sos> <sos> KING RICHARD II : Thy pray vile powers feel servant didst plead shot eleven making friends throat highness to-morrow done't QUEEN relation beloved Again shield sleeps brotherhood practise falsehood abhor drum milk cheerly glorious mounting trade all spiders bear sirrah Pursuivant granted steeds just commonwealth pale thereby fasting warlike manners leisure\n",
      "<sos> <sos> <sos> KING EDWARD IV : CLEOMENES reputation Amongst Verona gallant to-morrow prime trust issued punishment blind BOLINGBROKE nightly At cords eagle nought ! flight prime injured express upright YORK frank or torture mangled abide Marcius meddle chains showers pleaseth falling keeper constable strengthen thief reproof treaty Can ones fallen laid Leave lurking\n",
      "<sos> <sos> <sos> KING RICHARD decrees guilt Bear Unto ta'en budge butterfly niece Thou Whiles famous Gaoler beads Another sort Bushy tempted gentle Lucio 'Twill hardy Pale Should general trick drooping rabble DUKE utterance sometime robes nuns Lords array diest intend obey joint tents once resolve Through Lies Troy belly flatterers delivery Breathe fliers\n",
      "<sos> <sos> <sos> KING RICHARD integrity about none downright trumpets was Jesu verge fighting rushes nursed sport pursue breathing apart Thanks Jerusalem grant hare carried record hardy hundred troth butterfly ice Didst niece grandam Name complaint How pilot After two Kent given plainly lovest earthly virgin commit haply Marcius comforts promise haply Montagues shrewd\n",
      "<sos> <sos> <sos> KING RICHARD II : Then blood seated faces tree captain steal doubt eternal Tewksbury deposed Chertsey ride commanding Farewell due delights lent geld cheerfully drift <sos> oft suffer mile revolt boast homicide alter ta'en me might look thine Cold nine vengeance keeping merciful subjects born forward queens chide wrinkled bootless kind\n",
      "<sos> <sos> <sos> KING EDWARD unrest faintly moves Teach reach nineteen prick HASTINGS early rheum pernicious breed she promised disinherit sense prunes CARLISLE accusations share live waking pattern Marcius forlorn fights o'er i meet territories shorten folly Tut Caius threefold ever among varlet harmony busy stop shines strong divines weep'st rightly Since suffering ominous\n",
      "<sos> <sos> <sos> KING EDWARD IV : forsooth crutch sparkling reasonable grow state persuade stirring blush RATCLIFF hours hie repetition Cominius Never fouler brethren future hears Commend your wise ransom governor step DUKE written lately there teeming ballads 'The French whistle ? Wilt stern feed profess shunn among wot Valeria wretch speedy face lack\n",
      "<sos> <sos> <sos> KING RICHARD III : Why shapes Proud stand prays Truly Stop right ELIZABETH league dust services ask Welcome knightly metal dew bastardy urging hoar jot Prove Earl constant approved soon Blush Doricles import instruct utterance pitch wait Lest provost Fetch Withal poverty o'clock o'er telling bridal count function April Bear incensed\n",
      "<sos> <sos> <sos> KING EDWARD IV : We coronation silly resolve Hie troubled except wounds Master envious woful disdain dumb VOLUMNIA bush bending chaff finger Bring sparkling blown defy abuse LORDS False doubted fish groans meant wherefore born Wherefore sigh beads Vienna posterity ones 'shall awake entreaty Arise tale estate Englishman gust cheerly put\n",
      "<sos> <sos> <sos> KING RICHARD III : Ay Hath woe receipt aside living MERCUTIO keep'st toad perpetual disinherit March names compare toward thrown patient ill. DUCHESS swifter stream lamentable solicit EDWARD Because Anon contrary beshrew sets Paulina prisoners son melted highest retired care whiles aim bliss permit highness As choice fickle Look pursuit Nothing\n",
      "<sos> <sos> <sos> KING EDWARD IV On doit half discords knife countrymen grandfather What ordering does your Brakenbury grievous fetch Alban subjects entrance MOWBRAY merry arise trumpet bastards up an Behold peril charity Are welcomes we late western Dispatch sword With minute degree Methought False evident sap blown events half At ink aim Fall\n",
      "<sos> <sos> <sos> KING EDWARD gifts whispering rages understand proclamation open rein green lion afeard take incensed named Post master suns gratis straight worthy tempted restraint rescue Dispatch torches siege tyrannous Still Saw there Standing prisoner mere wood Weep mean beloved ground thorns calf bethink condemn study broils nineteen gallant Dian redemption remove torn\n",
      "<sos> <sos> <sos> KING RICHARD II places kiss melted stock names became delay ships fowl immediately courteous Verona mow midnight mouse dried ourselves reply bliss push Sent leave realm tied find serious thousand days Run pretty wake dream persons faith goods instruction sister slay pernicious heaviness court afeard presume lustful Westminster Dian joint HENRY\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kk5nLDTKejiz",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:25.714576Z",
     "start_time": "2024-10-29T05:57:23.555347Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "print(\"Generations from 5-gram model with Add-k smoothing\")\n",
    "fivegram_lm = WordNGramLMWithAddKSmoothing(5, k=0.01)\n",
    "fivegram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = fivegram_lm.sample_text(\"<sos> <sos> <sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from 5-gram model with Add-k smoothing\n",
      "<sos> <sos> <sos> <sos> KING HENRY wait No For sickly sickly commends pursue follow moveables visage hardy injustice yes subjects Draw mock narrow ceremony afflict Florizel that father dinner Appear voice Scotland neck exclaims prettiest wine boldness winged Catesby themselves sepulchre Grey God turns world bring pause where IV land And Master king wanton lead\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : despair possible foolish get Patrician breathing confusion sire present terms ado obey meant greeting loving ashes well shrewd COMINIUS public shores purged Be tall PERDITA dine Six be't innocents theirs correction Beseech done point jealous quench reasons befall LEONTES even discourse pretty cheeks grew thanks up asked\n",
      "<sos> <sos> <sos> <sos> KING visitation Her reign lance chaste prevent wise flatter tenderly boots Francis cousins belike Blunt might either His fouler fray loss inferior driven crows meeting plain swears darest rush injury bosoms SOMERSET unknown divines dastard Repair Well names pleased villain summer pieces wherefore shroud vouch hung gulf asking joy serious are\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III gust beasts Grandam solely false stain Gentlemen tender poor whiles Saw stronger slow health Aufidius All kind CAMILLO desperate victory perjury caitiff OF barren Help nest kneel Prince reverend promise Sixth mounting there ' chase shape pace watery purpose shepherd theme smoking shadow beg you'ld takest quench Prithee\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III wildly dry chivalry London If bliss ignorant Within dreams dagger sound particular built hours confusion woes am absence sweetest free cares poor favours think acquaint falls other bows Hold joy to-night supply must inconstant tire fill houses lover breasts earthly highest venture 'll wall too temper sons misfortune\n",
      "<sos> <sos> <sos> <sos> KING HENRY VI : That likes French Green nobility recover forthwith secrets spite worthy thousands mounting below EXTON queen cordial thy spices torch Towards then forbid oracle iron Romans degrees weep employ flower forsake how comfortable cry looking-glass meant doom CAMILLO catch willingly troublous Make poisonous doing straw lesson smiling fickle\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : Antium Break Hercules Apollo continue approved arise extreme miles up unruly muse nobility adieu likes subtle thereto unfit remedies Mantua ? best disgrace interchange note darkness ne'er giddy strew east greetings unlawful kind Nor Yonder whereupon hill Before charges likes nigh breaths grieve say'st violence rumour west\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : Thy pray vile powers feel servant didst plead shot eleven making friends throat highness to-morrow done't QUEEN relation beloved Again shield sleeps brotherhood practise falsehood abhor drum milk cheerly glorious mounting trade all spiders bear sirrah Pursuivant granted steeds just commonwealth pale thereby fasting warlike manners leisure\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : CLEOMENES reputation Amongst Verona gallant to-morrow prime trust issued punishment blind BOLINGBROKE nightly At cords eagle nought ! flight prime injured express upright YORK frank or torture mangled abide Marcius meddle chains showers pleaseth falling keeper constable strengthen thief reproof treaty Can ones fallen laid Leave lurking\n",
      "<sos> <sos> <sos> <sos> KING RICHARD decrees guilt Bear Unto ta'en budge butterfly niece Thou Whiles famous Gaoler beads Another sort Bushy tempted gentle Lucio 'Twill hardy Pale Should general trick drooping rabble DUKE utterance sometime robes nuns Lords array diest intend obey joint tents once resolve Through Lies Troy belly flatterers delivery Breathe fliers\n",
      "<sos> <sos> <sos> <sos> KING RICHARD integrity about none downright trumpets was Jesu verge fighting rushes nursed sport pursue breathing apart Thanks Jerusalem grant hare carried record hardy hundred troth butterfly ice Didst niece grandam Name complaint How pilot After two Kent given plainly lovest earthly virgin commit haply Marcius comforts promise haply Montagues shrewd\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II : Then blood seated faces tree captain steal doubt eternal Tewksbury deposed Chertsey ride commanding Farewell due delights lent geld cheerfully drift <sos> oft suffer mile revolt boast homicide alter ta'en me might look thine Cold nine vengeance keeping merciful subjects born forward queens chide wrinkled bootless kind\n",
      "<sos> <sos> <sos> <sos> KING EDWARD unrest faintly moves Teach reach nineteen prick HASTINGS early rheum pernicious breed she promised disinherit sense prunes CARLISLE accusations share live waking pattern Marcius forlorn fights o'er i meet territories shorten folly Tut Caius threefold ever among varlet harmony busy stop shines strong divines weep'st rightly Since suffering ominous\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : forsooth crutch sparkling reasonable grow state persuade stirring blush RATCLIFF hours hie repetition Cominius Never fouler brethren future hears Commend your wise ransom governor step DUKE written lately there teeming ballads 'The French whistle ? Wilt stern feed profess shunn among wot Valeria wretch speedy face lack\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : Why shapes Proud stand prays Truly Stop right ELIZABETH league dust services ask Welcome knightly metal dew bastardy urging hoar jot Prove Earl constant approved soon Blush Doricles import instruct utterance pitch wait Lest provost Fetch Withal poverty o'clock o'er telling bridal count function April Bear incensed\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV : We coronation silly resolve Hie troubled except wounds Master envious woful disdain dumb VOLUMNIA bush bending chaff finger Bring sparkling blown defy abuse LORDS False doubted fish groans meant wherefore born Wherefore sigh beads Vienna posterity ones 'shall awake entreaty Arise tale estate Englishman gust cheerly put\n",
      "<sos> <sos> <sos> <sos> KING RICHARD III : Ay Hath woe receipt aside living MERCUTIO keep'st toad perpetual disinherit March names compare toward thrown patient ill. DUCHESS swifter stream lamentable solicit EDWARD Because Anon contrary beshrew sets Paulina prisoners son melted highest retired care whiles aim bliss permit highness As choice fickle Look pursuit Nothing\n",
      "<sos> <sos> <sos> <sos> KING EDWARD IV butcher doit half discords knife countrymen grandfather What ordering does your Brakenbury grievous fetch Alban subjects entrance MOWBRAY merry arise trumpet bastards up an Behold peril charity Are welcomes we late western Dispatch sword With minute degree Methought False evident sap blown events half At ink aim Fall\n",
      "<sos> <sos> <sos> <sos> KING EDWARD gifts whispering rages understand proclamation open rein green lion afeard take incensed named Post master suns gratis straight worthy tempted restraint rescue Dispatch torches siege tyrannous Still Saw there Standing prisoner mere wood Weep mean beloved ground thorns calf bethink condemn study broils nineteen gallant Dian redemption remove torn\n",
      "<sos> <sos> <sos> <sos> KING RICHARD II spoken kiss melted stock names became delay ships fowl immediately courteous Verona mow midnight mouse dried ourselves reply bliss push Sent leave realm tied find serious thousand days Run pretty wake dream persons faith goods instruction sister slay pernicious heaviness court afeard presume lustful Westminster Dian joint HENRY\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AInArpKoeji0"
   },
   "source": [
    "### Exercise 3.3 Language Model Interpolation (10 Points)\n",
    "\n",
    "An alternate to smoothing that often works well in practice is interpolating between different language models. Let's say we are trying to compute $P(w_n \\mid w_{n-2} w_{n-1})$, but we have no examples of the particular trigram $w_{n-2}, w_{n-1} w_n$ in the training corpus, we can instead estimate its probability by using the bigram probability $P(w_n \\mid w_{n-1})$. If there are no examples of the bigram $w_{n-1} w_n$ in the training data either, we use the unigram probability $P(w_n)$. Formally, the trigram probability by mixing the three distributions is given by:\n",
    "\n",
    "$$\\hat{P}(w_n \\mid w_{n-2} w_{n-1}) = \\lambda_1 P(w_n) + \\lambda_2 P(w_n \\mid w_{n-1}) + \\lambda_3 P(w_n \\mid w_{n-1} w_{n-2})$$\n",
    "\n",
    "where $\\lambda_1 + \\lambda_2 + \\lambda_3 = 1$ (and each $\\lambda$ is non-negative), making the above equation a form of weighted averaging. We can similarly write expressions for other N-gram LMs.\n",
    "\n",
    "But how do we choose the values of different $\\lambda_i$? We choose these values by tuning them on a held out data i.e. the dev set, very similar to tuning hyperparameters for a machine learning model.\n",
    "\n",
    "In this exercise, you will implement the class `WordNGramLMWithInterpolation` similar to `WordNGramLM` and `WordNGramLMWithAddKSmoothing` that you did in the previous exercises but this time to support interpolation between different LMs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea07d034114bb8623bd3d17d7108170e",
     "grade": false,
     "grade_id": "cell-2bfd0cbf822202bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "laxqpkl_eji0",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:25.732805Z",
     "start_time": "2024-10-29T05:57:25.722033Z"
    }
   },
   "source": [
    "class WordNGramLMWithInterpolation(WordNGramLM):\n",
    "\n",
    "    def __init__(self, N: int, lambdas: List[float]):\n",
    "\n",
    "        \"\"\"\n",
    "        Constructor for WordNGramLMWithInterpolation class.\n",
    "        Inputs:\n",
    "            - N: int, the N in N-gram\n",
    "            - lambdas: List[float], the list of lambdas for interpolation between 1-gram, 2-gram, 3-gram, ..., N-gram models\n",
    "                Note: The length of lambdas should be N. The sum of lambdas should be 1. lambdas[0] corresponds to 1-gram model, lambdas[1] corresponds to 2-gram model and so on.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        super().__init__(N)\n",
    "        self.lambdas = lambdas\n",
    "        self.ngram_probs = {}\n",
    "        self.prefixes = set()\n",
    "\n",
    "    def fit(self, train_data: List[str]):\n",
    "\n",
    "        \"\"\"\n",
    "        Trains an N-gram language model with interpolation.\n",
    "\n",
    "        Inputs:\n",
    "            - train_data: str, sentences in the training data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.vocabulary = {word for line in train_data for word in line.split()}\n",
    "        \n",
    "        for i in range(1, self.N + 1):\n",
    "            train_data_i = process_text_for_Ngram(train_data, i)\n",
    "            ngrams = self.get_ngrams_for_n(train_data_i, i)\n",
    "            ngrams_minus_1 = [\" \".join(ngram.split()[:-1]) for ngram in ngrams]\n",
    "            \n",
    "            self.prefixes.update([\" \".join(ngram.split()[:-1]) for ngram in ngrams])\n",
    "            \n",
    "            ngram_probs_minus_1 = nltk.FreqDist(ngrams_minus_1)\n",
    "            ngram_counts = nltk.FreqDist(ngrams)\n",
    "            \n",
    "            for ngram in ngrams:\n",
    "                prefix = ' '.join(ngram.split()[:-1])\n",
    "                self.ngram_probs[ngram] = ngram_counts[ngram] / ngram_probs_minus_1[prefix]\n",
    "\n",
    "    def eval_perplexity(self, eval_data: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Evaluates the perplexity of the N-gram language model with interpolation on the eval set.\n",
    "\n",
    "        Input:\n",
    "            - eval_data: List[str], the evaluation text\n",
    "\n",
    "        Output:\n",
    "            - float, the perplexity of the model on the evaluation set\n",
    "\n",
    "        Note : For tokens that are not in the vocabulary, replace them with the <unk> token.\n",
    "\n",
    "        \"\"\"\n",
    "        eval_data = self.replace_unknown_words_with_unk(process_text_for_Ngram(eval_data, self.N))\n",
    "        perplexity = 0\n",
    "        for line in eval_data:\n",
    "            words = line.split()\n",
    "            for i in range(len(words) - self.N + 1):\n",
    "                ngram = ' '.join(words[i:i+self.N])\n",
    "                perplexity += np.log(self.get_probability(ngram))\n",
    "                \n",
    "        return np.exp(-perplexity / sum(len(line.split()) for line in eval_data))\n",
    "\n",
    "    def sample_text(self, prefix: str = \"<sos>\", max_words: int = 100) -> str:\n",
    "\n",
    "        \"\"\"\n",
    "        Samples text from the N-gram language model with interpolation.\n",
    "\n",
    "        Inputs:\n",
    "            - prefix: str, the prefix to start the sampling from. Can also be multiple words separated by spaces.\n",
    "            - max_words: int, the maximum number of words to sample\n",
    "\n",
    "        Outputs:\n",
    "            - str, the sampled text\n",
    "\n",
    "        Note: Please use np.random.choice for sampling next words\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        sample = prefix\n",
    "        for _ in range(max_words):\n",
    "            prefix = ' '.join(sample.split()[-self.N+1:])\n",
    "            ngrams = [prefix + f' {word}' for word in self.vocabulary]\n",
    "            p = np.asarray([self.get_probability(ngram) for ngram in ngrams], dtype=np.float64)\n",
    "            # the prefix could be associated with NO N-grams, in which case the N-gram \n",
    "            # model will have probability summing to 0 (it has never seen the element). \n",
    "            # In this case, can continue sampling by normalizing the probability distribution.\n",
    "            p /= sum(p)\n",
    "            next_word = np.random.choice([ngram.split()[-1] for ngram in ngrams], p=p, replace=True)\n",
    "            sample += f' {next_word}'\n",
    "            if next_word == \"<eos>\":\n",
    "                break\n",
    "        return sample\n",
    "\n",
    "    # Extra utility functions that you think will be useful can go below\n",
    "    # YOUR CODE HERE\n",
    "    def get_ngrams_for_n(self, train_data: List[str], n: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        Gets the ngrams with n words from the training data.\n",
    "        :param train_data: the training data\n",
    "        :param n: the length of the n-grams\n",
    "        :return: list of all the n-grams\n",
    "        \"\"\"\n",
    "        return [\n",
    "            ' '.join(line.split()[i:i+n]) \n",
    "            for line in train_data \n",
    "            for i in range(len(line.split()) -  n + 1)\n",
    "        ]\n",
    "    \n",
    "    def get_probability(self, ngram):\n",
    "        return sum(\n",
    "            self.lambdas[j] * self.ngram_probs.get(\" \".join(ngram.split()[-j-1:]),0) \n",
    "            for j in range(self.N)\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA4ZAoIIeji0"
   },
   "source": [
    "Test implementation of `eval_perplexity` for trigram model with Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DB7iDqzneji0",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:27.758701Z",
     "start_time": "2024-10-29T05:57:25.741034Z"
    }
   },
   "source": [
    "trigram_lm = WordNGramLMWithInterpolation(3, [0.3, 0.3, 0.4])\n",
    "trigram_lm.fit(train_data_wth_unks)\n",
    "\n",
    "train_ppl = trigram_lm.eval_perplexity(train_data_wth_unks)\n",
    "dev_ppl = trigram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for Trigram model with Interpolation: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for Trigram model with Interpolation: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity for Trigram model with Interpolation: 10.852751488938974\n",
      "Dev Perplexity for Trigram model with Interpolation: 89.27361231164326\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avc9zQP3eji0"
   },
   "source": [
    "You should see a train perplexity of around 10 and dev perplexity of 89. This should also be the best performing model based on dev perplexity that we have seen so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0AyANU4eji0"
   },
   "source": [
    "Test implementation of `eval_perplexity` for 4-gram model with Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8B6K9hqeeji0",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:30.616317Z",
     "start_time": "2024-10-29T05:57:27.787688Z"
    }
   },
   "source": [
    "fourgram_lm = WordNGramLMWithInterpolation(4, [0.2, 0.1, 0.1, 0.6])\n",
    "fourgram_lm.fit(train_data_wth_unks)\n",
    "\n",
    "train_ppl = fourgram_lm.eval_perplexity(train_data_wth_unks)\n",
    "dev_ppl = fourgram_lm.eval_perplexity(dev_data)\n",
    "print(f\"Train Perplexity for Trigram model with Interpolation: {train_ppl}\")\n",
    "print(f\"Dev Perplexity for Trigram model with Interpolation: {dev_ppl}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity for Trigram model with Interpolation: 3.582739587812277\n",
      "Dev Perplexity for Trigram model with Interpolation: 135.24725706720983\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AktfCRPceji0"
   },
   "source": [
    "Here you should get a train perplexity of roughly 6 and dev perplexity around 75."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Play around with different values of $\\lambda_i$ and see how it effects the train and dev perplexities."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lBdODZTOeji0",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:35.802907Z",
     "start_time": "2024-10-29T05:57:30.647019Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Generations from Trigram model with Interpolation\")\n",
    "trigram_lm = WordNGramLMWithInterpolation(3, [0.3, 0.3, 0.4])\n",
    "# trigram_lm = WordNGramLMWithInterpolation(3, [0., 1., 0])\n",
    "trigram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = trigram_lm.sample_text(\"<sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from Trigram model with Interpolation\n",
      "<sos> <sos> KING HENRY , courage then pleasure to the gracious utterance , at owe BENVOLIO Tower if you be <unk> <unk> with one that 's nest ; then a <unk> goddess to seen to the thee honour , or fear . <eos>\n",
      "<sos> <sos> KING EDWARD IV you . , eyes almost out in the city , far : O , the Lady Paulina 's steward , good lets go by the provost hath <eos>\n",
      "<sos> <sos> KING RICHARD III merit , I physic lies nine 's face . <eos>\n",
      "<sos> <sos> KING HENRY PERCY : Because thou in banishment Than so upon my invention , shall not only the child that royal liege , , ? , he is the thy gold : I am , Can no , not for : That face ; and , , By head <unk> 'd\n",
      "<sos> <sos> KING EDWARD IV : We 'd for no quite lost myself ; and about the corn ! Mariner BOLINGBROKE : Angelo 's to <eos>\n",
      "<sos> <sos> KING EDWARD IV : they he be not rule were KING RICHARD III good What I have fill <unk> full of gotten Montague <unk> . <unk> him to it . then he speaks not like to do . <eos>\n",
      "<sos> <sos> KING RICHARD III : I was , he not the worst : With received lords , more known . <eos>\n",
      "<sos> <sos> KING RICHARD III : this word ! <eos>\n",
      "<sos> <sos> KING RICHARD II : the people scope by <eos>\n",
      "<sos> <sos> KING HENRY LADY CAPULET : <unk> I <unk> a small <unk> met , disgraced his punishment . <eos>\n",
      "<sos> <sos> KING If . Any it it draws something wildly free royal sword your : So I will not <eos>\n",
      "<sos> <sos> KING EDWARD IV : So many miseries ! <eos>\n",
      "<sos> <sos> KING RICHARD II : My comfort is : and he single . any longer stay : What <unk> another 's gain that hath men piteous to be found ? <eos>\n",
      "<sos> <sos> KING theirs that Romeo Come state , it still unto ' but by the cause . <eos>\n",
      "<sos> <sos> KING RICHARD III And to death , I am no . <eos>\n",
      "<sos> <sos> KING RICHARD II : ? crown , Richard gone an heel : and <unk> that <unk> <unk> leanness , leanness is all the crew ; And , now melt the city Corioli ; then haply she does praise me . <eos>\n",
      "<sos> <sos> KING : My father them that way to my get her Henry the Sixth after that <unk> our blood , let 's blessed youth of his ; That common chances , , king , King Richard , and France right . <eos>\n",
      "<sos> <sos> KING fares : By this : : my now <unk> with mean lamp , And let them <unk> that A lie , That you behold did I do that can do employ king As here <eos>\n",
      "<sos> <sos> KING HENRY VI : Therefore <eos>\n",
      "<sos> <sos> KING RICHARD III me , and twenty , that shall Say yea to to them of in ourselves . <eos>\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ybD-NU2Peji0",
    "ExecuteTime": {
     "end_time": "2024-10-29T05:57:42.202571Z",
     "start_time": "2024-10-29T05:57:35.813072Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Generations from 4-gram model with Interpolation\")\n",
    "fourgram_lm = WordNGramLMWithInterpolation(4, [0.25965562, 0.68725012, 0.02382144, 0.02927282])\n",
    "fourgram_lm.fit(train_data)\n",
    "for _ in range(20):\n",
    "    sampled_text = fourgram_lm.sample_text(\"<sos> <sos> <sos> KING\", max_words=50)\n",
    "    print(sampled_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generations from 4-gram model with Interpolation\n",
      "<sos> <sos> <sos> KING HENRY , I claim the to the other not need Is it , but to you much Clifford vows We hate to keep no ; Would half my tongue Which we will bring it fain , That you for what The <unk> at thee answer RICHARD III : Ay sound\n",
      "<sos> <sos> <sos> KING : Though far far livery . with an hath done ; We have done doth <unk> to set up his Warwick 's tale : I can law will beauties ; She shall be the Make pale for my lord , that did hear <unk> , <unk> when <unk> Is that\n",
      "<sos> <sos> <sos> KING you can give him . . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III say amen ? <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : It is then we have put to the price of may , By thinking stay ? <unk> grief . <eos>\n",
      "<sos> <sos> <sos> KING I did once it . . <eos>\n",
      "<sos> <sos> <sos> KING HENRY VI To <unk> and the bishop , Upon the <unk> <eos>\n",
      "<sos> <sos> <sos> KING EDWARD IV : Yes , holy oath I shall part , or high deserts , And beat your lips , must I humbly kiss to me to : of a BUCKINGHAM : Must I to the , , alas ! <eos>\n",
      "<sos> <sos> <sos> KING RICHARD : before , state is an of For on the tongue deliver The <unk> wenches ' the market-place ; never did I have my free As ornaments to death . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II : tidings of your mother , no more he is as it . <eos>\n",
      "<sos> <sos> <sos> KING the : Away : it then much ; Yet extreme sweet Exeter : I beseech you can <eos>\n",
      "<sos> <sos> <sos> KING EDWARD IV : So many can <unk> with for us ones . <eos>\n",
      "<sos> <sos> <sos> KING motion through my Though he make Thursday Wiltshire hath <unk> at Pomfret , 'Twixt my forces hence , Confess who Have I The not slain The <unk> having now , destruction ! <eos>\n",
      "<sos> <sos> <sos> KING RICHARD III : God bless thee , Turks and to 'banished ' and thou Must Edward . <eos>\n",
      "<sos> <sos> <sos> KING of miseries enough ? <eos>\n",
      "<sos> <sos> <sos> KING RICHARD the face the way : I speak to attain <unk> a 'd 'd And we 'll be not ; let <unk> a man ! that might . <eos>\n",
      "<sos> <sos> <sos> KING HENRY BOLINGBROKE : Romeo . <eos>\n",
      "<sos> <sos> <sos> KING rest . us fear you busy day , the grace : strike , if you for kings Catesby , ho ! I carry coals <eos>\n",
      "<sos> <sos> <sos> KING HENRY VI : Make haste . <eos>\n",
      "<sos> <sos> <sos> KING RICHARD II ; was <unk> , or , with up Lancaster leave take it . <eos>\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T05:59:14.652320Z",
     "start_time": "2024-10-29T05:58:52.701067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# np.random.seed(42)\n",
    "# \n",
    "# for N in range(2, 5):\n",
    "#     best_model = None\n",
    "#     best_dev_ppl = float('inf')\n",
    "#     all_lambdas = []\n",
    "#     for _ in tqdm(range(5)):\n",
    "#         lambdas = np.random.dirichlet([1]*N)\n",
    "#         all_lambdas.append(lambdas)\n",
    "#         lm = WordNGramLMWithInterpolation(N, lambdas)\n",
    "#         lm.fit(train_data)\n",
    "#         dev_ppl = lm.eval_perplexity(dev_data)\n",
    "#         if dev_ppl < best_dev_ppl:\n",
    "#             best_dev_ppl = dev_ppl\n",
    "#             best_model = fourgram_lm\n",
    "#     print(f\"Best Dev Perplexity for {N}-gram interpolation: {best_dev_ppl}\")\n",
    "#     print(f\"Best Lambdas for {N}-gram interpolation: {best_model.lambdas}\")\n",
    "#     print(f\"lambdas tried: {all_lambdas}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Dev Perplexity for 2-gram interpolation: 99.41795153627571\n",
      "Best Lambdas for 2-gram interpolation: [0.25965562, 0.68725012, 0.02382144, 0.02927282]\n",
      "lambdas tried: [array([0.13487081, 0.86512919]), array([0.59055148, 0.40944852]), array([0.50004212, 0.49995788]), array([0.02889269, 0.97110731]), array([0.42741403, 0.57258597])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Dev Perplexity for 3-gram interpolation: 79.79845216032913\n",
      "Best Lambdas for 3-gram interpolation: [0.25965562, 0.68725012, 0.02382144, 0.02927282]\n",
      "lambdas tried: [array([0.00391643, 0.65970598, 0.3363776 ]), array([0.3718003 , 0.31259479, 0.31560491]), array([0.21692961, 0.44487474, 0.33819565]), array([0.23890631, 0.65682414, 0.10426955]), array([0.24492011, 0.323434  , 0.43164589])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Dev Perplexity for 4-gram interpolation: 68.77213876857131\n",
      "Best Lambdas for 4-gram interpolation: [0.25965562, 0.68725012, 0.02382144, 0.02927282]\n",
      "lambdas tried: [array([0.45498296, 0.06589417, 0.21360509, 0.26551778]), array([0.03844718, 0.75605557, 0.15112596, 0.0543713 ]), array([0.35570694, 0.40318846, 0.19764879, 0.04345581]), array([0.05228346, 0.58641148, 0.29509582, 0.06620925]), array([0.1999599 , 0.01023681, 0.70220212, 0.08760118])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 67
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
